[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Machine Learning Design for Business",
    "section": "",
    "text": "Welcome\nWelcome to Machine Learning Design for Business! This is the the online textbook that compliments the UC BANA 7075 course. This course aims to provide a framework for developing real-world machine learning systems that are deployable, reliable, and scalable. You will be introduced to MLOps as the intersection of DataOps, ModelOps, and DevOps; combined, these concepts provide scalable, reliable, and repeatable machine learning workflows. You will learn how MLOps enables organizations to overcome challenges in operationalizing machine learning models. Along the way, you will learn about important organizational issues including privacy, fairness, security, stakeholder management, project collaboration, and more!\nThroughout this textbook you’ll find embedded lectures, hands-on exercises, and additional resources that will allow you to explore the tools, techniques, and best practices required to successfully design and deploy machine learning systems in today’s organizations.",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "index.html#who-should-read-this",
    "href": "index.html#who-should-read-this",
    "title": "Machine Learning Design for Business",
    "section": "Who should read this",
    "text": "Who should read this\nThis book is ideal for graduate students, data scientists, engineers, and analytics professionals who want to bridge the gap between building machine learning models and deploying them into reliable, scalable production environments. Those looking to deepen their understanding of operationalizing ML models will benefit from hands-on experience with MLOps workflows, including data management, model deployment, and monitoring. Individuals with a basic background in machine learning or software development will gain practical skills to streamline the machine learning lifecycle and align their work with organizational and business goals.\nThis book is also valuable for those interested in cross-functional collaboration, providing insights into how data science teams can work alongside engineering and business units to achieve successful machine learning outcomes.\nThis book is technical in nature, designed to provide hands-on experience in deploying, monitoring, and managing machine learning systems. While it’s possible to successfully complete the book with minimal coding experience, having some familiarity with Python and basic machine learning concepts will be beneficial for understanding and applying the material. The course introduces technical tools and workflows, but it’s structured to guide students of various backgrounds through each step. Those with prior experience in Python or ML will have a smoother time grasping the concepts and may find it easier to implement projects independently. However, foundational knowledge in programming or machine learning is not strictly required, as core principles and step-by-step instructions are provided to support all readers in building effective MLOps pipelines.\n\n\n\n\n\n\nIf you are new to Python, I recommend you check out https://bradleyboehmke.github.io/uc-bana-6043 to get up to speed with the basics.",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "index.html#conventions-used-in-this-book",
    "href": "index.html#conventions-used-in-this-book",
    "title": "Machine Learning Design for Business",
    "section": "Conventions used in this book",
    "text": "Conventions used in this book\nThe following typographical conventions are used in this book:\n\nstrong italic: indicates new terms,\nbold: indicates package & file names,\ninline code: monospaced highlighted text indicates functions or other commands that could be typed literally by the user,\ncode chunk: indicates commands or other text that could be typed literally by the user\n\n\n1 + 2\n\n3\n\n\nIn addition to the general text used throughout, you will notice the following code chunks with images:\n\n\n\n\n\n\nSignifies a tip or suggestion\n\n\n\n\n\n\n\n\n\nSignifies a general note\n\n\n\n\n\n\n\n\n\nSignifies a warning or caution",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "index.html#software-used-throughout-this-book",
    "href": "index.html#software-used-throughout-this-book",
    "title": "Machine Learning Design for Business",
    "section": "Software used throughout this book",
    "text": "Software used throughout this book\nTBD",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "index.html#additional-resources",
    "href": "index.html#additional-resources",
    "title": "Machine Learning Design for Business",
    "section": "Additional resources",
    "text": "Additional resources\nTBD",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "01-intro-ml-system.html",
    "href": "01-intro-ml-system.html",
    "title": "1  ML System Design",
    "section": "",
    "text": "1.1 ML System Design\nMachine Learning (ML) System Design is the discipline of creating reliable, scalable, and maintainable machine learning systems that solve real-world business problems. Unlike standard machine learning modeling, which focuses primarily on algorithm development and evaluation, ML System Design considers the broader ecosystem in which a model must operate. This involves defining the architecture, infrastructure, and processes that make a model functional and sustainable within production environments. As organizations increasingly rely on machine learning to make data-driven decisions, robust system design has become essential for delivering models that consistently meet organizational needs and can adapt to change.\nEffective ML system design enables organizations to avoid many pitfalls of deploying machine learning in production. Poorly designed systems can lead to issues like inaccurate predictions due to data drift, high operational costs, increased tech debt1, or significant downtime during retraining or model updates. By adhering to design principles such as modularity, scalability, and reproducibility, ML engineers and data scientists can develop systems that are more resilient and easier to manage. These principles form the backbone of good ML system design and help ensure that models can not only be deployed but also monitored, improved, and scaled as needed.\nThis section will explore these design principles in detail and examine how they align with key stages of the ML system lifecycle, from data processing and model training to deployment, monitoring, and iteration. As Chip Huyen points out, “Machine learning in production is 10% modeling and 90% engineering” (Huyen 2022). Consequently, understanding ML System Design, the lifecycle of ML systems, and the technical decisions to consider is foundational for anyone working in machine learning, as it significantly impacts the ML system’s overall reliability and long-term value for the organization.\nML system design refers to the process of building, structuring, and integrating machine learning models into larger production environments to deliver reliable, scalable, and sustainable solutions. While traditional machine learning focuses on developing high-performing models, system design extends the focus to creating an entire ecosystem where these models can continuously operate, adapt, and provide value over time. It encompasses everything from data pipelines and infrastructure to model versioning, monitoring, and scaling, ensuring that machine learning projects align with organizational goals and can be maintained as data, requirements, and technology evolve.\nTherefore, ML system design includes multiple facets beyond the algorithms themselves:\nflowchart LR\n  subgraph ML[ML System]\n    direction TB\n    subgraph DataOps\n    end\n    subgraph ModelOps\n    end\n    subgraph DevOps\n    end\n  end\n  A[Stakeholders] --&gt; ML\n  B[Business Requirements] --&gt; ML\n  ML --&gt; C[End Users]\n  DataOps --&gt; ModelOps --&gt; DevOps\n\n\n\n\nFigure 1.1: Components of an ML System.",
    "crumbs": [
      "Laying the Foundation",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>ML System Design</span>"
    ]
  },
  {
    "objectID": "01-intro-ml-system.html#ml-system-design",
    "href": "01-intro-ml-system.html#ml-system-design",
    "title": "1  ML System Design",
    "section": "",
    "text": "Complexities of an ML System\n\n\n\n\n\nML systems are very complex and require various engineering tasks such as:\n\nData Engineering: data acquisition & data preparation,\nML Model Engineering: ML model training & serving, and\nCode Engineering: integrating ML model into the final product.\n\nConsequently, ML System Design and ML Engineering are often used synonymously.\n\n\n\nThe Complexities of an ML System (https://ml-ops.org)\n\n\n\n\n\n\n\n\nDataOps: Data Management and Pipelines\nAt the heart of any ML system is data, which is processed, transformed, and delivered to the model in a way that supports both training and inference. A well-designed ML system typically includes data pipelines that handle:\n\nData ingestion: Collecting data from various sources, including databases, APIs, and real-time streams.\nData processing: Cleaning, transforming, and structuring data for model consumption.\nData validation: Ensuring that data quality is maintained and meets the standards required by the model.\nData versioning and lineage: Tracking data versions and maintaining a record of data transformations, which are critical for reproducibility and regulatory compliance.\n\n\n\nModelOps: Model Lifecycle Management\nA central aspect of ML system design is managing the entire model lifecycle, from development and testing to deployment and retirement. This includes:\n\nExperiment tracking and versioning: Maintaining a record of model versions, hyperparameters, and evaluation metrics to track performance and support reproducibility.\nDeployment pipelines: Automating model deployment processes to reduce manual errors and accelerate time-to-production.\nMonitoring and alerting: Establishing mechanisms for monitoring model performance in production and detecting issues such as data drift, concept drift, or system degradation.\nContinuous improvement: Supporting processes for regular retraining, fine-tuning, and updating models as data and requirements change.\n\n\n\nDevOps Practices\nGood ML system design brings DevOps practices to the world of machine learning. DevOps, short for “Development and Operations,” is a set of practices and principles that combines software development (Dev) and IT operations (Ops) with the goal of shortening the software development lifecycle and delivering high-quality, reliable software more efficiently. At its core, DevOps is about fostering a culture of collaboration between development and operations teams, integrating automated processes, and leveraging continuous integration and continuous deployment (CI/CD) practices to streamline workflows. This includes:\n\nAutomating code and model updates to streamline deployment and minimize downtime.\nAutomation of testing and validation: Implementing automated tests to validate model performance, accuracy, and reliability.\nCompute resources: Setting up scalable, flexible compute resources (such as cloud instances, GPUs, or Kubernetes clusters) to handle model training and inference.\nStorage solutions: Designing data storage strategies that balance cost, speed, and accessibility.\nNetworking and security: Ensuring secure data transfer and protecting sensitive information while allowing fast access for machine learning processes.\nCollaboration between teams: Encouraging collaboration across data science, engineering, and business teams to ensure that models meet organizational requirements and add real value.\n\n\n\n\n\n\n\nDriven by business requirements\n\n\n\nThe design of each key element in an ML system is ultimately driven by business requirements, as they define the purpose and value that the system should deliver. Business goals shape how data is processed, what metrics the model optimizes, and the reliability, scalability, and security standards it must meet. For example, a financial institution deploying a fraud detection model may prioritize stringent data validation and versioning to comply with regulatory standards, while a retail organization focused on real-time recommendations may emphasize rapid data ingestion and low-latency deployment.\nModel lifecycle management is similarly guided by business needs; frequent retraining cycles, experiment tracking, and monitoring capabilities are crucial when a system must adapt to fast-changing consumer behavior or market trends. Infrastructure choices, such as selecting between cloud and on-premise solutions, also reflect organizational constraints, like budget or resource availability.\nBy aligning these elements with clear business objectives, organizations can create ML systems that are not only technically sound but also effective in achieving their strategic goals.",
    "crumbs": [
      "Laying the Foundation",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>ML System Design</span>"
    ]
  },
  {
    "objectID": "01-intro-ml-system.html#why-ml-system-design-matters",
    "href": "01-intro-ml-system.html#why-ml-system-design-matters",
    "title": "1  ML System Design",
    "section": "1.2 Why ML System Design Matters",
    "text": "1.2 Why ML System Design Matters\nML system design addresses the challenges of productionizing machine learning. In a laboratory or research setting, machine learning models are often developed with a focus on achieving high accuracy or minimizing error on a given dataset. However, deploying these models in production involves a different set of concerns. In real-world applications, ML systems need to handle fluctuating data distributions, evolving user needs, and high availability. Without a robust design, machine learning models can quickly degrade in performance, lead to incorrect predictions, or even disrupt business operations.\nBy prioritizing system design, organizations can build ML workflows that are both responsive to change and maintainable over time. This approach reduces technical debt—the accumulation of outdated or poorly designed code, data dependencies, and complex interactions that are difficult to fix — highlighted by the authors in Hidden Technical Debt in Machine Learning Systems as a critical challenge in ML applications (Sculley et al. 2015). Poorly managed dependencies and hidden feedback loops, for instance, can lead to unpredictable model behavior and complicate future updates. Thoughtful ML system design mitigates these issues, allowing models to deliver consistent, reliable results while aligning predictions more closely with organizational metrics and objectives. Ultimately, well-architected ML systems are more adaptable, enabling models to evolve as business goals and data distributions shift over time.",
    "crumbs": [
      "Laying the Foundation",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>ML System Design</span>"
    ]
  },
  {
    "objectID": "01-intro-ml-system.html#sec-design-principles",
    "href": "01-intro-ml-system.html#sec-design-principles",
    "title": "1  ML System Design",
    "section": "1.3 Design Principles for Good ML System Design",
    "text": "1.3 Design Principles for Good ML System Design\nCreating an effective ML system involves more than just building an accurate model; it requires thoughtful design to ensure that the system remains reliable, scalable, and adaptable over time. Good ML system design incorporates a set of principles that help address real-world challenges in production environments, such as evolving data, model drift, and changing business requirements. The following design principles guide ML engineers and data scientists in building systems that meet these demands and deliver sustained business value.\n\n\n\n\n\n\nclassDiagram\n    class Principles {\n      Modularity and Abstraction\n      Scalability\n      Reproducibility\n      Automation\n      Monitoring and Maintenance\n      Security and Compliance\n      Adaptability and Flexibility\n    }\n\n\n\n\nFigure 1.2: Principles that create reliable, scalable, and adaptable machine learning systems.\n\n\n\n\n\n\nModularity and Abstraction\nModularity is the practice of dividing a system into independent, self-contained components, each responsible for a specific function. In an ML system, this could mean separating data ingestion, preprocessing, training, and monitoring into distinct modules that can operate independently (Sculley et al. 2015). This modularity simplifies updates and maintenance, as each component can be modified or scaled without disrupting the entire system. For example, if a new feature engineering technique improves model accuracy, it can be implemented in the data preprocessing module without affecting the deployment pipeline.\nAbstraction, on the other hand, hides complex details within each module, making the system easier to manage and more accessible to team members who don’t need to understand every technical detail. As noted by Huyen (2022), abstraction helps bridge the gap between data scientists, engineers, and business stakeholders, allowing each to focus on high-level functionality without needing an in-depth understanding of every process. Together, modularity and abstraction improve collaboration, flexibility, and ease of scaling within ML systems.\n\n\nScalability\nScalability ensures that an ML system can handle increased demand—whether in terms of data volume, number of users, or computational load—without requiring extensive re-engineering. Designing for scalability involves choosing infrastructure and tools that allow for efficient resource allocation and growth. For instance, deploying a model on cloud infrastructure, where compute resources can be dynamically allocated, allows an ML system to scale up to handle peak loads and scale down during quieter periods, optimizing costs and performance (Levine et al. 2020).\nAnother aspect of scalability is planning for future expansion. An ML system might start with a few users or limited data, but as it proves valuable, the system may need to accommodate more data sources, larger user bases, or additional model versions. Scalable design considers these future needs from the outset, making it easier to extend the system’s capabilities without significant architectural changes.\n\n\nReproducibility\nReproducibility is critical for ML systems, particularly in production settings where consistent results and traceability are essential. Reproducibility ensures that anyone with access to the same code, data, and configuration can recreate a model with the same results. This is essential for troubleshooting, compliance, and validating model performance. As described by Amershi et al. (2019), reproducibility allows teams to understand how specific predictions are made and to resolve any issues that arise in production more efficiently.\nAchieving reproducibility requires careful versioning of data, models, and code. Version control tools like Git and DVC (Data Version Control) help keep track of changes to code and data over time, while tools like MLflow or Weights & Biases allow for experiment tracking and versioning of model parameters. Reproducibility is especially important in regulated industries, where organizations may need to demonstrate how a model made a particular prediction or prove compliance with specific standards.\n\n\nAutomation\nAutomation is a foundational principle in ML system design, as it reduces manual intervention, minimizes human error, and accelerates workflows. As described by Polyzotis et al. (2019), automation is particularly valuable in environments where frequent model retraining, testing, or deployment is necessary. For instance, an automated pipeline can retrain a model when new data is available, perform validation checks, and deploy the updated model to production, all without requiring human involvement.\nKey areas for automation in ML systems include data ingestion and preprocessing, model training and evaluation, deployment, and monitoring. Automating these stages not only saves time but also ensures that the system operates consistently and can adapt to changing data and conditions. This is crucial in fast-paced environments, such as e-commerce or finance, where systems must quickly respond to new information.\n\n\nMonitoring and Maintenance\nMonitoring and maintenance are essential for keeping an ML system aligned with its intended goals over time. Once a model is deployed, its performance can be affected by data drift (changes in data distribution) or concept drift (changes in the underlying relationships within the data) (Gama et al. 2014). Without monitoring, these issues can lead to model degradation, resulting in inaccurate predictions or decisions that don’t meet business objectives.\nGood ML system design includes monitoring dashboards and automated alerts that track metrics such as prediction accuracy, latency, data drift, and system errors. Tools like Prometheus and Grafana can help set up performance monitoring, while specialized ML monitoring solutions can track model-specific metrics. Regular maintenance practices, such as retraining or recalibrating models, are also essential for sustaining system performance and adapting to new data patterns or business requirements.\n\n\nSecurity and Compliance\nSecurity and compliance are often overlooked in ML system design but are increasingly important, especially in regulated industries like healthcare, finance, and government. An ML system that processes sensitive data must include security measures to protect data integrity and confidentiality. Security considerations include encrypting data in transit and at rest, managing user access controls, and safeguarding against adversarial attacks (Papernot et al. 2017).\nCompliance involves ensuring that the ML system adheres to industry regulations and organizational policies. For instance, GDPR compliance may require an ML system to provide transparency into how predictions are made and to allow users to request data deletions. Designing with security and compliance in mind not only protects the organization but also builds trust with users and stakeholders.\n\n\n\n\n\n\nWhat’s GDPR?\n\n\n\n\n\nThe General Data Protection Regulation (GDPR) is a comprehensive privacy law enacted by the European Union in 2018, aimed at protecting the personal data and privacy of individuals within the EU and the European Economic Area (EEA). GDPR sets strict guidelines on how organizations must collect, store, process, and share personal data, giving individuals more control over their information. Key principles of GDPR include data minimization, purpose limitation, and transparency, along with rights for individuals such as the right to access, correct, and delete their data. Non-compliance with GDPR can lead to significant fines, making it essential for companies, especially those dealing with machine learning systems, to prioritize data security and privacy to ensure compliance.\nWe discuss regulation and other important human right considerations in Chapter 12.\n\n\n\n\n\nAdaptability and Flexibility\nAdaptability is the ability of an ML system to evolve as data, business requirements, and technologies change. In a dynamic business environment, the needs of an ML system may shift over time, requiring the model to be updated, new features to be added, or the infrastructure to be reconfigured (Sculley et al. 2015). Designing for adaptability involves using flexible frameworks, modular components, and tools that support rapid changes without extensive rework.\nFor example, a well-designed ML system might use containerization (e.g., Docker) to allow models to be easily moved across environments or use APIs to integrate new data sources without significant restructuring. This flexibility enables teams to quickly implement changes, test new ideas, and stay aligned with business goals, making the system more resilient to future changes.\n\n\nPutting It All Together\nThese principles — modularity, scalability, reproducibility, automation, monitoring and maintenance, security, and adaptability — form the foundation of good ML system design. Each principle contributes to creating a system that is not only technically robust but also capable of delivering sustained business value. By applying these principles, ML engineers and data scientists can build systems that are flexible, resilient, and scalable, ensuring that machine learning models remain effective and reliable over time. Good ML system design allows organizations to move beyond individual models and create a stable, agile infrastructure that continuously adapts to meet evolving business demands.",
    "crumbs": [
      "Laying the Foundation",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>ML System Design</span>"
    ]
  },
  {
    "objectID": "01-intro-ml-system.html#relation-to-ml-system-lifecycle-stages",
    "href": "01-intro-ml-system.html#relation-to-ml-system-lifecycle-stages",
    "title": "1  ML System Design",
    "section": "1.4 Relation to ML system lifecycle stages",
    "text": "1.4 Relation to ML system lifecycle stages\nGood ML system design requires a holistic approach that considers how key elements and design principles intersect with each stage of the ML system lifecycle. The ML lifecycle can be broken down into distinct stages: data processing, model development, deployment, monitoring, and continuous improvement. By aligning design principles with these stages, organizations can create systems that are not only effective at deployment but sustainable, adaptable, and closely aligned with business objectives over the long term.\n\n\n\n\n\n\nsequenceDiagram\n    participant dp as Data Ingestion & Processing\n    participant md as Model Development\n    participant dep as Deployment\n\n    Note over dp,dep: Modularity and Abstraction\n    Note over dp,dep: Scalability\n    Note over dp,dep: Reproducibility\n    Note over dp,dep: Automation\n    Note over dp,dep: Monitoring and Maintenance\n    Note over dp,dep: Security and Compliance\n    Note over dp,dep: Adaptability and Flexibility\n\n\n\n\nFigure 1.3: ML design principles should be considered across all stages of the ML lifecycle. By doing so, organizations can create systems that are not only effective at deployment but sustainable, adaptable, and closely aligned with business objectives over the long term.\n\n\n\n\n\n\nData Processing\nThe data processing stage encompasses everything from data ingestion and transformation to validation and storage. Principles like modularity and automation are especially valuable here, as they allow data pipelines to handle diverse data sources and adapt to changes without disrupting downstream processes. DataOps practices ensure the accuracy and integrity of data, including validation and lineage tracking, so the right data reaches the model reliably. Reproducibility also plays a crucial role at this stage, as versioned datasets and pipelines help maintain consistency, which is vital for model retraining and compliance.\n\n\nModel Development\nModel development involves experimentation, model training, and evaluation. Here, modularity and reproducibility are essential for managing experiments and enabling easy comparison of results across different model versions. ModelOps practices, including experiment tracking and model versioning, facilitate tracking hyperparameters, code versions, and results, ensuring models can be accurately reproduced and refined. Scalability is another key consideration, especially for large datasets or complex models that require significant computational resources. In this stage, infrastructure choices, such as cloud or GPU-based solutions, allow the system to scale up as needed.\n\n\nDeployment\nThe deployment stage focuses on moving models from development to production in a seamless, automated, and reliable manner. Automation is paramount, with CI/CD pipelines automating the testing, validation, and deployment processes to minimize human error and expedite time-to-production. DevOps principles enable automated deployment processes that integrate testing and validation steps, reducing downtime and increasing reliability. Security also becomes critical, ensuring that data access and model endpoints are protected against unauthorized access or adversarial attacks.\n\n\nMonitoring and Maintenance\nOnce a model is live, continuous monitoring is essential to track key metrics such as accuracy, latency, and model drift, ensuring that the model performs as expected over time. Monitoring and maintenance principles are implemented through tools and dashboards that monitor data drift and system performance. Alerts can notify teams of anomalies or degradation, enabling quick action to retrain or update the model if needed. Automation also supports regular retraining workflows, particularly in dynamic environments where data patterns shift frequently. Maintenance ensures that the ML system remains robust and responsive to changing data and requirements.\n\n\nContinuous Improvement\nThe continuous improvement stage focuses on enhancing the model based on feedback from monitoring and evolving business needs. Adaptability and flexibility are essential here, allowing the system to integrate new data, retrain models, and test enhancements with minimal friction. Scalability and modularity enable models to grow and improve without requiring complete redesigns of the system. In practice, this means designing systems with modular components that can easily integrate new models or data sources, ensuring that the system remains aligned with both technical advancements and organizational goals.",
    "crumbs": [
      "Laying the Foundation",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>ML System Design</span>"
    ]
  },
  {
    "objectID": "01-intro-ml-system.html#summary",
    "href": "01-intro-ml-system.html#summary",
    "title": "1  ML System Design",
    "section": "1.5 Summary",
    "text": "1.5 Summary\nIn this chapter, we introduced the concept of Machine Learning (ML) System Design, focusing on how it creates a foundation for building reliable, scalable, and adaptable machine learning systems that can deliver value in real-world production environments. Unlike traditional model development, ML system design considers the entire ecosystem, encompassing data pipelines, model lifecycle management, and operational infrastructure, all shaped by business requirements. By following core design principles — such as modularity, scalability, reproducibility, automation, monitoring, and security — ML systems can avoid common production pitfalls like model drift, high operational costs, and downtime, ensuring that models are not only deployed successfully but also perform reliably over time.\nThe chapters that follow will expand on each element of ML system design, providing readers with a deep understanding of the key concepts and principles that enable the creation of robust ML systems. Readers will gain the ability to identify essential design decisions that align with business goals, as well as the tools and practices necessary to implement these considerations effectively. By the end of this book, readers will be equipped to build, manage, and maintain ML systems that are both technically sound and responsive to evolving business needs.\n\n\n\n\n\n\nFurther Reading\n\n\n\n\n\n\nMotivation for MLOps\nHidden Technical Debt in Machine Learning Systems",
    "crumbs": [
      "Laying the Foundation",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>ML System Design</span>"
    ]
  },
  {
    "objectID": "01-intro-ml-system.html#exercise",
    "href": "01-intro-ml-system.html#exercise",
    "title": "1  ML System Design",
    "section": "1.6 Exercise",
    "text": "1.6 Exercise\nRead one or more of the following case studies. These case studies cover different perspectives, elements, and principles of ML system design.\n\nWhat are the primary business objective(s) for the ML system discussed? How does the system add value for both the organization and its customers?\nAnalyze key elements and design principles discussed. For example:\n\nDataOps: How does the organization handle data ingestion, processing, and versioning to support a constantly changing catalog and user preferences?\nModelOps: What strategies does the organization use to manage the lifecycle of its models, including retraining, versioning, and experimentation?\nDevOps: How does the organization ensure continuous integration and deployment for its models? What automation, testing, and monitoring practices are used to maintain system reliability?\nDesign Principles: Identify examples of modularity, scalability, automation, and monitoring within the organization’s ML system. Explain how each principle contributes to the system’s success.\n\n\n\n\n\n\n\n\nNote that these articles will likely mention technical concepts and tools that you may not be familiar with and feel like they are over your head. Do not worry about this! This book will help to bridge some of these gaps.\n\n\n\n\n\n\n\n\n\nCase Studies\n\n\n\n\n\n\nNetflix: Netflix’s Recommendation System: Algorithms, Business Value, and Innovation\nUber: Scaling Machine Learning at Uber with Michelangelo\nSpotify: Inside Spotify’s Recommender System: A Complete Guide to Spotify Recommendation Algorithms\nAirbnb: Bighead: A Framework-Agnostic, End-to-End Machine Learning Platform\nGoogle: TFX - an end-to-end machine learning platform for TensorFlow\nLinkedIn: Scaling Machine Learning Productivity at LinkedIn\nFacebook: Introducing FBLearner Flow: Facebook’s AI backbone\nBooking.com: 150 Successful Machine Learning Models: 6 Lessons Learned at Booking.com\nTwitter: Twitter’s Recommendation Algorithm\n\n\n\n\n\n\n\n\nAmershi, Saleema, Andrew Begel, Christian Bird, Robert DeLine, Harald Gall, Ece Kamar, Nachiappan Nagappan, Besmira Nushi, and Thomas Zimmermann. 2019. “Software Engineering for Machine Learning: A Case Study.” In 2019 IEEE/ACM 41st International Conference on Software Engineering: Software Engineering in Practice (ICSE-SEIP), 291–300. IEEE.\n\n\nGama, João, Indrė Žliobaitė, Albert Bifet, Mykola Pechenizkiy, and Abdelhamid Bouchachia. 2014. “A Survey on Concept Drift Adaptation.” ACM Computing Surveys (CSUR) 46 (4): 1–37.\n\n\nHuyen, Chip. 2022. Designing Machine Learning Systems. \" O’Reilly Media, Inc.\".\n\n\nLevine, Sergey, Aviral Kumar, George Tucker, and Justin Fu. 2020. “Offline Reinforcement Learning: Tutorial, Review, and Perspectives on Open Problems.” arXiv Preprint arXiv:2005.01643.\n\n\nPapernot, Nicolas, Patrick McDaniel, Ian Goodfellow, Somesh Jha, Z Berkay Celik, and Ananthram Swami. 2017. “Practical Black-Box Attacks Against Machine Learning.” In Proceedings of the 2017 ACM on Asia Conference on Computer and Communications Security, 506–19.\n\n\nPolyzotis, Neoklis, Martin Zinkevich, Sudip Roy, Eric Breck, and Steven Whang. 2019. “Data Validation for Machine Learning.” Proceedings of Machine Learning and Systems 1: 334–47.\n\n\nSculley, David, Gary Holt, Daniel Golovin, Eugene Davydov, Todd Phillips, Dietmar Ebner, Vinay Chaudhary, Michael Young, Jean-Francois Crespo, and Dan Dennison. 2015. “Hidden Technical Debt in Machine Learning Systems.” Advances in Neural Information Processing Systems 28.",
    "crumbs": [
      "Laying the Foundation",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>ML System Design</span>"
    ]
  },
  {
    "objectID": "01-intro-ml-system.html#footnotes",
    "href": "01-intro-ml-system.html#footnotes",
    "title": "1  ML System Design",
    "section": "",
    "text": "Technical debt in machine learning systems refers to the accumulation of hidden costs due to shortcuts, entanglement, and system complexity, which degrade maintainability and scalability over time. ML systems are particularly prone to technical debt from issues like data dependencies, undeclared consumers, and pipeline jungles, making proactive debt management essential for long-term sustainability (Sculley et al. 2015).↩︎",
    "crumbs": [
      "Laying the Foundation",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>ML System Design</span>"
    ]
  },
  {
    "objectID": "02-before-we-build.html",
    "href": "02-before-we-build.html",
    "title": "2  Before We Build",
    "section": "",
    "text": "2.1 Working with Stakeholders to Understand the Business Problem\nBuilding an effective machine learning (ML) system requires more than just technical knowledge and model-building skills. The success of an ML project depends heavily on the foundational planning that happens long before the first line of code is written or the first dataset is processed. This planning phase is essential to ensuring that the project aligns with the business goals, addresses the right problem, and is both technically feasible and valuable. In this chapter, we’ll explore the key considerations and actions to take before starting the development of an ML system.\nThe first step in any ML project is to collaborate closely with stakeholders to fully understand the business problem. This stage is critical because a thorough understanding of the problem directly impacts the translation of business needs into a solvable analytics problem, helps scope the project realistically, and ensures the ML system will truly meet organizational goals. Stakeholders include anyone with a vested interest in the project’s success—such as executives, department leads, data science teams, IT, and end users. Each group brings a unique perspective, and understanding their needs and expectations provides clarity on objectives, potential constraints, and the broader impact of the solution.\nEffective communication with stakeholders helps to align everyone on the project’s purpose and desired outcomes. By having these early conversations, ML practitioners gain insight into business priorities, potential data requirements, and assumptions being made about data availability, user behavior, and expected outcomes. Common assumptions that come to light in these initial meetings might include beliefs about data quality or completeness, end-user expectations of functionality, or even implicit views on the model’s potential accuracy and impact. Identifying and addressing these assumptions early on prevents misalignment and reduces the risk of costly adjustments later in the project.\nTo gain a comprehensive understanding of the business problem, ML practitioners should consider key questions with stakeholders, such as:\nThese questions help not only to clarify the business goals but also to highlight how the problem should be reframed into an analytics problem. For instance, a high-level business problem like “improving customer retention” can translate into an analytics problem focused on predicting customer churn and identifying key factors contributing to it. Defining the problem at this level makes it easier to identify relevant data, narrow down model requirements, and set realistic goals.\nAdditionally, early discussions often uncover essential requirements and constraints, such as data dependencies, privacy concerns, or specific regulatory requirements. By clarifying these aspects, ML teams can make more informed decisions on technical design, data preprocessing, and timeline estimation. Furthermore, gaining a clear understanding of the end-users’ needs helps in defining how the ML system should be integrated into existing workflows, ensuring the solution is not only technically robust but also user-friendly and practical.\nIn summary, investing time upfront to deeply understand the business problem and address underlying assumptions results in a more targeted, relevant ML solution. This shared understanding among stakeholders lays the groundwork for a smooth translation of business objectives into technical requirements, helping to scope the project effectively and set it up for long-term success.",
    "crumbs": [
      "Laying the Foundation",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Before We Build</span>"
    ]
  },
  {
    "objectID": "02-before-we-build.html#working-with-stakeholders-to-understand-the-business-problem",
    "href": "02-before-we-build.html#working-with-stakeholders-to-understand-the-business-problem",
    "title": "2  Before We Build",
    "section": "",
    "text": "What specific problem are we trying to solve?\nWhat are the business objectives associated with addressing this problem?\nWho will use the ML system, and what actions or decisions will it facilitate?\nWhat are the potential risks or consequences if the system produces inaccurate or unintended results?\nAre there existing solutions or processes in place, and what are their limitations?\n\n\n\n\n\n\n\n\n\nYou should help guide the discussion\n\n\n\n\n\nA common challenge when working with stakeholders is that their initial requests may not be technically feasible or the best solution from an ML perspective. Business owners often lack technical expertise and may propose solutions that are impractical due to limitations in data availability, infrastructure, or real-time processing capabilities.\nFor example, a credit card company might request a real-time fraud detection system that automatically denies fraudulent transactions. However, if real-time infrastructure is lacking, data pipelines are not in place, or budget constraints prevent deployment, the proposed solution may not be viable. In such cases, ML practitioners must deeply understand the problem and collaborate with stakeholders to re-scope it within practical constraints. Alternative approaches could include assessing customer risk at the time of credit card application, flagging high-risk transactions for manual review instead of automatic denial, or shifting focus from individual transaction fraud to identifying high-risk merchants. By aligning technical capabilities with business goals, ML practitioners can ensure that the final solution is both impactful and feasible.\n\n\n\n\n\n\n\n\n\n\nIsn’t this a project manager responsibility?\n\n\n\n\n\nData scientists should be involved in the early planning process of an ML project because their expertise in data and analytics enables them to assess the feasibility of proposed solutions, clarify data requirements, and identify potential technical challenges. While some ML practitioners may balk at including planning, communication, brainstorming, and other project-management-focused elements in discussions on ML projects, these early stages are often where critical project alignment occurs. In my experience, the most successful projects have involved ML team leads working closely not only with project managers and other team leads but also with representatives from the department requesting the solution. Data scientists bring essential knowledge about data limitations, model requirements, and potential roadblocks that might otherwise go unnoticed. Their involvement helps refine the project’s scope to align with both the business goals and technical realities, setting realistic expectations and paving the way for a solution that is both effective and feasible. This collaborative approach during planning ultimately saves time, enhances clarity, and boosts the likelihood of delivering a meaningful, successful ML solution.",
    "crumbs": [
      "Laying the Foundation",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Before We Build</span>"
    ]
  },
  {
    "objectID": "02-before-we-build.html#determining-if-the-problem-requires-an-ml-solution",
    "href": "02-before-we-build.html#determining-if-the-problem-requires-an-ml-solution",
    "title": "2  Before We Build",
    "section": "2.2 Determining if the Problem Requires an ML Solution",
    "text": "2.2 Determining if the Problem Requires an ML Solution\nNow that we understand the importance of working with stakeholders to fully grasp the business problem, the next step is to translate the business problem into an analytics problem. This process will help us determine whether machine learning (ML) is the right approach to address the issue. ML can be a powerful tool, but it’s not always the best solution. Determining if ML is suitable requires thoughtful consideration, as unnecessary ML implementation can lead to wasted resources, increased complexity, and maintenance challenges.\n\nKey Considerations to Determine ML Suitability\nDetermining if a problem requires an ML solution involves assessing whether the business objectives demand certain characteristics that ML can uniquely provide.\n\nSome essential considerations include:\n\n\n\n\n\n\nLearning Complex Patterns from Data\n\n\n\n\n\nML excels when the solution requires identifying complex, often non-linear relationships within data that are difficult to capture using rules-based or traditional statistical approaches. If the problem involves intricate patterns that need to be learned from large volumes of data, ML may be appropriate. For example, ML can be effective at analyzing the complex and non-linear relationships between a customer’s purchase history, browsing behavior, and demographic characteristics to generate personalized product recommendations.\n\n\n\n\n\n\n\n\n\nAvailability of Quality Data\n\n\n\n\n\nML solutions require substantial and high-quality data for training and testing. Without sufficient data, the model cannot learn the patterns or features necessary to make accurate predictions. Data availability should include not only a large enough sample size but also a diverse dataset that represents the full range of scenarios the model will encounter in production. If quality data is unavailable, ML is unlikely to perform well and may not be worth pursuing.\n\n\n\n\n\n\n\n\n\nMaking Predictions on Unseen Data\n\n\n\n\n\nML is suitable for problems where we need the system to make predictions on new, unseen data that will continue to arrive over time. For instance, in fraud detection, the goal is for the system to recognize fraudulent behavior in real-time as new transactions occur. This is an inherently predictive task and well-suited to ML, where models trained on historical fraud data can be applied to identify anomalies in new transactions.\n\n\n\n\n\nML is Not Always the Answer\nMachine learning is a powerful tool, but it’s not a one-size-fits-all solution. Yet, in today’s fast-paced tech landscape, it’s common for business leaders to latch onto popular trends like ML, AI, and automation, believing that these technologies can solve a wide range of problems or offer an innovative edge. However, the reality is that many problems don’t require the complexity or resources of an ML system and can actually be addressed more effectively with simpler approaches. Below are examples of problems that often don’t meet the suitability criteria for ML, illustrating why a different solution may be more appropriate.\n\n\n\n\n\n\nRule-Based Decision Systems\n\n\n\n\n\nIf a problem can be solved with straightforward rules or conditions, then ML is likely unnecessary. For example, an e-commerce site offering a standard discount based on membership level (e.g., 10% off for premium members) may not need a predictive model to calculate discounts. A simple rule-based system is faster to implement, more interpretable, and easier to maintain. Business leaders sometimes assume that ML will increase personalization or provide better insights, but in some cases, it may only add complexity without significant, meaningful benefits.\n\n\n\n\n\n\n\n\n\nBasic Data Retrieval and Filtering\n\n\n\n\n\nWhen a task involves retrieving specific records or filtering data based on fixed criteria, ML is overkill. For instance, if a business wants a list of customers who made a purchase within the last month, a structured query in a database will suffice. ML could add unnecessary processing time, reduce transparency, and complicate data workflows without providing any added value. Leaders may be drawn to the idea of “automating data processes with ML,” but it’s critical to recognize that traditional data querying and reporting tools are often more efficient and will suffice when the goal is to simply slice and dice our data.\n\n\n\n\n\n\n\n\n\nStatic Reporting and Descriptive Analytics\n\n\n\n\n\nML is valuable for uncovering patterns, making predictions, or adapting to new data, but if the goal is simply to summarize historical data or calculate aggregate statistics (e.g., total sales last quarter or average customer lifetime value), traditional data analysis tools are more suitable. ML brings no additional value to tasks that involve reporting known facts. Although ML may sound impressive, using it for simple reporting can lead to unnecessary costs in computation, maintenance, and monitoring.\n\n\n\n\n\n\n\n\n\nTasks with Deterministic Outputs\n\n\n\n\n\nWhen a problem has predictable, deterministic outputs based on clear rules, ML can be redundant. For example, payroll tax calculation, which follows specific formulas, does not require a model to “learn” the process. Hard-coded logic or rule-based systems are not only more accurate in such cases but also eliminate potential errors introduced by an ML model. Business leaders sometimes believe that ML will “future-proof” deterministic tasks, but simpler systems are usually more reliable, cost-effective, and transparent.\n\n\n\n\n\n\n\n\n\nHeavily Regulated Decisions Requiring Full Transparency\n\n\n\n\n\nIn industries such as finance or healthcare, strict regulations often require full transparency for every decision, making ML—especially complex models—an unsuitable choice. For instance, mortgage approvals based on a set of criteria are better handled by rules-based systems to ensure regulatory compliance and easy interpretability. While ML can provide valuable insights, its lack of interpretability in some models makes it challenging to justify for highly regulated tasks. Business leaders may be drawn to ML’s perceived sophistication, but in some cases, a rules-based approach may be more practical and reliable.\n\n\n\nThese examples, although not comprehensive, highlight the importance of carefully evaluating whether ML is truly the right tool for the job. ML can be ideal when there’s a need to learn from complex patterns in data, make predictions on new data, or adapt dynamically over time. However, using ML for problems that don’t meet these criteria or have additional concerns as mentioned above, can waste resources, reduce transparency, and increase project complexity. Recognizing when a simpler method will be more effective is a critical skill for data scientists and ML practitioners. Avoiding unnecessary ML solutions allows teams to focus their resources where they will add the most value, while helping business leaders make more informed, strategic technology decisions.\n\n\nPitfalls of Using ML Unnecessarily\nUsing ML when it’s not needed can create more problems than it solves. ML is powerful but also complex, requiring specialized skills, infrastructure, and ongoing maintenance. When ML is applied unnecessarily, organizations risk:\n\n\n\n\n\n\nIncreased Complexity and Maintenance Costs\n\n\n\n\n\nML systems require regular monitoring, retraining, and validation to ensure they remain accurate and reliable. For example, if an ML model is deployed to handle a task that could be addressed with simple rules, the organization may end up dedicating time and resources to monitor and maintain an over-engineered solution that adds little value. Traditional software solutions often require far less maintenance and are more stable over time.\n\n\n\n\n\n\n\n\n\nReduced Interpretability and Transparency\n\n\n\n\n\nML models, especially complex ones like neural networks, can be difficult to interpret. In situations where transparency is crucial—such as compliance with regulations or gaining end-user trust—a rules-based approach might be preferable. Using ML without necessity can lead to resistance from stakeholders who need clear explanations for the system’s outputs.\n\n\n\n\n\n\n\n\n\nWaste of Time and Resources\n\n\n\n\n\nDeveloping an ML system demands resources for data preparation, model selection, and deployment, as well as ongoing maintenance and infrastructure support. If the problem does not require ML, these resources could be better spent on other areas, such as enhancing customer experience or improving data quality.\n\n\n\n\n\n\n\n\n\nPotential for Errors and Misinterpretations\n\n\n\n\n\nML models are not infallible and can produce unexpected or incorrect results, especially when faced with data outside their training set. For example, if an ML model is applied to a problem that is straightforward or deterministic, it may introduce unnecessary variability or errors, which could lead to costly mistakes. For example, a recommendation system that misclassifies products might negatively impact user experience and decrease trust in the system.",
    "crumbs": [
      "Laying the Foundation",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Before We Build</span>"
    ]
  },
  {
    "objectID": "02-before-we-build.html#defining-performance-metrics-for-the-ml-system",
    "href": "02-before-we-build.html#defining-performance-metrics-for-the-ml-system",
    "title": "2  Before We Build",
    "section": "2.3 Defining Performance Metrics for the ML System",
    "text": "2.3 Defining Performance Metrics for the ML System\nEstablishing comprehensive performance metrics is critical for evaluating how effectively an ML system solves the intended business problem. Defining these metrics early not only provides a target for model performance but also ensures alignment between technical teams and business stakeholders. Performance metrics serve as both a development benchmark and a standard for continuous monitoring in production, helping teams maintain an effective and valuable ML system over time.\nA robust approach to performance metrics includes:\n\nModel performance metrics which measure predictive accuracy and reliability\nSystem performance metrics which gauge how well the overall ML system operates in a real-world environment\nBusiness performance metrics which measure the impact the ML system provides to the business.\n\n\n\n\n\n\n\nflowchart LR\n  subgraph ML[ML System]\n    direction BT\n    subgraph p0[Overall System Performance]\n    end\n    subgraph tech[Technical performance]\n      subgraph p1[Model performance metrics]\n      end\n      subgraph p2[System performance metrics]\n      end\n    end\n    subgraph p3[Business performance metrics]\n    end\n\n   p1 --&gt; p0\n   p2 --&gt; p0\n   p3 --&gt; p0\n  end\n\n\n\n\n\nFigure 2.2: Understanding an ML sytems performance requires multiple types of performance metrics: (1) model performance metrics, (2) system performance metrics, and (3) business performance metrics.\n\n\n\n\n\nBy incorporating all three, ML practitioners can ensure that the system is not only technically accurate but also capable of meeting the demands of production use and drives measurable improvements for the business. Let’s dive into each category in more detail.\n\nTechnical Performance Metrics\nTechnical performance metrics are essential for evaluating both the model’s accuracy and the system’s operational efficiency. These metrics allow teams to optimize not only the predictive power of the model but also its usability within a production environment. By considering both model and system performance metrics, teams can ensure the ML system is not only accurate but also performant, reliable, and capable of meeting operational requirements in production.\n\n\n\n\n\n\nModel Performance Metrics\n\n\n\n\n\nThese metrics evaluate the accuracy and reliability of the ML model in making predictions. These metrics include common metrics you likely have heard of before if you’ve done any ML tasks such as mean squared error, \\(R^2\\), and mean absolute error for regression problems; cross-entropy, gini index, precision, and recall for classification problems; or BLEU, BERTScore, and perplexity for large language models. The choice of metric depends on the type of ML task (e.g., classification, regression) and the consequences of different kinds of errors.\nFurther reading: Selecting the Right Metric for evaluating Machine Learning Models - Part 1, Part 2\n\n\n\n\n\n\n\n\n\nSystem Performance Metrics\n\n\n\n\n\nWhile model accuracy is critical, it’s equally important to assess how well the overall ML system functions in real-world conditions. These metrics track the system’s efficiency, responsiveness, and reliability, ensuring that it can handle production demands. Metrics we often consider to measure system performance include:\n\nLatency: Measures the time required for the system to make a prediction once data is available. Low latency is critical in real-time applications like fraud detection and autonomous vehicles. Imagine a pedestrian steps out in front of an autonomous vehicle, there needs to be nearly zero time (or nearly no latency) between the car’s ML system taking in that input and making a prediction to stop otherwise the consequence will be catostrophic! 1\nThroughput: Indicates the number of predictions the system can process per unit of time. High throughput is essential for large-scale applications, such as recommendation systems used by Netflix and Spotify. For example, Netflix has around 280 million customers that they need to produce recommendation predictions for on a daily to weekly basis. 2\nUptime: Tracks the percentage of time the system is fully operational. Uptime is especially important for mission-critical systems, where outages can disrupt service and lead to lost revenue.\nScalability: Assesses the system’s ability to maintain performance as user demand or data volume increases, especially while needing to maintain real-time inference requirements. For example, imagine how user demand for Amazon surges on Black Friday! 3\nResource Utilization: Tracks CPU, memory, and GPU usage to ensure efficient resource allocation, particularly relevant for cloud-based ML systems. Efficient resource utilization can significantly reduce costs, as discussed in Ramesh et al., 2020.\n\n\n\n\nConsidering both model and system performance metrics enables teams to build ML systems that are not only accurate but also highly responsive, efficient, and reliable in a production environment.\n\n\nBusiness Performance Metrics\nWhile technical metrics are essential for evaluating the functionality of the ML system, business metrics ensure that the ML system drives meaningful impact for the organization. These metrics translate technical outputs into measurable business outcomes, aligning the ML system with the broader organizational goals. Some examples follow.\n\n\n\n\n\n\nRevenue Impact\n\n\n\n\n\nFor systems designed to drive sales or conversions, revenue-focused metrics quantify effectiveness. For example:\n\nIncremental Revenue: measures the additional revenue generated by the ML system compared to a baseline. This can demonstrate the impact of a recommendation system on customer purchases (McKinsey, 2018).\nConversion Rate: measures the percentage of users who complete a desired action after interacting with the ML system (e.g., making a purchase after receiving a recommendation).\n\n\n\n\n\n\n\n\n\n\nOperational Efficiency\n\n\n\n\n\nFor applications focused on cost reduction or improving efficiency, business will tend to use metrics that capture the system’s ability to streamline processes such as:\n\nCost Savings: measures the reduction in operational costs achieved by using the ML system, such as fewer maintenance visits with predictive maintenance models (Deloitte, 2020).\nProcess Time Reduction: measures the time saved in completing a process using the ML system, relevant in areas such as automated customer support ticket resolution (IBM, 2019).\n\n\n\n\n\n\n\n\n\n\nCustomer Engagement\n\n\n\n\n\nFor ML systems that serve customers directly, engagement metrics help gauge relevance and user experience. For example:\n\nClick-Through Rate (CTR): measures the percentage of users who engage with personalized content or recommendations. CTR is a common metric for digital content recommendations (Covington et al., 2016).\nUser Retention Rate: measures the percentage of users who continue to engage with the platform over time, providing a longer-term view of the system’s relevance.\n\n\n\n\n\n\n\n\n\n\nAccuracy in High-Stakes Decisions\n\n\n\n\n\nFor applications in areas like healthcare or finance, additional metrics measure the system’s ability to make accurate, high-impact decisions. For example:\n\nReduction in Error Rates for High-Risk Cases: measures the reduction in error rates (false-positives or false-negatives) in high-stakes predictions (e.g., fraud detection), which can demonstrate the value of the ML system in risk mitigation (Fawcett & Provost, 1997).\nCompliance and Risk Management Impact: measures the system’s role in meeting regulatory standards and reducing compliance risks, especially critical in regulated industries (EU GDPR, 2018).\n\n\n\n\nBy defining and monitoring both technical and business metrics, ML teams can ensure their system is effective from both a technical and strategic perspective, delivering real business value.\n\n\nBest Practices for Implementing Performance Metrics\nSuccessfully implementing performance metrics requires thoughtful integration into the ML system lifecycle. Here are some best practices commonly used to make metrics more effective. Later chapters will dive into the best practices focused on monitoring and setting thresholds and alerts.\n\nSet Benchmarks and Targets: Establish target values for each metric based on baseline performance, industry standards, and stakeholder expectations. Benchmarks help set realistic goals for model and system improvement (Sculley et al., 2015).\nUse Multiple Metrics for a Holistic View: Relying on a single metric can lead to misleading conclusions. Using a combination of metrics—such as precision and latency, or recall and business impact—provides a balanced understanding of performance (Saito & Rehmsmeier, 2015).\nMonitor Metrics Continuously: Performance metrics should be monitored throughout the model lifecycle, including in production. Continuous monitoring helps detect issues like data drift or system degradation (Breck et al., 2017).\nSet Thresholds and Alerts: Define acceptable thresholds for critical metrics and set up alerts if the system’s performance falls below these levels. This allows for quick intervention to resolve potential issues before they impact users or business outcomes.\nRegularly Re-Evaluate Metrics: As business needs and data sources evolve, so should the metrics. Periodic re-evaluation ensures that metrics remain relevant and continue to align with the organization’s priorities.",
    "crumbs": [
      "Laying the Foundation",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Before We Build</span>"
    ]
  },
  {
    "objectID": "02-before-we-build.html#understanding-the-potential-value-of-a-solution",
    "href": "02-before-we-build.html#understanding-the-potential-value-of-a-solution",
    "title": "2  Before We Build",
    "section": "2.4 Understanding the Potential Value of a Solution",
    "text": "2.4 Understanding the Potential Value of a Solution\nBefore embarking on building an ML system, it is essential to evaluate the potential value that the solution will bring to the organization. Understanding this value helps justify the investment of time, resources, and budget, and ensures that the ML system aligns with the organization’s business objectives. Evaluating potential value involves asking the right questions, considering both tangible and intangible benefits, and aligning with stakeholder priorities to secure buy-in.\n\nEvaluating Impact on Business Objectives\nThe success of an ML system is ultimately measured by its impact on business objectives. By evaluating how the system will improve key metrics — whether increasing revenue, reducing costs, enhancing customer satisfaction, or improving operational efficiency — teams can prioritize the features and use cases that will generate the greatest return on investment. The goal is to clearly articulate how the ML solution will contribute to the broader goals of the business, whether it’s through improved decision-making, optimized processes, or creating better customer experiences.\n\n\nQuestions to Estimate and Define the System’s Value\nTo estimate and define the value of an ML system, it’s useful to ask the following questions:\n\nHow Will the Solution Improve Business Outcomes? Consider the specific business outcomes that the ML system is intended to influence. For example, will a recommendation system increase sales by suggesting more relevant products to customers? And if so, what does the business reasonably expect those incremental sales to equate to? Or maybe the improved recommendation system will be able to make more time relevant predictions based on today’s trends or news, which could increase daily active users which could increase potential ad revenue. Or maybe the improved recommendation system is designed to reduce customer churn, which could lead to lower new customer acquisition costs. Answering these question helps determine just how the ML system is expected to benefit the organization and if the potential benefits justify the investment and ensures the solution is well-targeted.\nWhat Are the Tangible and Intangible Benefits? When evaluating the potential value, it’s important to look beyond the immediate financial benefits. Tangible benefits, such as cost savings, increased revenue, or reduced processing time, are easier to quantify and often form the basis for return on investment analyses. However, intangible benefits, like improved customer satisfaction, increased user engagement, enhanced employee productivity, or reduced risk, are equally important for long-term success but not as easy to quantify. For example, a fraud detection model may not only save money but also enhance customer trust—an intangible yet valuable outcome for the business. Although these are difficult to quantify, it is important to identify these potential benefits and determine if there is a way to quantify and track them.\n\n\n\nAligning Value Assessment with Stakeholder Priorities\nTo secure buy-in, it’s critical to align the value assessment with stakeholder priorities. This involves understanding the goals and pain points of various stakeholders and clearly articulating how the ML solution addresses them. Stakeholders, such as business executives, team leads, and end users, each have different perspectives on what constitutes value. By tailoring the value assessment to address these perspectives, ML practitioners can better communicate the expected benefits and ensure everyone is aligned on the importance of the project.\nInvolving stakeholders in this value assessment also provides an opportunity to identify potential risks, set realistic expectations, and agree on success criteria from the outset. When stakeholders see how the solution directly supports their goals, they are more likely to support the project and allocate the necessary resources to ensure its success.\nUnderstanding and clearly articulating the potential value of the ML solution lays a strong foundation for the project. It ensures that the system is designed to address the right problem, prioritizes outcomes that matter most to the business, and secures the support needed for successful development and deployment.",
    "crumbs": [
      "Laying the Foundation",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Before We Build</span>"
    ]
  },
  {
    "objectID": "02-before-we-build.html#understanding-technical-requirements-to-determine-feasibility",
    "href": "02-before-we-build.html#understanding-technical-requirements-to-determine-feasibility",
    "title": "2  Before We Build",
    "section": "2.5 Understanding Technical Requirements to Determine Feasibility",
    "text": "2.5 Understanding Technical Requirements to Determine Feasibility\nBefore building an ML system, it’s crucial to assess the technical requirements to determine the feasibility of the project. Defining these requirements upfront helps ensure that the solution is practical, achievable, and that the necessary resources are available.\n\n\n\n\n\n\nIt’s important to note that you will not have complete information on the requirements that follow. However, getting as much understanding upfront can help drive key decisions to mitigate risks, and set the foundation for a successful project early in the process.\n\n\n\nTechnical requirements span several areas, including data, algorithms, infrastructure, deployment, and scalability. Understanding these requirements early allows teams to identify potential challenges and make informed decisions regarding the scope and direction of the project.\n\n\n\n\n\n\nflowchart LR\n  subgraph ML[ML System]\n    direction BT\n    subgraph p0[Overall Technical Requirements]\n    end\n    subgraph p1[Data requirements]\n    end\n    subgraph p2[Algorithm requirements]\n    end\n    subgraph p3[Infrastructure requirements]\n    end\n    subgraph p4[Deployment requirements]\n    end\n    subgraph p5[Scale requirements]\n    end\n\n   p1 --&gt; p0\n   p2 --&gt; p0\n   p3 --&gt; p0\n   p4 --&gt; p0\n   p5 --&gt; p0\n  end\n\n\n\n\nFigure 2.3: Technical requirements span several areas, including data, algorithms, infrastructure, deployment, and scalability.\n\n\n\n\n\n\n\n\n\n\n\nData Requirements\n\n\n\n\n\nData is the foundation of any ML system, and understanding data requirements is vital for project success. This involves identifying data sources (e.g., internal databases, third-party APIs), assessing data quality (e.g., completeness, accuracy, consistency), and determining preprocessing needs, such as data cleaning, transformation, or augmentation. Ensuring that sufficient, high-quality data is available early in the project is crucial, as poor data quality can significantly impact model performance.\n\n\n\n\n\n\n\n\n\nAlgorithm Requirements\n\n\n\n\n\nChoosing the appropriate algorithm involves considering the problem type, the complexity of potential solutions, and the interpretability needs of stakeholders. Some problems may require simple, interpretable models like linear regression, while others may benefit from more complex models, such as deep learning. The algorithm choice also impacts computation time, required data, and the ability to provide explanations for predictions—all of which influence feasibility.\n\n\n\n\n\n\n\n\n\nInfrastructure Requirements\n\n\n\n\n\nML systems often demand significant computational resources for training and inference. Understanding infrastructure requirements includes determining compute needs (e.g., CPUs, GPUs), selecting appropriate software tools (e.g., TensorFlow, PyTorch), and evaluating cloud vs. on-premises options for scalability and cost-effectiveness. For projects with heavy resource demands, cloud services can provide a flexible solution, while smaller projects may be better suited to local infrastructure.\n\n\n\n\n\n\n\n\n\nDeployment Requirements\n\n\n\n\n\nDeployment considerations include the delivery method and the integration of the model within existing systems. This could involve setting up an API endpoint to deliver predictions, integrating the model into an application, or deploying the model on edge devices. A well-planned deployment pipeline is key to automating processes such as validation, testing, and deployment, ensuring that the model moves from development to production efficiently.\n\n\n\n\n\n\n\n\n\nScale Requirements\n\n\n\n\n\nIt’s important to understand the anticipated demand for the ML system and whether it will operate in a batch or real-time setting. For systems that require low latency (e.g., fraud detection), scalability must be a priority, ensuring the system can handle large numbers of requests without degrading performance. For batch processing tasks, the focus may be more on data throughput and the ability to handle large datasets effectively.\n\n\n\nOnce the technical requirements have been defined, teams must assess whether they have the necessary resources and expertise to proceed. Gaps may exist in areas such as data availability, technical skills, or infrastructure capabilities. Addressing these gaps might involve acquiring additional data, seeking third-party services, or upskilling team members to meet project needs. Making feasibility adjustments—such as narrowing the project scope, choosing simpler algorithms, or relying on cloud infrastructure to meet compute demands—can also ensure that the project remains viable within existing constraints.\nEvaluating technical requirements in these areas ensures that the ML system is both feasible and aligned with available resources. By addressing these aspects early, teams can make informed decisions, mitigate risks, and set the foundation for a successful project.",
    "crumbs": [
      "Laying the Foundation",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Before We Build</span>"
    ]
  },
  {
    "objectID": "02-before-we-build.html#recognizing-ml-system-development-as-an-iterative-process",
    "href": "02-before-we-build.html#recognizing-ml-system-development-as-an-iterative-process",
    "title": "2  Before We Build",
    "section": "2.6 Recognizing ML System Development as an Iterative Process",
    "text": "2.6 Recognizing ML System Development as an Iterative Process\nDeveloping an ML system is inherently an iterative process, involving continuous refinement, experimentation, and adaptation. Unlike traditional software development, where requirements and specifications are typically well-defined from the outset, ML systems evolve as they learn from data, integrate feedback, and adapt to changing business needs. Successful ML projects often require multiple rounds of model tuning, retraining, and adjustments to meet both technical and business objectives. Embracing this iterative nature helps ensure that the final solution is robust, scalable, and well-aligned with its intended purpose.\n\n\n\n\n\n\nflowchart LR\n  subgraph planning[Foundational Planning]\n    direction TB\n    subgraph p1[Understand the Business Problem]\n    end\n    subgraph p2[Determine ML Suitability]\n    end\n    subgraph p3[Define Performance Metrics]\n    end\n    subgraph p4[Understand the Potential Value]\n    end\n    subgraph p5[Understand Technical Requirements]\n    end\n  end\n\n  p1 --&gt; p2 --&gt; p3 --&gt; p4 --&gt; p5\n\n  planning --\"Iteration\"--&gt; building[ML System Development] --\"Iteration\"--&gt; planning\n\n\n\n\n\nFigure 2.4: Developing an ML system is inherently an iterative process, involving continuous refinement, experimentation, and adaptation as more information is learned through the planning and ML system development process.\n\n\n\n\n\nAs an ML project progresses, many of the topics discussed in this chapter—including performance metrics, the valuation of the project, technical requirements, and even the business problem itself—are likely to evolve. For instance:\n\nMetrics to Assess: Initial metrics defined to assess model performance or system efficiency may need to change if they are found to be insufficient, misleading, or if stakeholder priorities shift. For example, a metric like accuracy may become less useful if a focus on precision and recall better reflects the business goal.\nValuation of the Project: The estimated value of the project may evolve as new opportunities or limitations arise during development. The intended business impact, such as increasing customer engagement, may need revaluation if customer behaviors change or if new data sources reveal additional insights.\nTechnical Requirements: Technical needs such as data quality, infrastructure, or deployment pipelines often need adjustments based on model experiments, results, and feasibility assessments. Iterative model training may reveal gaps in data that require new sources or different preprocessing techniques, or identify infrastructure constraints that necessitate changes to compute resources.\nBusiness Problem: As the project progresses, the understanding of the business problem may change. Engaging with stakeholders and observing early results may lead to a deeper understanding of what needs to be solved, prompting refinements to the problem’s scope.\n\nThis iterative process requires finding a balance between being flexible enough to adapt to new information while avoiding uncontrolled changes, known as scope creep. Scope creep can derail a project by causing a continuous expansion of objectives, leading to wasted resources, delays, and reduced effectiveness. To manage this, teams should establish clear, well-documented milestones and revisit them periodically to assess if changes are necessary and justified. Any adjustments should be based on insights gained during iterations, with stakeholders involved in the decision-making process to ensure alignment.\nRecognizing ML system development as an iterative process allows teams to embrace change when needed while maintaining focus on the ultimate goals. It fosters continuous improvement, ensuring that the final system is effective, meets business objectives, and is resilient to the dynamic nature of data and business environments. By embracing iteration thoughtfully and managing scope effectively, ML practitioners can deliver solutions that are both impactful and sustainable.",
    "crumbs": [
      "Laying the Foundation",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Before We Build</span>"
    ]
  },
  {
    "objectID": "02-before-we-build.html#summary",
    "href": "02-before-we-build.html#summary",
    "title": "2  Before We Build",
    "section": "2.7 Summary",
    "text": "2.7 Summary\nThis chapter has outlined the crucial planning steps required before diving into the development of a machine learning (ML) system. Effective ML projects start with a deep understanding of the business problem, achieved by collaborating closely with stakeholders to ensure alignment between business needs and technical efforts. It is vital to evaluate whether the problem truly requires an ML solution, as not all issues benefit from the complexity and resource demands of machine learning. By avoiding unnecessary ML implementation, teams can focus resources on areas that provide meaningful impact.\nWe also explored the importance of defining performance metrics to assess both technical and business outcomes, as well as evaluating the potential value of the solution to determine if it justifies the investment. Technical requirements, such as data availability, infrastructure, and deployment needs, must be understood early to ensure feasibility and identify gaps that could impede progress. Finally, we recognized that ML system development is inherently iterative. Changes to metrics, requirements, or even the business problem are likely as the project progresses, requiring a careful balance between flexibility and avoiding scope creep.\nThe chapters that follow will equip you with the knowledge to understand and apply these foundational concepts, identify key decisions when designing an ML system, and effectively implement the tools and best practices required to build successful ML solutions. By building on this strong foundation, you will be better prepared to create ML systems that are impactful, adaptable, and well-aligned with organizational goals.\n\n\n\n\n\n\nFurther Reading\n\n\n\n\n\n\nDesigning ML-powered Software: This reading has a great section focused on the Machine Learning Canvas, a tool to structure the ML project, help to specify the core requirements, and answer the question – what do we want to achieve for the end-users of the predictive system?\n\n\n\n\nThe Machine Learning Canvas",
    "crumbs": [
      "Laying the Foundation",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Before We Build</span>"
    ]
  },
  {
    "objectID": "02-before-we-build.html#exercise",
    "href": "02-before-we-build.html#exercise",
    "title": "2  Before We Build",
    "section": "2.8 Exercise",
    "text": "2.8 Exercise\nConsider a scenario where a healthcare organization wants to build an ML system to improve patient outcomes by predicting hospital readmissions. To help guide this example, read the first three pages (sections 1-1.4) of this real-life case study of Mount Sinai Hospital in New York City. Use this example to help guide you in answering the following questions as thoroughly as the given information allows:\n\nStakeholder Engagement\n\nWho would the key stakeholders be for this project?\nWhat questions would you ask these stakeholders to ensure you understand the business problem?\nWhat assumptions might be uncovered during these discussions?\n\nEvaluating ML Suitability\n\nAssess whether ML is a suitable solution. What factors would you consider to determine if ML is appropriate for this problem?\nProvide an example of an alternative, non-ML approach that could be considered. What are the limitations of this approach compared to an ML approach?\n\nDefine Performance Metrics\n\nDefine three performance metrics for the ML system. Include at least one technical metric (e.g., accuracy), one system performance metric (e.g., latency), and one business metric (e.g., reduction in readmission rates).\nExplain why each of these metrics is important for evaluating the success of the ML system.\n\nUnderstanding Value and Feasibility\n\nWrite a paragraph that outlines the potential value of the ML system to the healthcare organization. Consider both tangible (e.g., cost savings) and intangible (e.g., improved patient satisfaction) benefits.\nList some key technical requirements that would be helpful to understand early on before developing the solution (e.g., data, infrastructure). What gaps might exist, and how would you address them?\n\nThe Iterative Process\n\nDescribe why the development of this ML system would be an iterative process. Provide an example of something that could change during development (e.g., a performance metric, a technical requirement) and how you would manage this change to avoid scope creep.\n\n\n\n\n\n\nMattson, Peter, Christine Cheng, Gregory Diamos, Cody Coleman, Paulius Micikevicius, David Patterson, Hanlin Tang, et al. 2020. “Mlperf Training Benchmark.” Proceedings of Machine Learning and Systems 2: 336–49.\n\n\nTolomei, Gabriele, Fabrizio Silvestri, Andrew Haines, and Mounia Lalmas. 2017. “Interpretable Predictions of Tree-Based Ensembles via Actionable Feature Tweaking.” In Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, 465–74.\n\n\nVemulapalli, Gopichand. 2023. “Operationalizing Machine Learning Best Practices for Scalable Production Deployments.” International Machine Learning Journal and Computer Engineering 6 (6): 1–21.",
    "crumbs": [
      "Laying the Foundation",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Before We Build</span>"
    ]
  },
  {
    "objectID": "02-before-we-build.html#footnotes",
    "href": "02-before-we-build.html#footnotes",
    "title": "2  Before We Build",
    "section": "",
    "text": "Latency is well-covered in Tolomei et al. (2017), which discusses latency optimization for ML infrastructure.↩︎\nMattson et al. (2020) explores techniques for optimizing throughput in production ML systems.↩︎\nVemulapalli (2023) discusses some machine learning best practices for scalable production deployments.↩︎",
    "crumbs": [
      "Laying the Foundation",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Before We Build</span>"
    ]
  },
  {
    "objectID": "03-dataops-role.html",
    "href": "03-dataops-role.html",
    "title": "3  The Role of DataOps",
    "section": "",
    "text": "3.1 Data Ingestion\nDataOps, short for Data Operations, is a collaborative and agile approach to designing, implementing, and managing data workflows. It is an essential pillar within the MLOps lifecycle, ensuring that data — the lifeblood of any machine learning system — is efficiently, reliably, and securely delivered to support model training and inference. While MLOps focuses on the end-to-end process of deploying and maintaining machine learning systems, DataOps hones in on the data-specific aspects, addressing the challenges of data management, processing, and quality control. By embedding DataOps practices into the MLOps framework, organizations can build scalable, reliable ML systems that deliver consistent and meaningful results.\nThe primary goals of DataOps are to ensure that data pipelines are efficient, reliable, and produce high-quality data for machine learning workflows. These goals are achieved through robust processes for:\nTogether, these core components form the backbone of DataOps, enabling teams to handle growing data volumes, ensure compliance with regulations, and adapt to evolving business needs. By establishing a strong DataOps foundation, organizations can mitigate risks like data inconsistencies, inefficiencies, and errors, ultimately paving the way for successful ML systems.\nThis chapter will discuss each of these core components and then the next chapter will start giving you the tools and patterns used to implement these components.\nData ingestion involves gathering and importing data from multiple sources into a system for storage, processing, and use in machine ML workflows. The nature of the data sources, their structure, and the method of ingestion play a significant role in determining the efficiency and reliability of the ML system. In this section, we will explore the fundamental differences between data sources, when to use them, and their advantages and disadvantages. We will also compare batch and streaming ingestion methods and their suitability for different scenarios.",
    "crumbs": [
      "DataOps",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>The Role of DataOps</span>"
    ]
  },
  {
    "objectID": "03-dataops-role.html#data-ingestion",
    "href": "03-dataops-role.html#data-ingestion",
    "title": "3  The Role of DataOps",
    "section": "",
    "text": "Understanding Data Sources\nData sources provide the foundation for machine learning (ML) workflows, and the choice of data source significantly impacts the design and effectiveness of the ML system. Each type of data source has unique characteristics, use cases, advantages, and limitations. Understanding these aspects is essential for building an efficient and scalable data ingestion pipeline.\n\n\n\n\n\n\nDatabases\n\n\n\n\n\nDatabases are structured systems designed to store, manage, and retrieve data efficiently. They are commonly used for transactional data, such as customer records, sales transactions, or financial ledgers.\n\nWhen to Use: Databases are ideal when data is frequently updated, needs to be queried precisely, or must maintain high consistency. For example, an e-commerce application may use a relational database to track user purchases and manage inventory levels. NoSQL databases are better suited for dynamic or semi-structured data, such as user-generated content or real-time event logs.\nAdvantages:\n\nRelational Databases (e.g., MySQL, PostgreSQL): Ensure data integrity through schema enforcement and strong consistency models.\nNoSQL Databases (e.g., MongoDB, DynamoDB): Offer flexibility for semi-structured or unstructured data and scale horizontally to handle growing data volumes.\n\nDisadvantages:\n\nRelational databases can struggle with scalability in high-throughput applications.\nNoSQL databases may not provide strong transactional guarantees, which could be problematic for certain use cases.\n\n\n\n\n\n\n\n\n\n\n\nAPIs\n\n\n\n\n\nAPIs (Application Programming Interfaces) enable programmatic access to data from external systems or services. They are often used to fetch dynamic data, such as weather updates, financial market data, or social media interactions.\n\nWhen to Use: APIs are most useful when the data is maintained externally and needs to be accessed on-demand. For example, a stock-trading platform might fetch real-time price updates through a financial market API.\nAdvantages:\n\nProvide a standardized way to access external data.\nAllow flexible querying of specific fields or data ranges.\nEnable real-time or near-real-time access to dynamic data.\n\nDisadvantages:\n\nAPI access can be rate-limited, introducing potential delays in data collection.\nDependence on external systems may lead to availability or latency issues if the API provider experiences downtime.\nOften requires robust error handling and retries to ensure reliability.\n\n\n\n\n\n\n\n\n\n\n\nData Lakes\n\n\n\n\n\nData lakes serve as centralized repositories for storing large volumes of raw, unstructured, and semi-structured data. They are designed to handle diverse datasets, such as logs, multimedia files, and IoT sensor readings.\n\nWhen to Use: Data lakes are ideal for big data, where the organization needs to store vast amounts of heterogeneous data for future exploration or processing. For instance, a media company might use a data lake to aggregate clickstream logs, user profiles, and video content metadata.\nAdvantages:\n\nEnable storage of massive datasets at a low cost.\nProvide flexibility for processing data in various ways, such as using batch or streaming pipelines.\nAllow analysts and data scientists to explore raw data without predefined schemas.\n\nDisadvantages:\n\nLack of enforced schema can lead to inconsistent data organization, often referred to as a “data swamp.”\nSlower access times compared to structured systems, especially for specific queries.\nRequire strong governance and metadata management to maintain data discoverability and usability.\n\n\n\n\n\n\n\n\n\n\n\nReal-Time Data Streams\n\n\n\n\n\nReal-time data streams consist of continuous flows of data generated by sources like IoT devices, user interactions, or event-driven systems. They are commonly used for applications requiring immediate insights, such as fraud detection, predictive maintenance, or live recommendation engines.\n\nWhen to Use: Real-time streams are essential when time sensitivity is critical. For example, an autonomous vehicle must process sensor data streams in real-time to make split-second decisions.\nAdvantages:\n\nProvide up-to-date information for time-sensitive applications.\nSupport dynamic updating of ML models and dashboards in near real-time.\nEnable responsiveness to events as they occur, improving decision-making agility.\n\nDisadvantages:\n\nRequire significant infrastructure to support continuous ingestion and processing.\nCan be complex to implement and maintain, especially for low-latency systems.\nHigher resource costs compared to batch processing due to the always-on nature of real-time systems.\n\n\n\n\n\nSelecting the right data source depends on the specific requirements of the ML system and its intended use case. For instance:\n\nUse databases when precise, structured data is needed for queries and frequent updates are expected.\nLeverage APIs when data resides in external systems and must be fetched dynamically or on demand.\nOpt for data lakes when dealing with vast amounts of heterogeneous data that may be analyzed in diverse ways over time.\nImplement real-time data streams when time-sensitive insights or rapid responses are required.\n\nBy understanding the fundamental differences and trade-offs between data sources, ML teams can design data ingestion pipelines tailored to their needs, ensuring efficient, reliable, and scalable workflows.\n\n\n\n\n\n\nYou don’t always have a choice!\n\n\n\n\n\nWhile choosing the ideal data source is important, you don’t always have a choice. In many cases, the data source is determined by external constraints—such as an organization’s existing infrastructure, third-party providers, or legacy systems. For example, if a company’s customer data is only available through a legacy database, you must work with that database, regardless of its limitations. Similarly, when pulling weather or stock market data, you may be limited to an API provided by the service provider, even if it introduces latency or rate limits. A critical part of data ingestion is recognizing these constraints early and designing the pipeline to work efficiently with the available data source.\n\n\n\n\n\nBatch vs. Streaming Ingestion\nIn the previous section, we discussed the idea of real-time data streams. Let’s discuss this a little more. The method of data ingestion — batch or streaming — determines how data flows into the ML system. Each method has distinct characteristics suited to specific needs.\nBatch ingestion collects data in chunks or intervals, such as daily, weekly, monthly, etc. This method is ideal for scenarios where real-time data is not critical, and the focus is on processing large volumes of data efficiently. For example, an e-commerce company may use batch ingestion to aggregate and analyze customer orders from the previous day. The simplicity of batch ingestion makes it easier to implement, and it is more cost-effective since it requires fewer continuous resources. However, its periodic nature introduces latency, which may be unacceptable in time-sensitive applications.\n\n\n\n\n\n\nflowchart LR\n    subgraph Monday\n      direction TB\n      ob1(observation) --&gt; id1[(Data source)]\n      ob2(observation) --&gt; id1\n      ob3(observation) --&gt; id1\n    end\n    subgraph Tuesday\n      direction TB\n      ob4(observation) --&gt; id2[(Data source)]\n      ob5(observation) --&gt; id2\n      ob6(observation) --&gt; id2\n    end\n    subgraph Wednesday\n      direction TB\n      ob7(observation) --&gt; id3[(Data source)]\n      ob8(observation) --&gt; id3\n      ob9(observation) --&gt; id3\n    end\n    processing[Batch data processing]\n    downstream[Downstream ML system processes]\n\n    Monday --&gt; processing\n    Tuesday --&gt; processing\n    Wednesday --&gt; processing\n    processing --&gt; downstream\n\n\n\n\nFigure 3.2: Batch processing collects data in chunks or intervals, such as on a daily cadence. In this example, every day a batch process is ran where data is ingested from its relevant data sources, processed and fed to downstream processes in the ML system.\n\n\n\n\n\nStreaming ingestion, by contrast, involves the continuous collection of data as it becomes available. This method is essential for use cases requiring real-time insights, such as fraud detection systems or live recommendation engines. Streaming allows systems to react immediately to new data, providing up-to-date results. However, this approach introduces higher complexity and infrastructure costs, as systems must be designed for low-latency processing and scalability. For instance, a financial institution detecting fraudulent transactions in real-time must ingest and process data streams from payment systems within milliseconds.\n\n\n\n\n\n\nflowchart LR\n    ob1(observation) --&gt; processing[Real-time data processing]\n    ob2(observation) --&gt; processing\n    ob3(observation) --&gt; processing\n    ob4(observation) --&gt; processing\n    ob5(observation) --&gt; processing\n\n    processing --&gt; downstream[Downstream ML system processes]\n    processing --&gt; id3[(Database)]\n\n\n\n\n\nFigure 3.3: Streaming, or real-time, systems process each observation as it comes in and then feeds that data to downstream ML systems and, simoultaneously, to a database for longterm storage.\n\n\n\n\n\nIn practice, organizations often adopt a hybrid approach, using batch ingestion for historical data and streaming ingestion for real-time updates. For example, a retail company may analyze historical sales trends using batch data while simultaneously processing live customer behavior data through streams. This strategy leverages the strengths of both methods, ensuring comprehensive and timely insights for ML systems.\n\n\nExamples\nBelow are three scenarios describing machine learning systems that utilize different types of data sources and require varying ingestion methods. For each scenario:\n\nIdentify the data source(s) (e.g., database, API, real-time stream, data lake) that are being used, or that you believe should be used.\nDetermine whether the ingestion process should be batch, streaming, or a hybrid approach.\nJustify your choice of ingestion method by considering the system’s requirements for latency, data volume, and frequency of updates.\n\n\n\n\n\n\n\nScenarios\n\n\n\n\n\nScenario 1: Predictive Maintenance for Industrial Machines\nA manufacturing company is building an ML system to predict when machines on the production line will require maintenance to avoid unplanned downtime. The system collects data from IoT sensors installed on the machines. These sensors continuously send information such as temperature, vibration levels, and pressure readings. The ML system needs to analyze this incoming data in real time to provide timely predictions and alerts for potential breakdowns.\nScenario 2: Customer Segmentation for a Retail Business\nA retail company wants to build an ML system to segment customers based on their purchase history, demographic data, and online behavior. The data comes from two sources: a relational database that stores historical transaction data and an API that provides weekly updates on recent marketing campaign responses. The system generates segmentation insights monthly for marketing teams to design personalized campaigns.\nScenario 3: Fraud Detection for Financial Transactions\nA bank is developing an ML system to detect fraudulent transactions. The system receives data from real-time transaction streams as customers make payments using credit cards. The ML model must analyze each transaction immediately to flag suspicious activity and trigger appropriate alerts. Historical data stored in a data lake is also used periodically to retrain the fraud detection model.",
    "crumbs": [
      "DataOps",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>The Role of DataOps</span>"
    ]
  },
  {
    "objectID": "03-dataops-role.html#data-processing",
    "href": "03-dataops-role.html#data-processing",
    "title": "3  The Role of DataOps",
    "section": "3.2 Data Processing",
    "text": "3.2 Data Processing\nData processing is a cornerstone of machine learning workflows, transforming raw, messy, or unstructured data into a clean, structured, and feature-rich format that models can effectively use. The quality and reliability of this step directly impact the performance of the machine learning system, making it one of the most critical stages in the pipeline.\n\n”Poor data quality is Enemy #1 to the widespread, profitable use of machine learning, and for this reason, the growth of machine learning increases the importance of data cleansing and preparation. The quality demands of machine learning are steep, and bad data can backfire twice – first when training predictive models and second in the new data used by that model to inform future decisions.”1\n\nIn practice, data processing involves several interrelated tasks. First, data sampling ensures that the volume of data being processed is manageable while maintaining representativeness. Next, data quality issues—such as missing values, inconsistencies, and outliers—are addressed through cleaning to ensure that the data is accurate and usable. Feature engineering comes next, where meaningful features are crafted from the raw data to capture relevant patterns and insights for the model. Finally, data leakage, a subtle yet potentially devastating issue, must be carefully avoided to ensure the integrity and generalizability of the model.\nThis section will explore these topics in detail, emphasizing their role in building reliable and scalable ML systems. By the end, you will understand the importance of thoughtful data processing and its role in creating robust machine learning pipelines.\n\nData Sampling\nData sampling is a crucial step in the data processing pipeline, particularly when working with large datasets. In many real-world scenarios, it can be infeasible or inefficient to process all available data due to computational constraints, resource limitations, or time considerations. Sampling allows data practitioners to work with a manageable subset of the data that accurately represents the overall population, ensuring efficient processing without compromising model performance or insights.\n\nWhy Sampling is Necessary\nModern machine learning systems often have access to massive datasets, ranging from millions of customer transactions to terabytes of sensor data from IoT devices. While having more data is generally beneficial, processing all of it can be resource-intensive and unnecessary, especially during exploratory data analysis or initial model development. Sampling enables practitioners to:\n\nReduce computational load, making processing faster and less expensive.\nTest and prototype pipelines or algorithms on smaller, representative datasets.\nAvoid introducing bias or errors due to overfitting large, redundant data.\n\nFor example, an organization analyzing customer purchase behavior across millions of transactions might sample a subset of data to identify initial trends or test new features before scaling up to the entire dataset.\n\n\nTypes of Sampling\nTwo primary sampling methods are commonly used in data processing: nonprobability sampling and probability sampling. Each has specific use cases, advantages, and limitations.\n\n\n\n\n\n\nNonprobability Sampling\n\n\n\n\n\nNonprobability sampling involves selecting data points based on specific criteria or convenience rather than assigning each data point a known chance of inclusion. This method is often used when quick insights or targeted analysis is needed, even if the results may not generalize to the entire population. Some examples include:\n\nConvenience sampling: Samples of data are selected based on their availability. This sampling method is popular because, well, it’s convenient.\nSnowball sampling: Future samples are selected based on existing samples. For example, to scrape legitimate Twitter accounts without having access to Twitter databases, you start with a small number of accounts, then you scrape all the accounts they follow, and so on.\nJudgment sampling: Experts decide what samples to include.\nQuota sampling: You select samples based on quotas for certain slices of data without any randomization. For example, when doing a survey, you might want 100 responses from each of the age groups: under 30 years old, between 30 and 60 years old, and above 60 years old, regardless of the actual age distribution.\n\nThe samples selected by nonprobability criteria are not representative of the real-world data and therefore are riddled with selection biases.(Heckman 2013) Because of these biases, you might think that it’s a bad idea to select data to train ML models using this family of sampling methods. You’re right. Unfortunately, in many cases, the selection of data for ML models is still driven by convenience.\nOne example of these cases is language modeling. Language models are often trained not with data that is representative of all possible texts but with data that can be easily collected—Wikipedia, Common Crawl, Reddit.\nAnother example is data for training self-driving cars. Initially, data collected for self-driving cars came largely from two areas: Phoenix, Arizona (because of its lax regulations), and the Bay Area in California (because many companies that build self-driving cars are located here). Both areas have generally sunny weather. In 2016, Waymo expanded its operations to Kirkland, Washington, specially for Kirkland’s rainy weather,(Lerman February 3, 2016) but there’s still a lot more self-driving car data for sunny weather than for rainy or snowy weather.\nNonprobability sampling can be a quick and easy way to gather your initial data to get your project off the ground. However, for reliable models, you want to use probability-based sampling if possible.\n\n\n\n\n\n\n\n\n\nProbability sampling\n\n\n\n\n\nProbability sampling ensures that every data point in the population has a known and non-zero chance of being included in the sample. This method is ideal for obtaining a representative subset of data and minimizing selection bias. Several subtypes of probability sampling exist, including:\n\nSimple Random Sampling: Every data point in the population has an equal chance of being selected. Often used when the dataset is large and homogeneous, such as selecting random customer records.\nStratified Sampling: The population is divided into distinct groups (strata), and samples are drawn proportionally from each group to ensure representation. This is often used in customer churn analysis to ensure proportional representation of customer demographics (e.g., age groups, regions).\nWeighted Sampling: Data points are assigned weights based on their importance or relevance, and sampling is performed based on these weights. Commonly used in recommendation systems to oversample high-value customers or popular products.\nReservoir Sampling: A fixed-size random sample is drawn from a stream of data, ensuring every item has an equal probability of being included. Commonly used for sampling large, continuous data streams like website clickstream logs in real-time.\nImportance Sampling: Data points are sampled based on their likelihood of influencing the model or target variable, focusing on high-impact points. Used in rare-event modeling, such as fraud detection, where fraudulent transactions are more heavily sampled.\n\n\n\n\nThe choice between sampling approaches depends on the goals and context of the analysis. In some cases, a hybrid approach may be appropriate, combining probability and nonprobability sampling. For example, a regional utility company wants to predict energy demand to optimize power generation and reduce operational costs. The dataset includes hourly energy consumption data from residential, commercial, and industrial customers across several regions, along with weather data and regional economic indicators. A hybrid approach such as the following may be required:\n\nProbability Sampling (Stratified Sampling for Regional Representation): The team uses stratified sampling to ensure that data is proportionally drawn from different regions (e.g., urban, suburban, rural) and customer types (residential, commercial, industrial). This ensures that the dataset is balanced and representative of the diverse energy consumption patterns across the utility’s coverage area.\n\nReason: Stratified sampling ensures that the model generalizes well across all regions and customer categories, reflecting realistic energy usage patterns.\n\nNonprobability Sampling (Convenience Sampling of Weather Data): The utility supplements the dataset with convenience sampling of weather data, pulling information from readily available weather stations rather than ensuring even geographic coverage. The data includes temperature, humidity, and wind speed for regions with accessible sensors.\n\nReason: Weather data is crucial for understanding energy demand (e.g., high temperatures lead to increased air conditioning use), but some rural areas lack weather stations. Convenience sampling allows the utility to quickly incorporate available weather data without delaying the project.\n\n\n\n\n\nData Quality\nData quality is a foundational pillar of any successful machine learning (ML) system. High-quality data ensures that the insights derived from the system are accurate, reliable, and actionable, while poor data quality can lead to flawed models, wasted resources, and misguided decisions. In the context of machine learning, data quality is about more than just correctness—it encompasses the accuracy, completeness, consistency, and relevance of the data being used.\nRaw data is often messy and unstructured, riddled with issues such as missing values, duplicates, inconsistencies, and outliers. These imperfections, if left unaddressed, can skew results, reduce model performance, and compromise the integrity of the ML system. Cleaning and validating data is, therefore, a critical step in the pipeline, ensuring that the inputs provided to models are trustworthy and representative of real-world scenarios.\nThis section explores the most common data quality challenges faced in ML workflows, their potential impacts, and the techniques used to address them. From handling missing data to removing duplicates and managing outliers, you’ll learn how to prepare data that meets the standards required for robust and reliable ML systems. By understanding and prioritizing data quality, practitioners can lay the groundwork for models that perform well not just in development but also in production, where the stakes are higher.\n\nCommon Data Quality Concerns\nData quality is the foundation of reliable and effective machine learning systems. Poor-quality data—riddled with missing values, inconsistencies, duplicates, outliers, or irrelevant features—can lead to biased models, inaccurate predictions, and flawed insights. Addressing these challenges requires a deep understanding of their causes, impacts, and resolutions. In this section, we’ll explore these issues in detail, using examples to illustrate their real-world relevance and techniques to resolve them.\n\n\n\n\n\n\nMissing data\n\n\n\n\n\nWhat it is: Missing data occurs when some observations lack values in one or more features. This issue can arise due to incomplete data collection processes, technical issues, or privacy restrictions. Missing data is often classified into three categories:\n\nMissing Completely at Random (MCAR): The absence of data is entirely independent of other variables.\nMissing at Random (MAR): Missingness is related to other observed variables but not the missing variable itself.\nMissing Not at Random (MNAR): Missingness is directly related to the value of the missing variable.\n\nExample: A hospital dataset tracking patient health outcomes might have missing values for “blood pressure” or “heart rate” because some patients did not complete their check-ups.\nImpact:\n\nMissing data can introduce bias, especially if the missingness is not random. For example, if patients with severe health issues are more likely to skip check-ups, the dataset will underrepresent critical cases, skewing the model.\nCertain machine learning algorithms, such as logistic regression, cannot handle missing values directly, leading to errors in training.\n\nTechniques:\n\nImputation: Replace missing values with statistical estimates (e.g., mean, median) or model-based predictions. For instance, you might fill in missing blood pressure values using averages grouped by age or gender.\nRemoval: Discard rows or columns with significant missingness if they don’t impact the overall dataset integrity. For example, dropping patients with multiple missing attributes may preserve data quality.\nDomain-Specific Solutions: Work with domain experts to infer missing values or augment the dataset with external data sources. For example, use past medical records to estimate missing patient data.\n\n\n\n\n\n\n\n\n\n\nInconsistent data\n\n\n\n\n\nWhat it is: Inconsistent data refers to variations in formatting, units, or categorizations across records. These inconsistencies often occur when datasets from different sources are merged or when collection standards are not enforced.\nExample: A global sales dataset might include prices recorded in both USD and EUR without indicating the currency, leading to ambiguity.\nImpact:\n\nPreprocessing pipelines may fail if they expect consistent inputs, such as a single currency or uniform date format.\nInconsistent data can lead to incorrect feature transformations, misinterpretation of model results, and reduced accuracy.\n\nTechniques:\n\nStandardization: Convert data into consistent formats before processing. For example, ensure all prices are converted to USD using the prevailing exchange rate.\nValidation Rules: Set up automated checks to enforce consistency, such as verifying that all date fields follow a standard format (e.g., YYYY-MM-DD).\nData Cleaning Scripts: Automate the process of detecting and resolving inconsistencies. For example, scripts can identify and reconcile category mismatches like “NYC” and “New York City.”\n\n\n\n\n\n\n\n\n\n\nDuplicate data\n\n\n\n\n\nWhat it is: Duplicate data consists of redundant records that represent the same observation multiple times. This issue often arises during data integration or repeated logging.\nExample: A customer database might have two identical entries for a single customer due to an error during data migration.\nImpact:\n\nDuplicates can inflate metrics like customer counts or revenue totals, leading to incorrect conclusions.\nThey bias models by overrepresenting certain patterns, making the model less generalizable.\n\nTechniques:\n\nDeduplication: Identify and remove duplicates using unique identifiers, such as email addresses or order IDs. In the absence of such identifiers, similarity measures like fuzzy matching can help detect duplicates.\nMerge Strategies: For partially overlapping duplicates, combine the relevant details into a single record. For example, consolidate multiple entries for a customer into one record with the most complete information.\nPreventative Measures: Enforce data integrity constraints during collection to avoid duplicates. For instance, ensure that customer IDs are unique within the database.\n\n\n\n\n\n\n\n\n\n\nOutiers\n\n\n\n\n\nWhat it is: Outliers are data points that deviate significantly from the rest of the dataset. They may represent errors, rare events, or natural variability.\nExample: A dataset tracking daily transactions might include a single record for a $1,000,000 purchase, which could be an error or a legitimate bulk order.\nImpact:\n\nOutliers can distort statistical measures such as mean and variance, leading to unreliable preprocessing steps like feature scaling.\nAlgorithms like linear regression and k-means clustering are highly sensitive to outliers, which can result in poor model performance.\n\nTechniques:\n\nOutlier Detection: Use statistical methods like interquartile range (IQR) or z-scores to identify anomalous points. For example, flag transactions that exceed three standard deviations from the mean.\nCapping or Truncation: Limit extreme values to predefined thresholds, such as capping all sales amounts above the 95th percentile.\nDomain Expertise: Determine whether outliers are valid or erroneous. For instance, consult sales teams to confirm whether a high transaction value is legitimate.\n\n\n\n\n\n\n\n\n\n\nRedundant or irrelevant data\n\n\n\n\n\nWhat it is: Redundant data includes features that duplicate information, while irrelevant data consists of variables that do not contribute meaningfully to the predictive task.\nExample: A dataset might include both “total purchase amount” and “average purchase amount per transaction,” where one feature can be derived from the other.\nImpact:\n\nRedundant or irrelevant features add noise to the dataset, increasing training time and risking overfitting.\nIrrelevant features can obscure meaningful patterns, reducing model interpretability and accuracy.\n\nTechniques:\n\nFeature Selection: Use statistical tests or model-based methods to identify and retain the most relevant features. For example, mutual information scores can indicate which variables are most predictive of the target variable.\nDimensionality Reduction: Combine redundant features into simpler representations using techniques like PCA. For instance, reduce high-dimensional text features into key topics or sentiment scores.\nExpert Review: Consult domain experts to exclude features that are not relevant. For example, remove “zip code” from a churn prediction model if it does not influence customer behavior.\n\n\n\n\nHigh-quality data is essential for robust and reliable machine learning systems. By addressing common issues such as missing values, inconsistencies, duplicates, outliers, and irrelevant features, practitioners can ensure that their datasets are clean, consistent, and ready for analysis. Each of these challenges can be mitigated through careful planning, appropriate techniques, and collaboration with domain experts, resulting in models that deliver meaningful and trustworthy results.\n\n\nImportance of Domain Knowledge\nDomain knowledge is essential when addressing data quality concerns in machine learning systems. While technical tools and methodologies provide the means to process and clean data, domain knowledge ensures that these actions are contextually informed and relevant to the problem at hand. Without a thorough understanding of the domain, practitioners risk misinterpreting data issues, applying inappropriate fixes, or overlooking critical nuances that could significantly impact the performance and reliability of the ML system.\n\nContextualizing Data Issues\nEach data quality issue—whether missing data, inconsistencies, duplicates, outliers, or irrelevant features—has unique implications that are best understood with domain expertise. For example, in healthcare datasets, missing values for key features like patient blood pressure or glucose levels might indicate incomplete check-ups or testing, but the severity of these gaps can only be properly assessed by medical professionals. Similarly, in financial datasets, an unusually large transaction might initially appear as an outlier, but domain experts can determine whether it reflects a legitimate bulk order or a fraudulent activity. By contextualizing these issues, domain experts help ensure that data quality interventions address the root causes without compromising the integrity of the dataset.\n\n\nGuiding Data Quality Strategies\nDomain knowledge informs the strategies used to resolve data quality issues. For instance:\n\nWhen dealing with inconsistent data, such as variations in currency or measurement units, domain experts can recommend appropriate standardization practices, such as converting all sales figures to a base currency like USD.\nFor duplicate data, they can help identify unique identifiers, such as customer IDs or transaction numbers, to accurately merge or remove records without losing valuable information.\nIn addressing redundant or irrelevant data, domain knowledge is invaluable for determining which features are meaningful to the predictive task and which can be safely excluded.\n\nThese insights ensure that data cleaning and preprocessing efforts enhance the dataset’s utility for machine learning without introducing new biases or inaccuracies.\n\n\nEnsuring Alignment with Business Objectives\nAddressing data quality issues is not just a technical task; it is also about ensuring that the cleaned dataset aligns with the organization’s goals and priorities. Domain experts bridge the gap between raw data and business needs by defining what “quality” means in the context of the problem. For example:\n\nIn a customer churn prediction model, domain experts might emphasize the importance of including recent complaint data, even if it contains some inconsistencies, because of its strong predictive value.\nIn an e-commerce recommendation system, domain experts might prioritize accurate timestamp data for user interactions, as it is critical for understanding seasonal trends and customer behavior.\n\nBy incorporating domain knowledge, ML practitioners can tailor their data quality efforts to deliver insights and predictions that drive meaningful business outcomes.\n\n\n\n\nFeature Engineering\nFeature engineering is the process of transforming raw data into meaningful inputs that enhance a machine learning model’s performance. It involves creating, modifying, or combining features to highlight relevant patterns or relationships that the model can learn from effectively. This process is critical to the success of machine learning systems, as the quality and relevance of features often have a more significant impact on model performance than the choice of algorithm.\n\nThe Role of Feature Engineering\nAt its core, feature engineering serves to bridge the gap between raw data and a machine learning model’s input requirements. Raw data, while abundant, often contains noise, irrelevant details, or complexities that hinder model performance. Feature engineering transforms this raw data into a more structured, interpretable, and informative format, making it easier for the model to identify patterns and relationships.\n\n\n\n\n\n\nflowchart LR\n    data[(Raw Data)] --&gt; feat{Feature&lt;br&gt;Engineering}\n    feat --&gt; mldata[(Model Input&lt;br&gt;Requirements)]\n    mldata --&gt; ml[Model Building]\n\n\n\n\n\nFigure 3.4: Feature engineering serves to bridge the gap between raw data and a machine learning model’s input requirements.\n\n\n\n\n\nFor example:\n\nIn a customer churn prediction model, raw transactional data might be transformed into features like “average purchase frequency” or “days since last purchase” to better capture customer behavior.\nIn a fraud detection system, transaction logs might be engineered into features such as “average transaction size during peak hours” or “number of transactions per location.”\n\nThrough such transformations, feature engineering ensures that the model focuses on the most relevant aspects of the data, improving accuracy, interpretability, and robustness.\n\n\nHow It Varies by Data and Algorithms\nThe approach to feature engineering depends significantly on the type of data being used and the algorithms employed. Different data structures and machine learning models require tailored techniques to maximize their effectiveness.\n\n\n\n\n\n\nStructured Data\n\n\n\n\n\nIn datasets with a tabular format, common techniques include:\n\nAggregations: Summarizing data through metrics like mean, median, or count (e.g., average monthly spending).\nScaling: Normalizing numerical values to ensure features are on a comparable scale, especially for distance-based models like k-nearest neighbors.\nEncoding Categorical Variables: Converting non-numeric categories into numerical representations using methods like one-hot encoding or label encoding.\n\n\n\n\n\n\n\n\n\n\nText Data\n\n\n\n\n\nUnstructured text requires specialized transformations to capture linguistic patterns and meaning:\n\nTokenization: Splitting text into smaller units such as words or phrases.\nEmbeddings: Using techniques like word2vec or BERT to map text into dense vector representations that encode semantic meaning.\nSentiment Scoring: Assigning scores to text to quantify sentiment (e.g., positive, neutral, negative) for tasks like opinion analysis.\n\n\n\n\n\n\n\n\n\n\nTime-Series Data\n\n\n\n\n\nSequential data often benefits from transformations that capture temporal relationships:\n\nLag Features: Including past values of a variable to predict future trends.\nRolling Averages: Smoothing fluctuations by averaging values over defined time windows.\nFourier Transformations: Extracting cyclical patterns from periodic data.\n\n\n\n\n\n\n\n\n\n\nAlgorithm-Specific Considerations\n\n\n\n\n\n\nTree-Based Models (e.g., Random Forests, XGBoost): These models handle raw and categorical data well, requiring minimal preprocessing but can benefit from carefully engineered aggregations or interaction terms.\nNeural Networks: These models excel with raw data when provided in a suitable format, such as embeddings for text or image pixels. However, they require data to be vectorized, normalized, and often augmented for robust learning.\n\n\n\n\nThe specifics of feature engineering techniques vary widely across domains and are outside the detailed focus of this book. However, it is crucial to recognize that the final output of feature engineering should structure data in a format suitable for model consumption. Depending on the use case, this could mean:\n\nTabular Data: A matrix where rows represent samples and columns represent features.\nSequential Data: Structured sequences (e.g., time-series or text) prepared for models like recurrent neural networks.\nVectorized Data: Dense or sparse vectors that encode the features, suitable for algorithms like support vector machines or neural networks.\n\n\n\n\n\n\n\nFeature engineering resources\n\n\n\n\n\nTo delve deeper into specific feature engineering practices, the following books and resources are highly recommended:\n\nFeature Engineering for Machine Learning: Principles and Techniques for Data Scientists (Zheng and Casari 2018): This book provides a comprehensive overview of feature engineering techniques across different data types, with practical advice and examples.\nFeature Engineering and Selection: A Practical Approach for Predictive Models (Kuhn and Johnson 2019): This resource delves into advanced feature selection methods and preprocessing techniques, with a focus on model performance improvement.\nHands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow (Géron 2022): Chapter 2 of this book covers essential data preprocessing and feature engineering steps with Python code examples.\nOnline Tutorials and Blogs:\n\nKaggle’s Feature Engineering Course: A free course offering hands-on practice with feature engineering in real-world datasets.\nTowards Data Science Feature Engineering Articles: A collection of articles covering practical and innovative feature engineering techniques.\n\nPapers with Code:\n\nFeature Engineering Papers: A repository linking research papers on feature engineering to practical code implementations.\n\n\nBy exploring these resources, practitioners can gain a deeper understanding of feature engineering techniques tailored to their specific data types and algorithms, ultimately building more effective machine learning systems.\n\n\n\n\n\n\nData Leakage\nData leakage occurs when information that would not be available during real-world inference inadvertently influences a machine learning model during training. This typically happens when features derived from the target variable or post-event information are included in the training data, leading to artificially inflated performance metrics.\n\n\n\n\n\n\nExamples of data leakage\n\n\n\n\n\n\nIncluding Future Information in Training Data\n\nScenario: A fraud detection model is designed to predict whether a transaction is fraudulent. The training dataset includes a feature indicating whether the transaction was flagged as fraud by manual review.\nWhy It’s Data Leakage: The feature directly correlates with the target variable but would not be available during real-time prediction. Including it inflates the model’s performance during training.\nImpact in MLOps: In production, the absence of this feature would cause the model’s performance to drop significantly, leading to incorrect fraud predictions and operational inefficiencies.\n\nImproper Data Splitting in Time-Series Analysis\n\nScenario: A time-series model is trained to predict stock prices based on historical data. The dataset is split randomly into training and test sets without considering the temporal sequence.\nWhy It’s Data Leakage: Future stock prices (from the test set) could influence training, as the random split allows information from the future to inform past predictions.\nImpact in MLOps: When deployed in production, the model fails to replicate its test performance because it can no longer rely on future data. This leads to inaccurate forecasting and potential financial losses.\n\nUsing Post-Event Data in Customer Churn Prediction\n\nScenario: A customer churn prediction model includes features like “number of customer support calls in the last month.” However, this feature is calculated retrospectively after the customer has already decided to leave.\nWhy It’s Data Leakage: This feature is only available after the target event (churn) has occurred and would not be accessible during inference for active customers.\nImpact in MLOps: During deployment, the model’s predictions are unreliable because it cannot use post-event data, resulting in flawed retention strategies and wasted resources.\n\n\n\n\n\n\nWhy Data Leakage is a Critical Issue in MLOps\nIn MLOps, where the goal is to create scalable, reliable, and production-ready machine learning systems, data leakage poses significant challenges:\n\nDecreased Model Generalizability: Models trained with leaked data perform exceptionally well during testing but fail to generalize to unseen production data, undermining their real-world utility. In MLOps, this can result in costly failures when the system is deployed.\nWasted Resources: The entire MLOps lifecycle—from data collection and preprocessing to model deployment and monitoring—is resource-intensive. Data leakage can render these efforts futile, as models with leakage often need to be retrained from scratch, incurring additional time and costs.\nErosion of Trust: A key aspect of MLOps is building trust in machine learning systems among stakeholders. Data leakage creates inflated performance metrics that can lead to overconfidence in the model’s capabilities, only to have those expectations shattered in production.\nCompromised Monitoring and Feedback Loops: In MLOps, monitoring is crucial to detect issues like drift and degradation. A model trained with leakage may produce unreliable predictions in production, complicating efforts to establish effective monitoring and feedback loops.\n\n\n\nHow to Prevent Data Leakage in MLOps\nTo build reliable and scalable ML systems in an MLOps workflow, rigorous practices are required to prevent data leakage:\n\nDataset Isolation: In an MLOps pipeline, ensure strict separation of training, validation, and test datasets. Automation tools should enforce this separation to prevent accidental overlap during preprocessing or feature generation.\nPipeline Validation: Validate the entire data pipeline to ensure that no future information is incorporated into the training process. This includes ensuring that scaling parameters (e.g., mean, standard deviation) or imputation values are calculated exclusively on training data.\nFeature Engineering Audits: Conduct regular audits of features to detect and remove any that are derived from the target variable or contain post-event information. Tools like feature importance scores or explainability frameworks can help identify problematic features.\nVersioning and Traceability: Use data versioning tools (e.g., DVC) to track changes in datasets and features over time. In MLOps, this ensures that any unintended leakage introduced during pipeline updates can be identified and corrected.\nContinuous Monitoring: In production, monitor model performance closely to detect signs of data leakage, such as an unexpected drop in accuracy or a sharp divergence between training and production metrics. Early detection can mitigate the impact and guide retraining efforts.\n\nIn an MLOps framework, preventing data leakage is not just a best practice but a foundational requirement for delivering reliable and maintainable machine learning systems. Leakage not only compromises the accuracy and robustness of models but also disrupts the iterative workflows that are central to MLOps, such as continuous integration, deployment, and monitoring. By prioritizing robust data handling practices and pipeline validations, MLOps teams can ensure that their models are not only performant but also trustworthy and sustainable in production environments.",
    "crumbs": [
      "DataOps",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>The Role of DataOps</span>"
    ]
  },
  {
    "objectID": "03-dataops-role.html#data-validation",
    "href": "03-dataops-role.html#data-validation",
    "title": "3  The Role of DataOps",
    "section": "3.3 Data Validation",
    "text": "3.3 Data Validation\nData validation is a critical step in the DataOps process that ensures datasets used in machine learning systems are accurate, complete, and reliable. In the context of machine learning, the quality of data directly impacts the performance and generalizability of models, making validation an essential safeguard against flawed results and operational inefficiencies. By systematically checking for errors, inconsistencies, and missing values, data validation helps to identify potential issues before they propagate through the machine learning pipeline, ultimately saving time and resources. It also fosters trust in the data by ensuring that all inputs meet predefined quality standards, which is particularly important when integrating data from multiple sources.\nData validation is not a one-time task but an ongoing process that spans the entire lifecycle of a machine learning system. From data ingestion to feature engineering and model deployment, validation plays a crucial role in detecting anomalies, ensuring consistency across datasets, and maintaining the relevance of the data. By embedding validation into DataOps workflows, organizations can create a foundation for scalable and dependable machine learning systems.\n\n\n\n\n\n\nKey Objectives of Data Validation\n\n\n\nThe primary objectives of data validation are to ensure the dataset’s integrity and usability while aligning it with the needs of the machine learning system:\n\nAccuracy: Verifying that data values are correct and reflect real-world scenarios. For instance, ensuring customer birthdates are valid and consistent with age calculations avoids errors during feature engineering.\nCompleteness: Checking that no critical data is missing or incomplete. For example, ensuring that every transaction in a sales dataset includes both the product ID and quantity sold prevents downstream issues in revenue calculations.\nConsistency: Ensuring that data formats, units, and structures are uniform across the dataset. For example, standardizing currency formats (e.g., USD) in global sales data helps avoid misinterpretation during analysis.\nUniqueness: Identifying and removing duplicate records to prevent data redundancy and biased model training. For instance, deduplicating customer profiles ensures accurate customer segmentation.\nTimeliness: Ensuring data is up-to-date and relevant for the task at hand. For real-time applications, such as fraud detection, validating the timeliness of incoming transaction data is essential for reliable predictions.\n\nBy focusing on these objectives, data validation ensures that machine learning systems are built on a foundation of high-quality, dependable data, reducing the likelihood of errors and enhancing overall performance.\n\n\n\nCommon Types of Data Validation\nData validation encompasses a range of checks and processes designed to ensure the quality, consistency, and reliability of datasets used in machine learning workflows. Each type of validation addresses specific aspects of data quality, ensuring that the dataset meets the requirements for accurate analysis and modeling. Below are the most common types of data validation and their roles in maintaining data integrity.\n\n\n\n\n\n\nSchema Validation\n\n\n\n\n\nSchema validation ensures that the dataset adheres to its predefined structure, including data types, column names, and value constraints. This is often the first step in data validation, as a mismatched schema can cause downstream processes to fail.\n\nExample: A dataset intended for customer analytics might require columns like CustomerID (integer), PurchaseDate (date), and AmountSpent (float). If CustomerID contains strings or PurchaseDate has invalid date formats, schema validation would flag these issues.\nWhy It’s Important: Schema validation ensures compatibility between datasets and the systems that consume them, preventing runtime errors during data processing and analysis.\n\n\n\n\n\n\n\n\n\n\nContent Validation\n\n\n\n\n\nContent validation focuses on the correctness of individual data values within the dataset. This includes verifying that values fall within expected ranges, follow required formats, or belong to valid categories.\n\nExample: In a demographic dataset, the Age column might be expected to contain values between 0 and 120. If a record includes a value of 200, content validation would identify it as an error.\nWhy It’s Important: Incorrect values can skew model training and lead to flawed insights. Content validation ensures that the dataset reflects realistic and meaningful information.\n\n\n\n\n\n\n\n\n\n\nCross-Field Validation\n\n\n\n\n\nCross-field validation examines the relationships between fields in a dataset to ensure logical consistency. It ensures that data points align with real-world constraints and dependencies.\n\nExample: In a dataset for employee records, the HireDate field should always precede the TerminationDate. Cross-field validation would flag any records where this condition is violated.\nWhy It’s Important: Logical inconsistencies can introduce biases or errors into models and analytics, reducing the reliability of results.\n\n\n\n\n\n\n\n\n\n\nCross-Dataset Validation\n\n\n\n\n\nCross-dataset validation ensures consistency and compatibility when integrating multiple datasets. It checks for alignment in shared fields, relationships, or identifiers across datasets.\n\nExample: When joining a sales dataset with a customer dataset, cross-dataset validation might confirm that all CustomerID values in the sales data exist in the customer data. Missing CustomerID values could indicate errors in data collection or integration.\nWhy It’s Important: Discrepancies between datasets can disrupt data pipelines and lead to incomplete or erroneous analyses.\n\n\n\n\n\n\n\n\n\n\nStatistical Validation\n\n\n\n\n\nStatistical validation uses descriptive statistics and patterns to identify anomalies or unexpected distributions in the data. This type of validation is especially useful for large datasets where manual checks are impractical.\n\nExample: In a dataset of daily sales, statistical validation might flag a sudden spike in sales for a particular day as a potential anomaly. This could indicate a data entry error or an event that requires further investigation.\nWhy It’s Important: Statistical anomalies can distort machine learning models and insights. Validation ensures that outliers or shifts in distributions are identified and addressed appropriately.\n\n\n\n\nBy incorporating these types of validation into the data pipeline, organizations can detect and resolve issues early, ensuring that datasets are clean, consistent, and ready for machine learning workflows. Each type of validation contributes to a robust foundation for building reliable and scalable ML systems.\n\n\nBest Practices for Data Validation\nEffective data validation is fundamental to building reliable machine learning systems. By leveraging domain expertise, incorporating validation at multiple stages, and implementing continuous checks, teams can address data quality issues proactively and ensure the success of their pipelines. Below are some key practices for robust data validation.\n\n\n\n\n\n\nLeverage Domain Expertise\n\n\n\n\n\nDomain knowledge is vital for designing meaningful validation checks that align with the specific context and operational needs of the data. While statistical methods and automated tools can identify obvious anomalies, domain experts provide critical insights into patterns, constraints, and acceptable ranges that are unique to the field. Their input ensures that validation rules capture the intricacies of the data and its intended use.\n\nDeep Contextual Understanding: Domain experts can identify subtleties that automated tools might miss. For example, a recorded blood glucose level of 10 mg/dL in a healthcare dataset might technically fall within a predefined range but would raise a red flag for medical professionals as a near-impossible value for a living patient.\nDefining Logical Relationships: Experts help validate cross-field dependencies, such as ensuring that “Hire Date” is always earlier than “Termination Date” in HR records or that “Loan Amount” does not exceed “Annual Income” in financial datasets.\nResolving Ambiguities: Inconsistent categorizations or missing metadata can lead to misinterpretations. Domain expertise helps reconcile these discrepancies by providing the real-world context necessary for making informed decisions.\nBest Practices: To incorporate domain knowledge effectively, schedule regular reviews with subject-matter experts, document domain-specific rules, and use their feedback to design validation logic.\n\nBy leveraging domain expertise, teams can ensure that validation processes are aligned with real-world expectations, reducing the risk of subtle but impactful errors that could undermine model performance.\n\n\n\n\n\n\n\n\n\nIncorporate Validation at Multiple Stages\n\n\n\n\n\nData validation should not be confined to a single step in the pipeline. Instead, it must be integrated at critical points to catch and correct errors as early as possible, minimizing their impact on downstream processes. A layered validation approach ensures that issues are addressed before they compound, saving time and resources.\n\nDuring Data Ingestion: Validate data as it enters the system to catch schema mismatches, missing fields, or invalid formats. Early detection ensures that errors don’t propagate to later stages of the pipeline.\n\nExample: A customer database ingesting data from an API might validate that all required fields (e.g., CustomerID, Email, SignUpDate) are present and correctly formatted. Missing or improperly formatted data would trigger an alert and block the ingestion process.\nWhy It’s Critical: Catching errors at this stage prevents bad data from being stored, processed, or analyzed, reducing the risk of cascading issues.\n\nBefore and After Data Transformations: Transformation processes, such as scaling, encoding, and feature extraction, can inadvertently introduce inconsistencies or errors. Validating data before and after these steps ensures the integrity of transformations.\n\nExample: After encoding categorical variables into numeric values, validate that all categories have been properly mapped and no invalid codes remain.\nWhy It’s Critical: Errors during transformation can mislead models or invalidate assumptions about the data, compromising model performance.\n\nPrior to Model Training or Inference: Perform comprehensive checks to confirm that the final dataset is clean, complete, and aligned with model requirements. Validate feature distributions, detect outliers, and ensure proper dataset splits to avoid data leakage.\n\nExample: Verify that feature distributions in the training and test sets are consistent. Large discrepancies might indicate data drift or improper splitting.\nWhy It’s Critical: Ensuring that the dataset aligns with model expectations prevents training on flawed or unrepresentative data, improving generalizability and performance.\n\n\nIntegrating validation at multiple stages creates a layered defense against data issues, ensuring that problems are addressed as they arise and minimizing downstream disruptions.\n\n\n\nIncorporate Validation at Multiple Stages\n\n\n\n\n\n\n\n\n\n\n\nImplement Continuous Validation for Real-Time Pipelines\n\n\n\n\n\nReal-time or streaming data pipelines introduce unique challenges, as data flows continuously and must be validated on the fly. Continuous validation ensures that data quality standards are upheld in dynamic environments, enabling reliable predictions and analysis even under high-velocity conditions.\n\nAutomated Validation Checks: Implement automated rules that validate data in real time, such as ensuring fields are populated, values fall within expected ranges, and timestamps are sequential.\n\nExample: For a weather forecasting model ingesting sensor data, validate that temperature readings are within a plausible range (-50°C to 60°C) and that timestamps are consistently ordered.\nWhy It’s Critical: Automated checks prevent bad data from entering the pipeline, reducing the risk of unreliable predictions or system failures.\n\nHandling Anomalies: Set up alert mechanisms to flag anomalous data points for further investigation or correction. For critical systems, design fallback processes to handle invalid data gracefully without disrupting operations.\n\nExample: In a fraud detection system, flagging a transaction with a missing TransactionID or an implausible transaction amount (e.g., $0 or $10 million) allows operators to investigate the issue without halting the pipeline.\nWhy It’s Critical: Continuous monitoring and anomaly detection ensure that issues are addressed promptly, maintaining the integrity of real-time workflows.\n\nIntegration with Monitoring Systems: Real-time pipelines should be integrated with monitoring tools to track key data quality metrics (e.g., percentage of missing fields, frequency of anomalies) and identify trends over time.\n\nExample: In a recommendation system for an e-commerce platform, monitor the consistency of product metadata to ensure that invalid records (e.g., missing prices or categories) are flagged and corrected automatically.\nWhy It’s Critical: Ongoing monitoring helps detect patterns of degradation or drift, enabling proactive maintenance and adjustments.\n\n\nContinuous validation ensures that high-velocity data pipelines remain reliable and robust, supporting the dynamic needs of real-time machine learning systems.\n\n\n\nBy leveraging domain expertise, validating data at multiple stages, and implementing continuous checks for real-time pipelines, teams can build resilient workflows that maintain data quality throughout the lifecycle. These best practices minimize errors, enhance trust in the data, and support the development of scalable and effective machine learning systems.\n\n\nCommon Challenges in Data Validation\nDespite its importance, data validation can be a complex and resource-intensive process, especially in large-scale machine learning workflows. Organizations face several challenges when implementing effective validation practices, from evolving data structures to managing high-velocity pipelines. Addressing these challenges requires a combination of strategic planning, automation, and collaboration across teams. Below are some of the most common challenges in data validation and strategies to mitigate them.\n\n\n\n\n\n\nHandling Evolving Schemas and Data Structures\n\n\n\n\n\nAs systems grow and data sources evolve, schemas and data structures often change over time. These changes can introduce unexpected errors if validation rules and downstream processes are not updated accordingly.\n\nChallenge: Changes in schema, such as adding or removing fields, altering data types, or modifying field names, can break validation checks and disrupt downstream workflows. For example, if a new column is added to a dataset without updating validation rules, it may be ignored or processed incorrectly.\nImpact: Unmanaged schema changes can lead to inconsistent or incomplete data, causing model degradation or failures in production.\nMitigation: Implement schema versioning to track and manage changes, and automate schema validation to identify discrepancies. Regular communication between data producers and consumers ensures alignment on schema updates.\n\n\n\n\n\n\n\n\n\n\nBalancing Thoroughness with Performance in Large-Scale Datasets\n\n\n\n\n\nIn large-scale datasets, exhaustive validation can be computationally expensive and time-consuming, particularly when dealing with real-time or high-volume data.\n\nChallenge: Performing detailed checks on every record in massive datasets can slow down data pipelines, increasing latency and computational costs. For instance, validating each field in a petabyte-scale dataset may be impractical without specialized infrastructure.\nImpact: Sacrificing thoroughness to maintain performance can result in undetected data quality issues, while overly thorough checks can delay time-sensitive processes.\nMitigation: Use sampling strategies to validate subsets of data for preliminary checks, and focus on high-priority fields or anomalies. Distributed processing frameworks, such as Apache Spark, can also help scale validation processes efficiently.\n\n\n\n\n\n\n\n\n\n\nManaging Validation Failures in Dynamic or High-Velocity Pipelines\n\n\n\n\n\nIn dynamic or real-time pipelines, validation failures must be handled quickly and effectively to avoid disrupting the flow of data.\n\nChallenge: High-velocity data streams generate large volumes of data that may fail validation checks due to schema mismatches, incomplete records, or anomalies. For example, a streaming pipeline for e-commerce transactions may receive invalid records during peak traffic.\nImpact: If validation failures are not managed appropriately, they can halt data ingestion, create bottlenecks, or allow poor-quality data to pass through unchecked.\nMitigation: Implement automated alerting and fallback mechanisms to handle validation failures gracefully. For instance, redirect invalid records to a quarantine or error-handling pipeline for further investigation while allowing valid data to continue flowing. Real-time dashboards can help monitor validation metrics and identify trends.\n\n\n\n\n\n\n\n\n\n\nAddressing Inconsistencies Across Multiple Data Sources\n\n\n\n\n\nIntegrating data from multiple sources often introduces inconsistencies, such as differing formats, units, or categorizations. These discrepancies can complicate validation and lead to unreliable datasets.\n\nChallenge: Datasets from disparate sources may lack standardization. For example, one dataset may record prices in USD, while another uses EUR without indicating the currency, making comparisons or aggregations problematic.\nImpact: Inconsistent data can lead to incorrect analyses, skewed model training, or misinterpretations of results.\nMitigation: Establish and enforce data standardization rules, such as using consistent formats, units, and categorizations across all sources. Employ automated data cleaning and reconciliation processes to resolve discrepancies. Collaboration with domain experts and data owners is crucial to defining consistent standards.\n\n\n\n\nData validation is a critical but challenging component of machine learning workflows. By proactively addressing issues such as evolving schemas, performance trade-offs, validation failures, and inconsistencies across sources, teams can build resilient pipelines that support robust and reliable ML systems. Tackling these challenges requires a combination of strategic planning, automation, and collaboration to ensure that data quality remains a cornerstone of the machine learning lifecycle.",
    "crumbs": [
      "DataOps",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>The Role of DataOps</span>"
    ]
  },
  {
    "objectID": "03-dataops-role.html#data-versioning-and-lineage",
    "href": "03-dataops-role.html#data-versioning-and-lineage",
    "title": "3  The Role of DataOps",
    "section": "3.4 Data Versioning and Lineage",
    "text": "3.4 Data Versioning and Lineage\nIn the world of machine learning and data-driven workflows, the reliability and traceability of data are critical. Data versioning and lineage are two foundational practices in DataOps that ensure datasets are consistently managed, reproducible, and transparent throughout their lifecycle. These practices not only empower teams to track changes, debug issues, and ensure compliance but also play a crucial role in fostering trust in the data used to build machine learning systems.\n\n\n\n\n\n\nData versioning focuses on capturing and maintaining historical versions of datasets. By recording each change, teams can roll back to previous versions, compare outcomes across iterations, and confidently experiment with new approaches.\n\n\n\n\n\n\n%%{init: {'gitGraph': {'mainBranchName': 'CustomerTransactions'}} }%%\n\ngitGraph\n   commit  id: \"v1.0.0\"\n   commit  id: \"v1.0.1\"\n   commit  id: \"v1.0.2\"\n   branch new_feature\n   commit id: \"add new feature\"\n   checkout CustomerTransactions\n   merge new_feature\n   commit  id: \"v1.1.0\"\n\n\n\n\n\nFigure 3.5: Data versioning tracks historical versions of a given dataset. This makes it explicit as to which instance of the dataset was used for a given model (i.e. v1.1.0) and also allows rolling back to previous versions (i.e. v1.0.2) if necessary.\n\n\n\n\n\nData lineage, on the other hand, documents the entire journey of data—from its origin to the final output—capturing how it was processed, transformed, and consumed. This traceability is essential for debugging, auditing, and understanding the impact of upstream changes on downstream processes.\n\n\n\n\n\n\nflowchart LR\n  db1[(Data&lt;br&gt;source 1)] --&gt; p1[/processing&lt;br&gt;step 1/]\n  p1 --&gt;  p2[/processing&lt;br&gt;step 2/]\n  db2[(Data&lt;br&gt;source 2)] --&gt; p2\n  p2 --&gt;  p3[/processing&lt;br&gt;step 3/]\n  db3[(Data&lt;br&gt;source 3)] --&gt; p3\n  p3 --&gt; p4[/processing&lt;br&gt;step 4/]\n  p4 --&gt; p5[/processing&lt;br&gt;step 5/]\n  p5 --&gt; db4[(Final&lt;br&gt;processed&lt;br&gt;data)]\n\n\n\n\n\nFigure 3.6: Data lineage tracks the movement and transformations of data from its original source(s) to its destination, including how the data was changed and why.\n\n\n\n\n\n\n\n\nTogether, data versioning and lineage create a transparent, reliable foundation for machine learning systems. They enable teams to meet regulatory requirements, mitigate risks, and streamline collaboration, making these practices indispensable in modern DataOps workflows.\n\nKey Use Cases for Data Versioning and Lineage\nData versioning and lineage are indispensable practices for ensuring reliability, transparency, and traceability in machine learning workflows. They address critical needs at various stages of the data lifecycle, from dataset updates to model deployment and auditing. Below provides an expanded exploration of their key use cases, highlighting their value in real-world applications.\n\n\n\n\n\n\nDataset Updates and Historical Record-Keeping\n\n\n\n\n\nDatasets are rarely static; they evolve over time as new data is added, errors are corrected, or data sources change. Versioning provides a structured approach to managing these updates, ensuring that historical records remain accessible for analysis and comparison.\n\nExample: In a healthcare application predicting patient readmissions, new patient data is added daily. Data versioning ensures that older datasets used for model training can be preserved, allowing teams to analyze performance trends and validate the impact of new data on the model.\nImpact: Maintaining historical datasets enables teams to trace the effects of data updates, ensure reproducibility, and mitigate risks associated with data drift.\n\n\n\n\n\n\n\n\n\n\nSupporting Experimentation in Machine Learning Workflows\n\n\n\n\n\nMachine learning involves iterative experimentation, where teams test different preprocessing techniques, feature engineering approaches, or model architectures. Data versioning and lineage allow for systematic tracking of these experiments, ensuring that changes to datasets and transformations are documented.\n\nExample: A retail company experimenting with customer segmentation might preprocess transactional data in multiple ways (e.g., normalizing vs. scaling numerical features). Versioning ensures each iteration is preserved, enabling direct comparison of model performance across different dataset versions.\nImpact: Experimentation becomes more controlled and efficient, as teams can revert to previous iterations, identify successful preprocessing pipelines, and replicate results with confidence.\n\n\n\n\n\n\n\n\n\n\nDebugging and Error Resolution\n\n\n\n\n\nErrors in data pipelines, such as incorrect preprocessing or missing records, can disrupt downstream processes and compromise model performance. Data lineage provides a detailed trace of the data journey, helping teams identify and resolve issues efficiently.\n\nExample: In a real-time fraud detection system, an unexpected spike in false positives might be traced back to an error during data aggregation. Lineage tools can pinpoint the exact step where the error occurred, enabling a targeted fix.\nImpact: By tracing data through every stage of the pipeline, teams can quickly isolate and correct issues, minimizing downtime and preventing future errors.\n\n\n\n\n\n\n\n\n\n\nEnsuring Regulatory Compliance and Auditability\n\n\n\n\n\nIndustries like healthcare, finance, and government require strict adherence to data governance and regulatory standards. Data versioning and lineage provide the transparency needed to demonstrate compliance during audits and ensure accountability.\n\nExample: A financial institution subject to GDPR must document how customer data is processed and used in predictive models. Lineage tools enable the institution to show the origin, transformations, and final usage of the data, meeting regulatory requirements.\nImpact: Compliance becomes more manageable, reducing the risk of fines or legal repercussions and building trust with stakeholders.\n\n\n\n\n\n\n\n\n\n\nManaging Data Across Multiple Teams and Workflows\n\n\n\n\n\nIn collaborative environments, multiple teams often work with the same datasets for different purposes, such as training, testing, and reporting. Data versioning ensures that all teams access consistent and accurate data, while lineage provides visibility into data dependencies and transformations.\n\nExample: In a global logistics company, the analytics team uses shipment data for demand forecasting, while the operations team uses the same data for route optimization. Versioning ensures that both teams work with the same baseline dataset, while lineage reveals how each team’s transformations affect their workflows.\nImpact: Collaboration becomes smoother, with reduced risks of duplication, misalignment, or conflicting results.\n\n\n\n\n\n\n\n\n\n\nMonitoring Data Quality and Detecting Drift\n\n\n\n\n\nOver time, data distributions may change due to external factors, introducing data drift that can degrade model performance. Lineage tools can help monitor data quality and track changes in data characteristics, enabling proactive responses.\n\nExample: A recommendation system for an online retailer detects a drop in click-through rates. Lineage tracing reveals a shift in customer behavior, such as increased searches for eco-friendly products. Versioning allows the team to retrain the model using updated data reflecting the new trends.\nImpact: Data drift is detected early, allowing teams to maintain model accuracy and relevance.\n\n\n\n\n\n\n\n\n\n\nReproducing Results and Facilitating Knowledge Sharing\n\n\n\n\n\nReproducibility is critical for both research and production environments. Data versioning ensures that datasets used in experiments or deployed models are preserved, enabling other teams to replicate and validate results.\n\nExample: In a pharmaceutical study, a machine learning model identifies potential drug interactions. Preserving the exact dataset and transformations used for the analysis allows external researchers to reproduce the findings and verify their validity.\nImpact: Knowledge sharing and collaboration improve, fostering trust in the results and enabling broader contributions to the project.\n\n\n\n\nBy implementing robust data versioning and lineage practices, organizations can enhance the transparency, reliability, and efficiency of their machine learning workflows. These practices not only address critical challenges like compliance and debugging but also empower teams to innovate confidently and collaboratively in an increasingly data-driven world.\n\n\nKey Components of Data Versioning and Lineage\nData versioning and lineage provide mechanisms for tracking changes, ensuring reproducibility, and offering transparency into the lifecycle of data. The following are the key components that underpin effective data versioning and lineage practices.\n\n\n\n\n\n\nData Versioning\n\n\n\n\n\nData versioning ensures that all changes to datasets are tracked and preserved, enabling teams to maintain a historical record of their data. This practice supports reproducibility, experimentation, and error recovery.\n\nMetadata Tagging for Datasets: Each dataset version should include metadata that captures important details such as timestamps, source information, preprocessing steps, and associated models. For example, tagging a dataset with its creation date, source system, and transformation details helps identify its role in various workflows.\nStoring Snapshots of Datasets: Versioning involves creating and storing immutable snapshots of datasets at specific points in time. These snapshots act as checkpoints that teams can use for comparison, debugging, or compliance purposes. For instance, retaining snapshots of customer transaction data before and after preprocessing ensures the original dataset is preserved for future reference.\nComparison for Changes: Versioning tools should allow for easy comparison of different dataset versions. For example, identifying changes in schema, added records, or updated values between two versions enables teams to analyze their impact on downstream processes or models.\n\n\n\n\n\n\n\n\n\n\nData Lineage\n\n\n\n\n\nData lineage focuses on documenting the entire journey of a dataset, from its origin to its final use. It provides insights into how data flows through pipelines and ensures traceability for debugging, auditing, and compliance.\n\nCapturing Source Information: Lineage begins with documenting where the data originated, including details like the source system, ingestion method, and timestamp. For example, knowing that a sales dataset came from a specific API on a given date ensures transparency and traceability.\nLogging Transformations Applied to the Data: Every transformation applied to a dataset—such as cleaning, normalization, or aggregation—should be recorded in detail. For instance, lineage tracking might reveal that raw sales data was aggregated by region and quarter before being used for demand forecasting.\nTracking Data Dependencies Across Workflows: Data lineage identifies relationships between datasets and workflows, enabling teams to understand how changes in one component affect others. For example, if a change occurs in the schema of a raw dataset, lineage tracking can reveal all downstream models, reports, or dashboards that rely on it.\n\n\n\n\nIn addition to capturing these key components, a few best practices to consider for data versioning and lineage include:\n\n\n\n\n\n\nIntegration with Workflow Automation\n\n\n\n\n\nData versioning and lineage should seamlessly integrate into automated workflows to ensure continuous tracking and real-time updates.\n\nPipeline Integration: Versioning and lineage tools must be embedded within data pipelines to automatically capture changes as data flows through ingestion, transformation, and modeling stages. For instance, a pipeline processing IoT sensor data should log every step, from ingestion to normalization.\nChange Detection and Alerts: Automated systems should monitor for changes to datasets or pipelines and notify teams when discrepancies arise. For example, an alert might be triggered if a dataset’s schema changes unexpectedly, allowing for quick troubleshooting.\n\n\n\n\n\n\n\n\n\n\nCentralized Management and Visualization\n\n\n\n\n\nCentralized storage and visual tools are essential for accessing and understanding versioning and lineage information.\n\nCentralized Repositories: Datasets and lineage metadata should be stored in a centralized system, such as a data lake or a dedicated tool like DVC or LakeFS. Centralized storage ensures consistency and prevents duplication, making it easier for teams to collaborate and retrieve historical data.\nVisual Representations: Tools that provide graphical representations of lineage offer an intuitive way to understand data flows and dependencies. For example, a visual lineage graph might display how raw survey data is transformed and aggregated into a final dataset used for customer sentiment analysis, highlighting dependencies and transformation steps.\n\n\n\n\n\n\n\n\n\n\nStandardize Naming and Storage\n\n\n\n\n\nEstablishing consistent naming conventions and centralized storage for datasets ensures clarity and accessibility across teams.\n\nWhy It Matters: Inconsistent naming or scattered storage can create confusion and hinder collaboration. Standardized practices make it easier to locate and identify datasets, reducing errors and miscommunication.\nHow to Implement: Use clear, descriptive names for datasets, such as including the dataset’s purpose, version, and timestamp in its name (e.g., customer_transactions_v1_2024-12-01). Store datasets in a centralized location, like a data lake or cloud repository, to ensure all team members have access to the latest and historical versions.\n\n\n\n\n\n\n\n\n\n\nAlign with Business and Regulatory Needs\n\n\n\n\n\nTailoring versioning and lineage practices to align with business objectives and regulatory requirements ensures their relevance and value.\n\nWhy It Matters: Different industries have unique compliance standards, such as GDPR in the EU or HIPAA in healthcare. Aligning data practices with these requirements reduces legal risks and ensures that systems meet stakeholder expectations.\nHow to Implement: Identify key compliance and business goals early in the process. For example, ensure lineage tools capture data provenance details to meet audit requirements, or design versioning practices that align with business-critical milestones, such as product launches or quarterly reporting.\n\n\n\n\n\n\nChallenges in Implementing Data Versioning and Lineage\nWhile data versioning and lineage are essential for maintaining reliable and transparent machine learning workflows, their implementation comes with significant challenges. These difficulties often stem from the complexity of data ecosystems, evolving requirements, and resource constraints. Below are key challenges and their implications. You’ll notice that many of these are the same challenges identified in the Data Validation section.\n\n\n\n\n\n\nHandling Evolving Schemas and Data Structures\n\n\n\n\n\nData schemas and structures frequently change due to updates in source systems, new business requirements, or changes in data pipelines. These changes can disrupt existing workflows and complicate versioning and lineage tracking.\n\nWhy It Matters: Schema changes can break downstream processes or make older dataset versions incompatible with updated systems, hindering reproducibility and operational efficiency.\nExample: An e-commerce platform might update its customer transaction schema by adding new fields (e.g., “discount code”) or renaming existing ones, causing discrepancies in the lineage and breaking versioned workflows.\nHow to Address: Implement schema evolution strategies, such as backward compatibility checks and automated schema validation tools, to accommodate changes without disrupting existing systems.\n\n\n\n\n\n\n\n\n\n\nBalancing Thoroughness with Performance in Large-Scale Datasets\n\n\n\n\n\nMaintaining detailed versioning and lineage information for massive datasets can strain storage and computational resources. Tracking every transformation and storing multiple dataset versions may lead to high costs and performance bottlenecks.\n\nWhy It Matters: Overhead from excessive storage or processing requirements can slow down workflows, making real-time or near-real-time processing unfeasible for large-scale operations.\nExample: A streaming platform processing terabytes of user activity data daily may struggle to version every batch without incurring prohibitive storage costs or latency.\nHow to Address: Use compression techniques, snapshot deltas instead of full copies, and prioritize versioning critical datasets over ephemeral or intermediate data.\n\n\n\n\n\n\n\n\n\n\nManaging Validation Failures in Dynamic Data Pipelines\n\n\n\n\n\nIn dynamic or high-velocity data pipelines, validation failures or pipeline interruptions can lead to incomplete or inconsistent lineage and versioning records.\n\nWhy It Matters: Missing or incorrect lineage records compromise the ability to debug issues or trace the data journey, leading to a loss of confidence in the system’s reliability.\nExample: In a fraud detection system ingesting live transactional data, a sudden schema mismatch during ingestion might skip validation, resulting in incomplete lineage tracking.\nHow to Address: Integrate robust validation checks at every stage of the pipeline and implement fail-safe mechanisms, such as pausing downstream processes until issues are resolved.\n\n\n\n\n\n\n\n\n\n\nAddressing Inconsistencies Across Multiple Data Sources\n\n\n\n\n\nIntegrating data from diverse sources, each with its own standards and inconsistencies, poses challenges for maintaining unified versioning and lineage.\n\nWhy It Matters: Disparate data sources with varying levels of documentation, quality, and structure make it difficult to track dependencies and transformations comprehensively.\nExample: A global organization might source data from regional offices with inconsistent naming conventions, formats, or processing practices, complicating lineage tracking and dataset reconciliation.\nHow to Address: Standardize data ingestion processes and enforce consistent naming conventions, metadata tagging, and validation rules across all data sources.\n\n\n\n\n\n\n\n\n\n\nEnsuring Scalability with Growing Data Volumes\n\n\n\n\n\nAs data volumes increase, the complexity of managing versioning and lineage grows exponentially. Systems must scale to handle larger datasets without sacrificing performance or accuracy.\n\nWhy It Matters: Scaling challenges can result in gaps in lineage tracking or slow down pipelines, limiting the system’s ability to support evolving business needs.\nExample: A social media platform analyzing user interactions in real time may find its lineage tools unable to keep pace with the sheer volume of incoming data.\nHow to Address: Use distributed systems and cloud-based solutions to scale storage and processing capabilities dynamically. Focus lineage tracking on critical datasets to balance thoroughness with efficiency.\n\n\n\n\nImplementing data versioning and lineage requires navigating challenges like evolving schemas, large-scale datasets, dynamic pipelines, and diverse data sources. By anticipating these difficulties and adopting strategies such as schema evolution, robust validation checks, and scalable infrastructure, organizations can build resilient systems that ensure data integrity and traceability while meeting the demands of modern machine learning workflows.",
    "crumbs": [
      "DataOps",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>The Role of DataOps</span>"
    ]
  },
  {
    "objectID": "03-dataops-role.html#summary",
    "href": "03-dataops-role.html#summary",
    "title": "3  The Role of DataOps",
    "section": "3.5 Summary",
    "text": "3.5 Summary\nThis chapter explored the foundational role of DataOps within the MLOps lifecycle, focusing on the key processes and principles that enable the efficient, reliable, and high-quality flow of data to support machine learning systems. From data ingestion to data validation, versioning, and lineage, we examined how these processes address common challenges in data management while ensuring the scalability and reliability of ML workflows.\nKey highlights included the importance of understanding data sources and their ingestion methods, the transformative role of data processing and feature engineering, and the critical need for robust data validation practices. We also delved into the benefits of data versioning and lineage, which enable traceability, reproducibility, and compliance in increasingly complex data ecosystems.\nWhile this chapter provided a conceptual and practical understanding of each DataOps process, the next chapter will shift focus to application. Readers will explore how these processes come together in an end-to-end DataOps pipeline, gaining hands-on insights into building and managing scalable, effective workflows. This transition from theory to practice is designed to solidify your understanding of DataOps and its critical role in delivering reliable and impactful machine learning systems.",
    "crumbs": [
      "DataOps",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>The Role of DataOps</span>"
    ]
  },
  {
    "objectID": "03-dataops-role.html#exercise",
    "href": "03-dataops-role.html#exercise",
    "title": "3  The Role of DataOps",
    "section": "3.6 Exercise",
    "text": "3.6 Exercise\nThis exercise is designed to engage you in a thought experiment that explores the practical applications of DataOps concepts. Each scenario below requires critical thinking and reflection on the principles discussed in this chapter. The scenarios are designed to be a bit vague so you can feel free to make certain assumptions regarding the scenario or even identify additional questions that need to be answered.\n\n\n\n\n\n\nPart 1: Data Ingestion Design\n\n\n\n\n\nImagine you are building an ML system for a ride-sharing company to predict rider demand in real-time.\nScenario Details:\n\nHistorical Trip Data: Stored in a relational database, this includes features like pickup/dropoff locations, trip durations, fares, and timestamps for trips over the past five years. Updates occur nightly.\nReal-Time Weather Updates: Obtained from a third-party API, the weather data includes temperature, precipitation, and wind speed, updated every 10 minutes. However, the API has a limit of 1000 requests per hour.\nDriver Availability Data: Streamed from an internal system, this data provides the location and status (available, occupied, offline) of drivers in real-time, updated every second.\n\nQuestions to Consider:\n\nFor each data source, would you choose batch, streaming, or hybrid ingestion? Justify your decision.\nWhat challenges might arise when combining these sources into a unified pipeline (e.g., mismatched data formats, latency)?\nIf the weather API experiences downtime or exceeds rate limits, how would you ensure the pipeline continues functioning without compromising predictions?\n\n\n\n\n\n\n\n\n\n\nPart 2: Data Validation Strategy\n\n\n\n\n\nYou are working on a fraud detection system for an e-commerce platform.\nScenario Details:\n\nTransactional Data: Includes payment amounts, timestamps, and location information. This data is streamed in real-time as customers complete purchases.\nCustomer Demographic Data: Stored in a central database, this data includes customer age, location, and preferred payment method. Updates are infrequent, typically occurring during customer registration or profile edits.\n\nQuestions to Consider:\n\nWhat specific validation checks would you implement for:\n\nReal-time transactional data (e.g., ensuring timestamps are sequential, payment amounts are positive)?\nCustomer demographic data (e.g., completeness of profiles, consistency between locations and timestamps)?\n\nWhere in the pipeline would you implement these checks to ensure high-quality data without introducing significant latency (i.e. during data ingestion, after data processing)?\nIn a scenario where real-time data includes unexpected values or incomplete fields, what fallback mechanisms would you put in place to avoid disruptions?\n\n\n\n\n\n\n\n\n\n\nPart 3: Data Versioning and Lineage in Practice\n\n\n\n\n\nYou are tasked with designing a churn prediction model for a subscription-based video streaming service.\nScenario Details:\n\nUser Activity Logs: Include data on session duration, content watched, and browsing patterns. Logs are collected continuously and stored in a data lake.\nSubscription Details: Include plan type, renewal dates, and payment status. This data is updated monthly and stored in a relational database.\nSupport Ticket Interactions: Contain customer issues, resolutions, and timestamps. These are logged as they occur, with potential delays in updates due to manual entry.\n\nQuestions to Consider:\n\nHow would you use data versioning to track changes in user activity logs, ensuring you can reproduce model training results even as new data is added?\nWhat specific lineage information would you prioritize capturing (e.g., transformations applied to raw activity logs, dependencies between features)?\nIf regulatory compliance (e.g., GDPR, which requires traceability of user data usage) is a factor, how might you adjust your versioning and lineage strategy?\n\n\n\n\n\n\n\n\n\n\nPart 4: Reflection on DataOps Challenges\n\n\n\n\n\nReflect on a hypothetical scenario where your ML pipeline for a financial institution fails in production.\nScenario (Failure) Details:\n\nA schema change in the credit card transaction dataset (e.g., renaming “customer_id” to “user_id”) was not communicated to the team.\nThe batch ingestion process for monthly transaction summaries included corrupted records due to network interruptions during transfer.\nReal-time streaming data from payment terminals introduced inconsistencies in timestamps due to system clock misalignments.\n\nQuestions to Consider:\n\nWhich specific DataOps practices (e.g., schema validation, data versioning, lineage tracking) could have prevented these failures?\nWhat steps could you take to proactively handle similar challenges in the future, such as designing validation workflows or automating schema change notifications?\nHow would you balance thorough validation checks with maintaining pipeline performance, especially in a high-throughput environment like financial fraud detection?\n\n\n\n\n\n\n\n\nGéron, Aurélien. 2022. Hands-on Machine Learning with Scikit-Learn, Keras, and TensorFlow. \" O’Reilly Media, Inc.\".\n\n\nHeckman, James. 2013. “Sample Selection Bias as a Specification Error.” Applied Econometrics 31 (3): 129–37.\n\n\nKuhn, Max, and Kjell Johnson. 2019. Feature Engineering and Selection: A Practical Approach for Predictive Models. Chapman; Hall/CRC.\n\n\nLerman, Rachel. February 3, 2016. “Google Is Testing Its Self-Driving Car in Kirkland,” February 3, 2016.\n\n\nZheng, Alice, and Amanda Casari. 2018. Feature Engineering for Machine Learning: Principles and Techniques for Data Scientists. \" O’Reilly Media, Inc.\".",
    "crumbs": [
      "DataOps",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>The Role of DataOps</span>"
    ]
  },
  {
    "objectID": "03-dataops-role.html#footnotes",
    "href": "03-dataops-role.html#footnotes",
    "title": "3  The Role of DataOps",
    "section": "",
    "text": "tdwi blog: https://tdwi.org/articles/2019/04/16/diq-all-data-quality-problems-will-haunt-your-analytics-future.aspx↩︎",
    "crumbs": [
      "DataOps",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>The Role of DataOps</span>"
    ]
  },
  {
    "objectID": "04-dataops-build.html",
    "href": "04-dataops-build.html",
    "title": "4  Putting DataOps into Practice",
    "section": "",
    "text": "4.1 Introduction to Data Pipelines\nIn the previous chapter, we explored the foundational concepts of DataOps, focusing on the importance of processes such as data ingestion, validation, versioning, and lineage in building reliable machine learning systems. Now, it’s time to take these concepts from theory to practice by applying them to create data pipelines. Data pipelines form the backbone of any modern ML system, serving as the structured, automated pathways through which data flows from raw sources to actionable insights.\nA data pipeline is a series of interconnected steps that collect, process, validate, and transform data into formats ready for machine learning workflows. Whether you’re ingesting data from multiple sources, cleaning and preparing it for modeling, or ensuring its integrity through validation and versioning, pipelines make it possible to handle these tasks efficiently and consistently. They are essential for ensuring scalability, reliability, and repeatability in ML systems, especially in environments where data is constantly changing or arriving in real-time.\nThis chapter will guide you through the practical implementation of DataOps principles by developing end-to-end data pipelines. We’ll begin with an introduction to the components of a data pipeline and the tools commonly used to implement them. From there, we’ll delve into the step-by-step process of building a pipeline, starting with a simple example and progressing to techniques for creating scalable workflows that can handle complex, large-scale ML applications.\nBy the end of this chapter, you’ll have a deeper understanding of how to translate DataOps practices into actionable pipelines, setting the stage for real-world machine learning deployments. Whether you’re working with batch or streaming data, structured or unstructured datasets, this chapter will equip you with the tools and strategies to design robust data pipelines that meet the demands of modern ML workflows.\nIn the world of machine learning (ML), the success of a system hinges on the quality, reliability, and timeliness of the data that powers it. Data pipelines are the operational backbone of these systems, ensuring data flows seamlessly from its source, through various transformations, and into the hands of models or end-users. A data pipeline is a series of automated steps that enable data ingestion, processing, and delivery—integrating the concepts of DataOps to ensure scalability, consistency, and efficiency.\nIn the previous chapter, we explored the fundamental principles of DataOps, including data ingestion, processing, validation, versioning, and lineage. These processes establish the foundation for building robust data pipelines. Now, we turn our attention to applying these principles in practice to design end-to-end workflows that support machine learning systems.",
    "crumbs": [
      "DataOps",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Putting DataOps into Practice</span>"
    ]
  },
  {
    "objectID": "04-dataops-build.html#introduction-to-data-pipelines",
    "href": "04-dataops-build.html#introduction-to-data-pipelines",
    "title": "4  Putting DataOps into Practice",
    "section": "",
    "text": "The Importance of Data Pipelines in ML System Design\nData pipelines address critical challenges faced by ML workflows, such as managing large data volumes, handling diverse data formats, and maintaining data integrity. By automating repetitive and error-prone tasks like ingestion, cleaning, and transformation, pipelines ensure that data is prepared and delivered reliably.\nFrom the concepts introduced earlier, pipelines incorporate:\n\nData Ingestion: Automating the flow of data from various sources—whether databases, APIs, or real-time streams—into a centralized system.\nData Processing: Applying transformations, feature engineering, and cleaning steps to structure raw data into formats ready for model consumption.\nData Validation: Embedding quality checks to ensure the consistency and integrity of data at every stage of the pipeline.\nData Versioning and Lineage: Providing traceability and reproducibility by maintaining historical records of datasets and documenting their transformations.\n\nFor example, in a customer churn prediction system, a data pipeline might ingest transaction data from a database, clean and preprocess it to handle missing values and inconsistencies, and validate that the data conforms to schema standards before feeding it into an ML model. Each step would leverage the DataOps principles discussed earlier to ensure that the process is efficient, scalable, and error-resistant.\n\n\nThe Role of DataOps in Constructing Scalable and Reliable Pipelines\nAs explored in the previous chapter, DataOps is not just a set of practices but a philosophy that ensures data workflows are collaborative, automated, and aligned with business objectives. When applied to pipeline construction, DataOps enables:\n\nScalability: Modular design allows pipelines to handle growing data volumes and adapt to new sources or transformations without significant redesigns.\nReliability: Continuous validation, versioning, and monitoring ensure that pipelines consistently deliver high-quality data, even in dynamic environments.\nCollaboration: DataOps principles encourage communication between data engineers, analysts, and machine learning practitioners, ensuring pipelines meet diverse needs.\nTraceability: By tracking data lineage and applying version control, DataOps ensures every step in the pipeline is documented, facilitating debugging, compliance, and reproducibility.\n\nConsider a recommendation system that ingests real-time user behavior data from an API and combines it with historical purchase data stored in a data lake. A DataOps-driven pipeline would:\n\nIngest and Validate: Fetch data from both sources, validating schema consistency and ensuring data quality.\nProcess and Transform: Standardize features such as timestamps, handle missing values, and engineer inputs like “average time between purchases.”\nTrack Lineage: Document the transformations applied to both real-time and historical data to ensure traceability and compliance.\nVersion Datasets: Maintain snapshots of preprocessed data for future analysis, debugging, or retraining.\n\nBy applying the foundational concepts of DataOps, such pipelines are not only robust and scalable but also agile enough to adapt to evolving ML requirements.\nIn this chapter, we will build on the foundational knowledge from the previous chapter to design and implement data pipelines that embody the principles of DataOps. Through hands-on examples and practical guidance, you will learn how to construct workflows that transform raw data into reliable inputs for machine learning systems, setting the stage for scalable and effective solutions.",
    "crumbs": [
      "DataOps",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Putting DataOps into Practice</span>"
    ]
  },
  {
    "objectID": "04-dataops-build.html#etl-vs.-elt-paradigms",
    "href": "04-dataops-build.html#etl-vs.-elt-paradigms",
    "title": "4  Putting DataOps into Practice",
    "section": "4.2 ETL vs. ELT Paradigms",
    "text": "4.2 ETL vs. ELT Paradigms\nWhen designing data pipelines, there are two primary paradigms: Extract, Transform, Load (ETL) and Extract, Load, Transform (ELT). These paradigms represent distinct approaches to organizing and processing data as it flows through pipelines, each with its own strengths and trade-offs. Choosing between ETL and ELT (or a hybrid approach) requires an understanding of your organization’s technical infrastructure, data requirements, and use cases.\n\nExtract, Transform, Load (ETL)\nThe ETL paradigm embodies a traditional, structured approach to data pipelines. It follows a linear process:\n\nExtract data from various sources, such as relational databases, APIs, or CSV files.\nTransform the extracted data into a clean, structured format using techniques like cleaning, aggregation, and enrichment.\nLoad the transformed data into a target system, such as a relational database or data warehouse.\n\n\n\n\n\n\n\nflowchart LR\n    ob1(Raw data source) --&gt; processing[Data processing]\n    ob2(Raw data source) --&gt; processing\n    ob3(Raw data source) --&gt; processing\n    processing --&gt; id3[(Data storage)]\n\n\n\n\nFigure 4.1: In the ETL paradigm, the pipeline ingests the data, then processes the data prior to storing the data in their target destination.\n\n\n\n\n\nETL pipelines focus on preparing high-quality, ready-to-use data before it enters the storage system. In ETL workflows, the data processing phase discussed earlier plays a central role. Transformations are performed early in the pipeline to ensure data quality and structure before it reaches the storage layer.\n\n\n\n\n\n\nWhen to Use ETL\n\n\n\n\n\n\nWhen working with traditional data warehouses or legacy systems that prioritize structured and clean data.\nIn use cases requiring strict data governance and pre-defined schemas, such as regulatory compliance reporting.\nWhen downstream applications depend on consistent, pre-processed datasets.\n\n\n\n\n\n\n\n\n\n\nAdvantages\n\n\n\n\n\n\nSimplifies downstream workflows by ensuring data is pre-processed and ready for use.\nReduces storage costs by retaining only clean and structured data.\nAligns well with environments that require high data integrity.\n\n\n\n\n\n\n\n\n\n\nChallenges\n\n\n\n\n\n\nUpfront transformations can delay data availability.\nScaling ETL pipelines to handle large datasets or real-time workflows can be resource-intensive.\nRigid processes may struggle to adapt to rapidly changing data needs.\n\n\n\n\n\n\n\n\n\n\nExample\n\n\n\n\n\nImagine a financial institution that extracts transaction data, transforms it into a consistent format by applying currency conversions and anomaly detection, and loads the cleaned data into a warehouse for fraud detection reports.\n\n\n\n\n\nExtract, Load, Transform (ELT)\nThe ELT paradigm, a more modern approach, inverts the transformation and loading steps:\n\nExtract data from various sources, often retaining its raw format.\nLoad the extracted data directly into a scalable storage system, such as a data lake or cloud-based data warehouse.\nTransform the data within the storage system using its computational resources, tailoring transformations to specific analytical needs.\n\n\n\n\n\n\n\nflowchart LR\n    ob1(Raw data source) --&gt; id3[(Data storage)]\n    ob2(Raw data source) --&gt; id3\n    ob3(Raw data source) --&gt; id3\n    id3 --&gt; processing[Data processing] --&gt; id3\n\n\n\n\nFigure 4.2: In the ELT paradigm, the pipeline ingests data directly into the destination system and transforms it in parallel or after the fact.\n\n\n\n\n\nIn ELT workflows, the data ingestion phase emphasizes rapid loading of raw data into storage, enabling flexibility for later transformations. Also, by storing the data in its raw form, ELT better handles structured, unstructured, and semi-structured data and allows downstream analytics on this data to more easily adapt.\n\n\n\n\n\n\nWhen to Use ELT\n\n\n\n\n\n\nWhen leveraging cloud-native platforms like Snowflake, BigQuery, or AWS Redshift, which support high-speed storage and in-database transformations.\nIn workflows requiring rapid ingestion and the ability to adapt transformations for different use cases.\nWhen storing raw data is essential for exploratory analysis or regulatory purposes.\n\n\n\n\n\n\n\n\n\n\nAdvantages\n\n\n\n\n\n\nEnables faster data ingestion by deferring transformations.\nSupports diverse and flexible transformations tailored to specific analyses.\nScales well with large data volumes, leveraging modern storage and processing systems.\n\n\n\n\n\n\n\n\n\n\nChallenges\n\n\n\n\n\n\nRequires advanced infrastructure to handle and process raw data efficiently.\nHigher storage costs due to the retention of raw, unprocessed data.\nAd-hoc transformations can lead to inconsistencies if not governed properly.\n\n\n\n\n\n\n\n\n\n\nExample\n\n\n\n\n\nAn e-commerce platform ingests raw clickstream data into a cloud data warehouse. When needed, transformations such as sessionizing user behavior or aggregating purchase trends are applied directly within the warehouse for personalized recommendations or sales forecasting.\n\n\n\n\n\nComparing ETL and ELT\n\n\n\n\n\n\n\n\nAspect\nETL\nELT\n\n\n\n\nData Transformation\nBefore loading into storage\nAfter loading into storage\n\n\nStorage Requirements\nLower, as only processed data is stored\nHigher, as raw data is retained\n\n\nProcessing Time\nSlower ingestion due to upfront transformations\nFaster ingestion with deferred transformations\n\n\nFlexibility\nLimited; transformations are predefined\nHigh; transformations can be ad hoc\n\n\nInfrastructure\nSuitable for legacy systems or traditional data warehouses\nIdeal for modern, scalable systems\n\n\n\n\n\n\n\n\n\nChoosing the Right Paradigm\n\n\n\n\n\nAs highlighted in the previous chapter, the goals of DataOps — efficiency, reliability, and scalability — should guide the choice of ETL, ELT, or a hybrid approach. Consider:\n\nETL is well-suited for structured environments and use cases that demand immediate access to clean, well-processed data.\nELT shines in cloud-native or big data ecosystems where raw data flexibility and scalability are critical.\n\nBoth paradigms have their strengths, and many organizations blend elements of each. For example, a retail company might use ETL for compliance reporting while leveraging ELT for real-time inventory analysis. By understanding these paradigms within the broader DataOps framework, teams can design pipelines that meet both technical and business requirements effectively.",
    "crumbs": [
      "DataOps",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Putting DataOps into Practice</span>"
    ]
  },
  {
    "objectID": "04-dataops-build.html#sec-dataops-tools",
    "href": "04-dataops-build.html#sec-dataops-tools",
    "title": "4  Putting DataOps into Practice",
    "section": "4.3 Tools for DataOps",
    "text": "4.3 Tools for DataOps\nBuilding effective and scalable data pipelines requires leveraging specialized tools at each stage of the DataOps lifecycle. From data ingestion to processing, validation, and versioning, the ecosystem of tools available is vast and continually expanding. This section provides an overview of commonly used tools, highlighting their capabilities, trade-offs, and when they might be most appropriate. Additionally, this space is dynamic, with new tools regularly introduced to address evolving challenges. Therefore, the goal is not to become tied to a specific tool but to understand the broader landscape and make informed decisions based on your pipeline’s requirements.\n\nData Ingestion Tools\nEfficiently gathering data from diverse sources is the foundation of any pipeline. Ingestion tools vary from those tailored for real-time streaming to solutions focused on batch processing and ease of integration. Some examples include:\n\n\n\n\n\n\nApache Kafka\n\n\n\n\n\nA distributed event-streaming platform designed for high-throughput, real-time data ingestion. Kafka is widely used in applications like fraud detection, IoT data pipelines, and real-time analytics.\n\nWhen to Use: Ideal for high-velocity, low-latency systems.\nLimitations: Steep learning curve and resource-heavy for smaller use cases.\n\n\n\n\n\n\n\n\n\n\nApache NiFi\n\n\n\n\n\nA flow-based programming tool that automates data movement and transformation with a user-friendly interface. NiFi supports a wide range of data sources and formats.\n\nWhen to Use: Low-code scenarios requiring rapid integration of multiple data sources.\nLimitations: Less suited for complex, high-throughput pipelines.\n\n\n\n\n\n\n\n\n\n\nAirbyte\n\n\n\n\n\nAn open-source data integration platform focused on moving data into data warehouses or lakes. Its extensive library of connectors simplifies ingesting data from various APIs and databases.\n\nWhen to Use: Batch ingestion with diverse source compatibility.\nLimitations: Primarily batch-focused and may require configuration for real-time pipelines.\n\n\n\n\n\n\n\n\n\n\nFivetran\n\n\n\n\n\nA managed data integration tool that simplifies data ingestion by automating schema handling and updates. It’s widely used for moving data into analytics-ready storage solutions.\n\nWhen to Use: Enterprise scenarios requiring minimal management overhead for cloud data integration.\nLimitations: Subscription-based pricing and limited customization compared to open-source tools.\n\n\n\n\n\n\nData Processing Tools\nProcessing raw data into clean, structured, and feature-rich formats is critical to preparing it for machine learning workflows. Many tools exist but the following are a few popular tools that support various scales and complexities of data transformation.\n\n\n\n\n\n\nApache Spark\n\n\n\n\n\nA powerful engine for distributed data processing. Spark supports both batch and streaming data workflows, making it suitable for big data and ML pipelines.\n\nWhen to Use: Processing large-scale data across distributed systems.\nLimitations: Requires expertise and infrastructure, which might be overkill for smaller datasets.\n\n\n\n\n\n\n\n\n\n\nDBT (Data Build Tool)\n\n\n\n\n\nA transformation tool that applies SQL to prepare data for analytics workflows. DBT is particularly useful for pipelines that involve data warehouses.\n\nWhen to Use: SQL-centric environments where analytics-ready data is the end goal.\nLimitations: Focused on transformations within SQL databases; less versatile for non-SQL workflows.\n\n\n\n\n\n\n\n\n\n\nPolars\n\n\n\n\n\nAn open source Python & Rust library for data manipulation and analysis, offering rich functionality for handling structured data with performance in mind.\n\nWhen to Use: Small to large datasets or for prototyping workflows. A great substitute for Pandas when performance and speed are required.\nLimitations: Not designed for real-time processing.\n\n\n\n\n\n\n\n\n\n\nPrefect\n\n\n\n\n\nA workflow orchestration tool that enables robust scheduling and monitoring of data processing tasks.\n\nWhen to Use: Complex pipelines requiring orchestration of multiple processing steps.\nLimitations: Adds an orchestration layer, which might be unnecessary for simple workflows.\n\n\n\n\n\n\nData Validation Tools\nEnsuring the integrity and accuracy of data is essential to building reliable pipelines. Validation tools help detect anomalies, enforce schema compliance, and improve data quality. Some popular data validation tools include:\n\n\n\n\n\n\nGreat Expectations\n\n\n\n\n\nA framework for defining, executing, and documenting data validation checks. It integrates well with modern data stacks.\n\nWhen to Use: Custom validation rules with automated reporting needs.\nLimitations: May require significant customization for non-standard checks.\n\n\n\n\n\n\n\n\n\n\nTFDV (TensorFlow Data Validation)\n\n\n\n\n\nA library designed for detecting anomalies and validating schema in ML datasets.\n\nWhen to Use: TensorFlow-based workflows or pipelines requiring statistical validation.\nLimitations: Limited applicability outside of TensorFlow-centric environments.\n\n\n\n\n\n\n\n\n\n\nDeequ\n\n\n\n\n\nA library developed by AWS for validating large datasets using Spark. It focuses on automated quality checks and anomaly detection.\n\nWhen to Use: Spark-based pipelines requiring scalable data quality checks.\nLimitations: Limited compatibility with non-Spark environments.\n\n\n\n\n\n\nData Versioning Tools\nVersioning ensures traceability and reproducibility by tracking changes to datasets and workflows. It is vital for debugging, compliance, and collaboration. Some common data versioning tools include:\n\n\n\n\n\n\nDVC (Data Version Control)\n\n\n\n\n\nA Git-like tool for versioning data, models, and pipelines. It integrates seamlessly with Git repositories.\n\nWhen to Use: Managing medium to large datasets in collaborative environments.\nLimitations: Can be challenging to set up for teams unfamiliar with Git.\n\n\n\n\n\n\n\n\n\n\nDelta Lake\n\n\n\n\n\nA storage layer that adds versioning and ACID transactions to data lakes. It works well with distributed systems like Apache Spark.\n\nWhen to Use: Large-scale pipelines needing robust versioning and consistency.\nLimitations: Requires Spark for full functionality, adding complexity to smaller-scale workflows.\n\n\n\n\n\n\n\n\n\n\nLakeFS\n\n\n\n\n\nA Git-like version control system for data lakes. It enables branching and snapshotting of data workflows.\n\nWhen to Use: Data lakes requiring advanced version control features.\nLimitations: Best suited for teams already working with data lakes.\n\n\n\n\n\n\nNavigating a Rapidly Evolving Ecosystem\nThe DataOps tooling landscape is dynamic, with new tools and frameworks regularly introduced to address emerging challenges. This constant innovation provides opportunities to enhance workflows but also demands adaptability.\n\nFocus on Principles: Rather than mastering specific tools, prioritize understanding the core concepts of data ingestion, processing, validation, and versioning. This flexibility allows you to evaluate and adopt new tools as they emerge.\nExperiment and Iterate: Allocate time for evaluating tools that may better align with your pipeline’s evolving needs. Open-source communities and GitHub repositories are excellent resources for exploration.\nHybrid Tooling: Often, no single tool will address all requirements perfectly. Combining tools—such as using Airbyte for ingestion, DBT for processing, and Great Expectations for validation—creates tailored workflows.\nLeverage Community Support: Most tools provide extensive documentation, active forums, and integration guides. Engage with these communities to stay informed about updates and best practices.\n\nBy focusing on the principles of DataOps and staying informed about the ever-changing ecosystem, teams can design resilient and adaptable pipelines. In the following sections, we’ll explore how to combine these tools into cohesive workflows and build scalable, efficient data pipelines for machine learning systems.",
    "crumbs": [
      "DataOps",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Putting DataOps into Practice</span>"
    ]
  },
  {
    "objectID": "04-dataops-build.html#hands-on-example-a-youtube-data-pipeline",
    "href": "04-dataops-build.html#hands-on-example-a-youtube-data-pipeline",
    "title": "4  Putting DataOps into Practice",
    "section": "4.4 Hands-On Example: A YouTube Data Pipeline",
    "text": "4.4 Hands-On Example: A YouTube Data Pipeline\nNow that you’ve learned a bit about data pipelines, common paradigms, and tooling involved, let’s apply some of these concepts to create a simplified data pipeline that demonstrates how to ingest, process, and prepare YouTube data for downstream machine learning (ML) workflows. We’ll focus on collecting data like video titles, transcripts, views, likes, and comments. This example ties together concepts from previous chapters, including data ingestion, processing, validation, and versioning.\n\nPipeline Design\nThe pipeline design we’ll use will resemble more of an ETL process than an ELT. This is mainly for storage simplicity since this pipeline is run locally (whether that be on my machine or your machine) rather than in a cloud environment where storage capacity constraints are less of an issue.\nWe’ll use a couple of APIs to ingest our data, perform a little bit of data processing to clean and prepare our data for future analyses, and then illustrate some basic data validation along with versioning and storing our final prepared data.\n\n\n\n\n\n\nflowchart LR\n    subgraph ingest[Data Ingestion]\n      direction LR\n      subgraph p1[Ingest Video IDs]\n      end\n      subgraph p2[Ingest Video Stats]\n      end\n      subgraph p3[Ingest Video Transcript]\n      end\n    end\n    p1 --&gt; p2\n    p1 --&gt; p3\n    ingest --&gt; process(Process Raw Data)\n    process --&gt; Validate --&gt; Version --&gt; data[(Data storage)]\n\n\n\n\nFigure 4.3: High-level architecture of our data pipeline, which leverages an ETL process to ingest, process, validate, version and then store our data.\n\n\n\n\n\n\n\nBasic Requirements\nIf you’d like to follow along and execute this code then there are a few requirements you’ll need on your end.\n\n\n\n\n\n\nYou can find the requirements, source code for the data pipeline, and helper functions here.\n\n\n\nFirst, you’ll need to make sure you have the following Python libraries installed:\n\n\n\nPython version: 3.12.7 | packaged by Anaconda, Inc. | (main, Oct  4 2024, 08:28:27) [Clang 14.0.6 ]\n\ndvc==3.59.0\ngreat_expectations==1.3.1\njupyterlab==4.1.6\nmatplotlib==3.8.0\nnumpy==1.26.4\npandas&lt;=2.2\npython-dotenv==0.21.0\ntqdm==4.63.0\nyoutube_transcript_api==0.6.2\n\n\n\nNext, to simplify this example I have created helper functions to abstract away a lot of the finer code details. You can see this in the following imports where I am importing helper functions from the dataops_utils.py module. If you want to reproduce this pipeline then you can download the dataops_utils.py script here.\n\n\nimport great_expectations as gx\nimport os\nimport numpy as np\nimport pandas as pd\nimport unicodedata\nimport warnings\n\nfrom dataops_utils import (\n    ingest_channel_video_ids,\n    ingest_video_stats,\n    ingest_video_transcript,\n)\nfrom dotenv import load_dotenv\n\n\nLastly, We’ll be using the YouTube Data API to extract metadata and video information. To follow along, ensure you have:\n\nA Google Cloud account.\nAccess to the YouTube Data API to include an API key. See here to get started.\n\nOnce you have a Youtube API key then you’re ready to go! The next code chunk sets your API key and establishes the API URL and the channel ID. Note, I’m a golf junkie so the channel ID I am using is for Grant Horvat, a Youtube golfer with nearly 1 million followers.1\n\n\n# I have my API key set as an environment variable\nload_dotenv()\nAPI_KEY = os.getenv('YOUTUBE_API_KEY')\n\n# In your case you can add your API key here\nif API_KEY is None:\n    API_KEY = \"INSERT_YOUR_YOUTUBE_API_KEY\"\n\nBASE_URL = \"https://www.googleapis.com/youtube/v3\"\nCHANNEL_ID = 'UCgUueMmSpcl-aCTt5CuCKQw'\n\n\n\n\nData Ingestion\nThe first step is to ingest the Youtube data. To do so, we need to follow three steps:\n\nIngest all the video IDs provided by a given channel.\n\n\n\n# Ingest Youtube video IDs\nvideo_ids = ingest_channel_video_ids(API_KEY, CHANNEL_ID)\n\n# Example of what the first record looks like\nvideo_ids[0]\n\n{'channel_id': 'UCgUueMmSpcl-aCTt5CuCKQw',\n 'video_id': 'wzrIKGcOlsU',\n 'datetime': '2025-01-13T17:00:24Z',\n 'title': 'Rory McIlroy has another gear.'}\n\n\n\n\nUse the ingested video IDs to ingest Youtube stats for each video such as total views, likes, and comments.\n\n\n\n# Ingest Youtube video statistics\nvideo_data = ingest_video_stats(video_ids, API_KEY)\n\n# Example of the stats collected for the first video\nvideo_data[0]\n\n{'channel_id': 'UCgUueMmSpcl-aCTt5CuCKQw',\n 'video_id': 'wzrIKGcOlsU',\n 'datetime': '2025-01-13T17:00:24Z',\n 'title': 'Rory McIlroy has another gear.',\n 'views': '3142',\n 'likes': '304',\n 'comments': '16'}\n\n\n\n\nAnd lastly, ingest the transcript for each video.\n\n\n\n# Ingest Youtube video transcripts\nvideo_data = ingest_video_transcript(video_data)\n\n# Example of the final raw data that includes\n# video ID, title, date, stats, and transcript\nvideo_data[0]\n\n{'channel_id': 'UCgUueMmSpcl-aCTt5CuCKQw',\n 'video_id': 'wzrIKGcOlsU',\n 'datetime': '2025-01-13T17:00:24Z',\n 'title': 'Rory McIlroy has another gear.',\n 'views': '3142',\n 'likes': '304',\n 'comments': '16',\n 'transcript': \"I've never seen you go after the ball like this there it is wow that was it that was so good 190 190 nice that was hit well good what was that 72 as well that was good that was nice that was FL that was nice 127 A2 191 that's gone 34 there you go\"}\n\n\n\n\n\nData Processing\nFor data preprocessing, we’re going to first convert our data to a Pandas DataFrame\n\n\nraw_data = pd.DataFrame(video_data)\nraw_data.head()\n\n\n\n\n\n\n\n\nchannel_id\nvideo_id\ndatetime\ntitle\nviews\nlikes\ncomments\ntranscript\n\n\n\n\n0\nUCgUueMmSpcl-aCTt5CuCKQw\nwzrIKGcOlsU\n2025-01-13T17:00:24Z\nRory McIlroy has another gear.\n3142\n304\n16\nI've never seen you go after the ball like thi...\n\n\n1\nUCgUueMmSpcl-aCTt5CuCKQw\nPz42jFngEzM\n2025-01-13T03:25:25Z\nThank you. 1 Million ❤️\n59474\n6757\n428\n[Music] so sick let's go [Music]\n\n\n2\nUCgUueMmSpcl-aCTt5CuCKQw\nfSHh01YT0-Q\n2025-01-07T18:50:32Z\nTiger Woods hits the ball off the heel.\n64116\n2055\n30\nover the course of my career I've always hit t...\n\n\n3\nUCgUueMmSpcl-aCTt5CuCKQw\nerzLT7fy2r0\n2025-01-07T17:56:07Z\nTiger Woods liked my golf swing!\n122584\n4486\n76\nwhat's wrong with that yeah that came off you ...\n\n\n4\nUCgUueMmSpcl-aCTt5CuCKQw\n3O08SnyZ88U\n2025-01-07T17:07:04Z\nTiger Woods teaches me how to hit it straight!\n555884\n18286\n142\nwhat did you do in your career when you had a ...\n\n\n\n\n\n\n\n\nAnd then clean our data by:\n\nRemoving missing values. There are a few videos with no transcript text because the videos have no talking in them.\nRemoving duplicate observations. Just in case there is duplication in video information during the downloading process.\nRemove any inconsistent data types. This avoids errors during data processing and ensures consistency in operations applied to the data.\nRemove any observations that have invalid datetime values. This ensures chronological accuracy for any time-based analysis or trends.\nRemove any videos with minimal number of views. This filters out content that may not provide enough engagement data for meaningful insights.\nRemove any videos with very little transcript text. This ensures that the remaining data contains sufficient content for natural language processing or text-based analysis.\nClean the title and transcript text. This removes unnecessary noise, such as non-character string values (i.e. unicode characters), making the text suitable for analysis.\n\n\n\n# Remove rows with missing data\ncleaned_data = raw_data.dropna()\n\n# Remove duplicate rows\ncleaned_data = cleaned_data.drop_duplicates()\n\n# Remove any inconsistent data types\nfor col in ['views', 'likes', 'comments']:\n    cleaned_data[col] = pd.to_numeric(cleaned_data[col], errors='coerce')\n\n# Remove any observations that have invalid datetime values\ncleaned_data['datetime'] = pd.to_datetime(cleaned_data['datetime'], errors='coerce')\ncleaned_data = cleaned_data.dropna(subset=['datetime'])\n\n# Remove any observations where the views value is less than 3 standard deviations\n# from the mean\nmean_views = cleaned_data['views'].mean()\nstd_views = cleaned_data['views'].std()\ncleaned_data = cleaned_data[cleaned_data['views'] &gt;= (mean_views - 3 * std_views)]\n\n# Remove any observations where the transcript length is less than 3 standard deviations\n# from the mean transcript length\ncleaned_data['transcript_length'] = cleaned_data['transcript'].apply(lambda x: len(x) if pd.notnull(x) else 0)\nmean_transcript_length = cleaned_data['transcript_length'].mean()\nstd_transcript_length = cleaned_data['transcript_length'].std()\ncleaned_data = cleaned_data[cleaned_data['transcript_length'] &gt;= (mean_transcript_length - 3 * std_transcript_length)]\n\n# Remove/clean the title and transcript columns for non-character string values\n# (i.e. unicode characters)\ndef clean_text(text):\n    if isinstance(text, str):\n        return unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('ascii')\n    return text\n\ncleaned_data['title'] = cleaned_data['title'].apply(clean_text)\ncleaned_data['transcript'] = cleaned_data['transcript'].apply(clean_text)\n\ncleaned_data.head()\n\n\n\n\n\n\n\n\nchannel_id\nvideo_id\ndatetime\ntitle\nviews\nlikes\ncomments\ntranscript\ntranscript_length\n\n\n\n\n0\nUCgUueMmSpcl-aCTt5CuCKQw\nwzrIKGcOlsU\n2025-01-13 17:00:24+00:00\nRory McIlroy has another gear.\n3142\n304\n16\nI've never seen you go after the ball like thi...\n246\n\n\n1\nUCgUueMmSpcl-aCTt5CuCKQw\nPz42jFngEzM\n2025-01-13 03:25:25+00:00\nThank you. 1 Million\n59474\n6757\n428\n[Music] so sick let's go [Music]\n32\n\n\n2\nUCgUueMmSpcl-aCTt5CuCKQw\nfSHh01YT0-Q\n2025-01-07 18:50:32+00:00\nTiger Woods hits the ball off the heel.\n64116\n2055\n30\nover the course of my career I've always hit t...\n483\n\n\n3\nUCgUueMmSpcl-aCTt5CuCKQw\nerzLT7fy2r0\n2025-01-07 17:56:07+00:00\nTiger Woods liked my golf swing!\n122584\n4486\n76\nwhat's wrong with that yeah that came off you ...\n208\n\n\n4\nUCgUueMmSpcl-aCTt5CuCKQw\n3O08SnyZ88U\n2025-01-07 17:07:04+00:00\nTiger Woods teaches me how to hit it straight!\n555884\n18286\n142\nwhat did you do in your career when you had a ...\n646\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWhile there are many advanced techniques for preprocessing text data—such as more thorough cleaning, lemmatization, or converting text into embeddings for model input—the intent of this section is to focus on building a simplified example of an end-to-end data pipeline. These additional steps can significantly enhance the quality and utility of text data, but they are outside the scope of this example, which is designed to highlight the core concepts and practical steps involved in creating a data pipeline.\n\n\n\n\n\nData Validation\nNext, we’ll validate our data. To do so we’ll use Great Expectations and, first, we need to create a data and define our data assets.\n\n\n# Create Data Context.\ncontext = gx.get_context()\n\n# Create Data Source, Data Asset, Batch Definition, and Batch.\ndata_source = context.data_sources.add_pandas(\"pandas\")\ndata_asset = data_source.add_dataframe_asset(name=\"Youtube video data\")\nbatch_definition = data_asset.add_batch_definition_whole_dataframe(\"batch definition\")\nbatch = batch_definition.get_batch(batch_parameters={\"dataframe\": cleaned_data})\n\n\nNow that the infrastructure is set up, we’ll go through a process of validating that our data meets certain expectations. This code defines a data validation suite to ensure the integrity of our cleaned YouTube dataset. It consists of three primary validation steps:\n\nColumn Existence Validation: It verifies that all required columns (channel_id, video_id, datetime, title, views, likes, comments, transcript, and transcript_length) are present in the dataset. This step ensures that the essential structure of the dataset is intact.\nData Type Validation: It checks that each column contains values of the expected data type, such as Object for textual data (channel_id, video_id, title, and transcript), Timestamp for date-related fields, and int64 for numerical fields (views, likes, comments, and transcript_length). This ensures that data types align with the intended use of each column.\nNull Value Validation: It confirms that no empty or null values exist in the critical columns. This guarantees that the dataset is complete and avoids errors caused by missing data in downstream processes.\n\nFinally, the code executes the validation suite against a data batch and prints whether all validation checks were successful. This ensures the dataset meets the defined quality standards before being used in the data pipeline.\n\n\n# Create an Expectation Suite\nsuite = gx.ExpectationSuite(name=\"Youtube video data expectations\")\n\n# Add the Expectation Suite to the Data Context\nsuite = context.suites.add(suite)\n\n# Validate columns exist\nsuite.add_expectation(gx.expectations.ExpectColumnToExist(column='channel_id'))\nsuite.add_expectation(gx.expectations.ExpectColumnToExist(column='video_id'))\nsuite.add_expectation(gx.expectations.ExpectColumnToExist(column='datetime'))\nsuite.add_expectation(gx.expectations.ExpectColumnToExist(column='title'))\nsuite.add_expectation(gx.expectations.ExpectColumnToExist(column='views'))\nsuite.add_expectation(gx.expectations.ExpectColumnToExist(column='likes'))\nsuite.add_expectation(gx.expectations.ExpectColumnToExist(column='comments'))\nsuite.add_expectation(gx.expectations.ExpectColumnToExist(column='transcript'))\nsuite.add_expectation(gx.expectations.ExpectColumnToExist(column='transcript_length'))\n\n# Validate data types\nsuite.add_expectation(gx.expectations.ExpectColumnValuesToBeOfType(\n    column='channel_id', type_=\"object\"\n    ))\nsuite.add_expectation(gx.expectations.ExpectColumnValuesToBeOfType(\n    column='video_id', type_=\"object\"\n    ))\nsuite.add_expectation(gx.expectations.ExpectColumnValuesToBeOfType(\n    column='datetime', type_=\"Timestamp\"\n    ))\nsuite.add_expectation(gx.expectations.ExpectColumnValuesToBeOfType(\n    column='title', type_=\"object\"\n    ))\nsuite.add_expectation(gx.expectations.ExpectColumnValuesToBeOfType(\n    column='views', type_=\"int64\"\n    ))\nsuite.add_expectation(gx.expectations.ExpectColumnValuesToBeOfType(\n    column='likes', type_=\"int64\"\n    ))\nsuite.add_expectation(gx.expectations.ExpectColumnValuesToBeOfType(\n    column='comments', type_=\"int64\"\n    ))\nsuite.add_expectation(gx.expectations.ExpectColumnValuesToBeOfType(\n    column='transcript', type_=\"object\"\n    ))\nsuite.add_expectation(gx.expectations.ExpectColumnValuesToBeOfType(\n    column='transcript_length', type_=\"int64\"\n    ))\n\n# Validate no empty values exist\nsuite.add_expectation(gx.expectations.ExpectColumnValuesToNotBeNull(column='channel_id'))\nsuite.add_expectation(gx.expectations.ExpectColumnValuesToNotBeNull(column='video_id'))\nsuite.add_expectation(gx.expectations.ExpectColumnValuesToNotBeNull(column='datetime'))\nsuite.add_expectation(gx.expectations.ExpectColumnValuesToNotBeNull(column='title'))\nsuite.add_expectation(gx.expectations.ExpectColumnValuesToNotBeNull(column='views'))\nsuite.add_expectation(gx.expectations.ExpectColumnValuesToNotBeNull(column='likes'))\nsuite.add_expectation(gx.expectations.ExpectColumnValuesToNotBeNull(column='comments'))\nsuite.add_expectation(gx.expectations.ExpectColumnValuesToNotBeNull(column='transcript'))\nsuite.add_expectation(gx.expectations.ExpectColumnValuesToNotBeNull(column='transcript_length'))\n\n# Validate results\nvalidation_results = batch.validate(suite)\nprint(validation_results.success)\n\n\n\n\nTrue\n\n\n\n\n\n\n\n\n\nThe validation checks implemented here represent just a small subset of the capabilities available with Great Expectations. This powerful tool provides a wide array of validation checks, enabling you to ensure data quality at a much deeper level. For instance, you can validate the distribution of values to check for expected statistical patterns, ensure cardinality constraints to avoid duplicate or excessive values, or verify that data adheres to specific patterns (e.g., email formats or numeric ranges). These additional validations can further enhance the robustness and reliability of your data pipelines. Explore the full range of options here: Great Expectations Documentation - Expectations.\n\n\n\n\n\nData Versioning\nFor our purposes, we’re going to store the final cleaned_data to our project directory and then we’re going to use DVC (Data Version Control) to version and track changes to our data.\n\n\n\n\n\n\nDVC assumes you are working within a Git repository, as it relies on Git for tracking the metadata of your data files and pipelines.\n\nIf you’re familiar with Git: You can follow along with this example as long as you are working within a Git repository. Make sure you have initialized a Git repository (git init) in your project directory and have basic knowledge of Git commands.\nIf Git is new to you: Don’t worry! You can still follow along to understand the process conceptually, even if you don’t execute the Git commands. Later chapters in this book will provide a deeper dive into Git, equipping you with the knowledge to implement version control effectively.\n\nFor now, focus on understanding how DVC integrates with data pipelines to manage and version datasets systematically.\n\n\n\nSo, first, we’ll store our final data as a parquet file, which is just a more efficient approach than storing as a CSV file.\n\n\n# Ensure the directory exists\nos.makedirs('data', exist_ok=True)\n\n# Write the cleaned data to a parquet file\ncleaned_data.to_parquet('data/youtube_video_data.parquet', index=False)\n\n\nNext, we need to initialize DVC in our project by running the following command in the project root.\ndvc init\nThis initializes a .dvc directory with a few internal files to track data and pipeline versions. These should be added to Git.\ngit status\nChanges to be committed:\n        new file:   .dvc/.gitignore\n        new file:   .dvc/config\n        ...\ngit commit -m \"Initialize DVC\"\nNext, you need to use dvc add to start tracking the dataset file. This command creates a .dvc file (youtube_video_data.parquet.dvc) to track the file’s metadata and location. It also adds a .gitignore file so that the actual .parquet data file is not committed to git; instead the .parquet.dvc metadata file is committed.\ngit add data/youtube_video_data.parquet.dvc data/.gitignore\nNext, run the following commands to track and tag the dataset changes in Git.\ngit commit -m 'Initial processed Youtube data'\ngit tag -a \"v1.0\" -m \"Youtube data v1.0\"\nIf you have a remote storage location (e.g., AWS S3, Google Drive, Azure Blob Storage) configured for DVC, you can also push the data asset to that location to ensure it is stored offsite and sharable to the rest of your team/organization.\ndvc remote add -d myremote s3://mybucket/myproject\ndvc push\nNow, say we re-run this pipeline next week and get additional video data. We can just follow this same procedure to save and version the updated data:\n# Write the cleaned data to a parquet file\ncleaned_data.to_parquet('data/youtube_video_data.parquet', index=False)\n\n# Track the updated file\ngit add data/youtube_video_data.parquet.dvc\n\n# Commit the changes\ngit commit -m 'Updated Youtube data'\ngit tag -a \"v2.0\" -m \"Youtube data v2.0\"\n\n\n\n\n\n\nOur example demonstrates only the basic functionality of DVC, showcasing how it can be used to version datasets within a pipeline. However, DVC offers a wide range of additional features, including:\n\nTracking and managing entire pipelines.\nHandling large datasets efficiently with external storage integrations.\nAutomating experiment tracking and comparisons.\n\nTo explore the full potential of DVC and learn how to leverage its advanced capabilities, check out the official documentation at https://dvc.org/doc. This resource provides comprehensive guidance and examples for incorporating DVC into robust, end-to-end workflows.",
    "crumbs": [
      "DataOps",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Putting DataOps into Practice</span>"
    ]
  },
  {
    "objectID": "04-dataops-build.html#creating-reliable-scalable-data-pipelines",
    "href": "04-dataops-build.html#creating-reliable-scalable-data-pipelines",
    "title": "4  Putting DataOps into Practice",
    "section": "4.5 Creating Reliable & Scalable Data Pipelines",
    "text": "4.5 Creating Reliable & Scalable Data Pipelines\nDesigning reliable and scalable data pipelines requires adherence to the foundational principles that we discussed that promote maintainability, reproducibility, and efficiency. The hands-on example of the YouTube data pipeline demonstrates some of these design principles; however, there are areas where improvements could further align the pipeline with these principles.\n\nPrinciples Incorporated in the YouTube Data Pipeline\n\n\n\n\n\n\nModularity and Abstraction\n\n\n\n\n\n\nWhat We Did: The pipeline uses a modular design by encapsulating reusable functions within the dataops_utils module. This abstraction reduces complexity and makes the codebase more manageable, enabling easier updates and debugging.\nWhy It Matters: Modularity ensures that individual components, such as data cleaning, validation, and versioning, are independently testable and maintainable. Abstraction allows users to focus on higher-level logic without worrying about low-level details.\n\n\n\n\n\n\n\n\n\n\nReproducibility\n\n\n\n\n\n\nWhat We Did: By incorporating Git for version control and DVC for dataset tracking, the pipeline ensures that every step—from data ingestion to cleaning—can be reproduced with consistent results.\nWhy It Matters: Reproducibility is essential for debugging, auditing, and collaboration, especially when multiple team members work on the same project or when retraining models on historical data.\n\n\n\n\n\n\n\n\n\n\nData Validation\n\n\n\n\n\n\nWhat We Did: The pipeline integrates Great Expectations to validate the structure and quality of the dataset. This ensures that the data meets predefined criteria before it is processed further.\nWhy It Matters: Validation prevents poor-quality data from contaminating downstream workflows, thereby enhancing reliability and trust in the pipeline.\n\n\n\n\n\n\nLimitations and Areas for Improvement\n\n\n\n\n\n\nScalability\n\n\n\n\n\n\nCurrent Challenge: The YouTube API imposes daily quota limits on data retrieval, constraining the volume of data that can be ingested. This makes the pipeline less scalable for large-scale applications.\nPotential Solution: To overcome this limitation, consider implementing data caching strategies, batching requests over multiple days, or leveraging additional API keys across multiple accounts to distribute the load.\n\n\n\n\n\n\n\n\n\n\nAutomation\n\n\n\n\n\n\nCurrent Challenge: The pipeline is not automated and requires manual execution for each step. This limits its reliability and scalability in production environments.\nPotential Solution: Incorporate workflow automation tools such as Apache Airflow or Prefect to schedule and monitor the pipeline. Automating these tasks would enhance reliability and reduce manual intervention.\n\n\n\n\n\n\n\n\n\n\nFault Tolerance\n\n\n\n\n\n\nCurrent Challenge: The pipeline lacks mechanisms to handle failures gracefully, such as retrying failed API calls or dealing with incomplete datasets.\nPotential Solution: Introduce error-handling routines and logging mechanisms to ensure that the pipeline can recover from failures without disrupting downstream processes.\n\n\n\n\n\n\n\n\n\n\nScalable Storage and Compute\n\n\n\n\n\n\nCurrent Challenge: The pipeline is designed for small-scale use and does not leverage distributed computing or scalable storage solutions.\nPotential Solution: Transition to cloud-based storage systems like AWS S3 or Google Cloud Storage and integrate distributed computing frameworks such as Apache Spark for handling large datasets.\n\n\n\n\n\n\nBalancing Design Principles\nWhile the YouTube data pipeline incorporates key design principles such as modularity, abstraction, and reproducibility, there are trade-offs due to its simplicity. The primary objective of this example was to illustrate the foundational steps in building a data pipeline, rather than creating a production-ready system. For real-world applications, enhancing scalability, automation, and fault tolerance would be critical to align fully with the design principles of reliable and scalable systems.\nBy continuously iterating on these principles, teams can evolve simple pipelines into robust, production-ready systems capable of handling complex, large-scale workflows.",
    "crumbs": [
      "DataOps",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Putting DataOps into Practice</span>"
    ]
  },
  {
    "objectID": "04-dataops-build.html#summary",
    "href": "04-dataops-build.html#summary",
    "title": "4  Putting DataOps into Practice",
    "section": "4.6 Summary",
    "text": "4.6 Summary\nIn this chapter, we explored the practical aspects of building data pipelines to support robust machine learning workflows. By combining the principles and concepts introduced in the previous chapter, we demonstrated how to design, implement, and validate a data pipeline using tools like Pandas, Great Expectations, and DVC. The YouTube data pipeline provided a hands-on example of how data ingestion, processing, validation, and versioning can come together to create a cohesive system.\nWe also compared the ETL and ELT paradigms, highlighting their applications and trade-offs, and discussed how the design principles for good ML systems—such as modularity, abstraction, and reproducibility—can guide the creation of reliable and scalable pipelines. While the example illustrated foundational techniques, it also highlighted areas for improvement, such as addressing scalability and automation challenges.\nThis chapter aimed to provide you with the foundational knowledge and tools to build data pipelines tailored to your needs. As you advance, you’ll encounter more complex requirements and additional tools to refine and scale your workflows. In the next chapter",
    "crumbs": [
      "DataOps",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Putting DataOps into Practice</span>"
    ]
  },
  {
    "objectID": "04-dataops-build.html#exercise",
    "href": "04-dataops-build.html#exercise",
    "title": "4  Putting DataOps into Practice",
    "section": "4.7 Exercise",
    "text": "4.7 Exercise\nThis exercise will help you apply the concepts covered in this chapter to design and evaluate a data pipeline. The focus is on understanding the design principles, tools, and processes involved in building reliable and scalable data pipelines.\n\n\n\n\n\n\nPart 1: Conceptual Design\n\n\n\n\n\nScenario: Imagine you are tasked with building a data pipeline for an online retail store. The pipeline should:\n\nIngest daily sales data from a transactional database and inventory updates from an API.\nProcess the data to calculate daily revenue and identify low-stock items.\nValidate the data for missing or inconsistent records.\nVersion the processed data for auditing and historical tracking.\n\nTask:\n\nSketch a conceptual design for this pipeline. Include the steps for ingestion, processing, validation, and versioning.\nIdentify which tools from this chapter (e.g., Pandas, Great Expectations, DVC) you would use for each step and justify your choice.\n\n\n\n\n\n\n\n\n\n\nPart 2: Hands-On Experimentation\n\n\n\n\n\nUsing the YouTube pipeline example as a reference, answer the following:\n\nModify the Pipeline:\n\nExtend the provided YouTube pipeline to include additional validation checks (e.g., ensure views is greater than likes or that transcript_length is within a realistic range).\nWhat changes did you make to the validation suite, and why?\n\nExperiment with Versioning:\n\nCreate a new version of the cleaned_data DataFrame by simulating a change in the input data (e.g., remove videos with fewer than 10,000 views).\nUse DVC to version the new dataset and compare it to the original version. What do the differences reveal?\n\n\n\n\n\n\n\n\n\n\n\nPart 3: Reflecting on Design Principles\n\n\n\n\n\n\nEvaluate the Pipeline:\n\nReview the YouTube pipeline example and your modified pipeline. How well do they incorporate the design principles from Chapter 1 (e.g., modularity, scalability, reproducibility)?\nIdentify one principle that could be improved in your pipeline design. How would you address this in a future iteration?\n\nScenario-Based Discussion:\n\nImagine that the YouTube API introduces stricter quota limits. How would this impact the pipeline? Propose a solution to handle such constraints while ensuring the pipeline remains functional and reliable.",
    "crumbs": [
      "DataOps",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Putting DataOps into Practice</span>"
    ]
  },
  {
    "objectID": "04-dataops-build.html#footnotes",
    "href": "04-dataops-build.html#footnotes",
    "title": "4  Putting DataOps into Practice",
    "section": "",
    "text": "Feel free to explore a different Youtube channel. Note that the channel ID is different than the Youtube handle. For example, Grant Horvat’s Youtube handle is @GrantHorvatGolfs but his channel ID is UCgUueMmSpcl-aCTt5CuCKQw. The easiest way to find a channel’s ID is to go to the channel metadata where information for listed for “About”, “Links”, and “Channel details”. At the bottom of the pop up window is an option to “Share Channel” and then “Copy Channel ID”.↩︎",
    "crumbs": [
      "DataOps",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Putting DataOps into Practice</span>"
    ]
  },
  {
    "objectID": "05-modelops-role.html",
    "href": "05-modelops-role.html",
    "title": "5  The Role of ModelOps",
    "section": "",
    "text": "5.1 Key Components of ModelOps\nIn the rapidly evolving landscape of machine learning, building a successful ML system requires more than just high-quality data and powerful algorithms. While DataOps focuses on preparing and managing data pipelines, ModelOps takes over to manage the lifecycle of machine learning models, from training and experimentation to deployment and monitoring. As a critical subset of MLOps, ModelOps ensures that models are not only trained effectively but also deployed, tracked, and maintained in production environments with scalability and reliability in mind.\nModelOps bridges the gap between experimentation and real-world application, addressing the challenges that arise when transitioning models from development to production. It encompasses a wide array of practices, including experiment tracking for reproducibility, model versioning to manage iterations, deployment strategies for real-time and batch use cases, and monitoring to ensure models perform well under changing conditions. This chapter explores the vital role of ModelOps in modern ML workflows, emphasizing its importance in creating robust, maintainable, and high-performing systems that meet both business and technical objectives.\nModelOps encompasses several interconnected components that ensure the efficient management, deployment, and monitoring of machine learning models throughout their lifecycle. Each component plays a critical role in building a robust and scalable system. Below, we provide a high-level overview of these key components, setting the foundation for deeper exploration in subsequent sections and chapters.\nBy integrating these components, ModelOps provides a comprehensive framework for managing machine learning models at scale. Each component contributes to the overall reliability, scalability, and efficiency of the system. In the chapters ahead, we will delve deeper into each of these aspects and explore practical implementations to bring these concepts to life.",
    "crumbs": [
      "ModelOps",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>The Role of ModelOps</span>"
    ]
  },
  {
    "objectID": "05-modelops-role.html#key-components-of-modelops",
    "href": "05-modelops-role.html#key-components-of-modelops",
    "title": "5  The Role of ModelOps",
    "section": "",
    "text": "Model Training\n\n\n\n\n\nModel training lies at the heart of the machine learning process, involving the development and fine-tuning of models to perform specific tasks. The process is iterative, requiring multiple rounds of experimentation to optimize performance.\n\nWhy It Matters: Effective training pipelines ensure that models learn from data accurately and efficiently. Iterative experimentation, where hyperparameters, architectures, and data subsets are adjusted, is essential for improving model performance and addressing domain-specific challenges.\nTools: Frameworks like TensorFlow, PyTorch, and Scikit-learn provide powerful tools to build and train models. Additionally, automated machine learning (AutoML) platforms can assist in automating parts of this process, making training accessible to teams of varying expertise.\nIntegration in ModelOps: ModelOps ensures that training is reproducible and scalable, enabling teams to revisit experiments, fine-tune parameters, and evaluate different models systematically.\n\n\n\n\n\n\n\n\n\n\nExperiment Tracking\n\n\n\n\n\nTracking experiments is a cornerstone of ModelOps, allowing teams to log and analyze hyperparameters, datasets, metrics, and results. This practice ensures that experiments are reproducible and insights are shareable.\n\nWhy It Matters: Experiment tracking fosters reproducibility, enabling teams to revisit past experiments and understand what worked and why. It facilitates performance comparisons across models and encourages collaboration by providing a centralized repository of experiment logs.\nTools: Platforms like MLflow, Weights & Biases, and Comet.ml offer powerful capabilities for logging and visualizing experiments, making it easier to track progress and identify optimal configurations.\nIntegration in ModelOps: By incorporating experiment tracking, ModelOps ensures transparency and accountability in model development, reducing the risk of wasted effort and enhancing collaboration across teams.\n\n\n\n\n\n\n\n\n\n\nModel Management and Versioning\n\n\n\n\n\nAs models evolve, managing multiple versions across environments becomes crucial. Model management involves tracking models, their metadata, and dependencies to ensure consistent behavior across development, testing, and production.\n\nWhy It Matters: Without version control, it can be challenging to identify which model version is deployed or determine the source of performance changes. Proper model management reduces errors and ensures reproducibility across environments.\nTools: Solutions like DVC, MLflow Model Registry, and BentoML help manage and version models, capturing important metadata and dependencies for each version.\nIntegration in ModelOps: ModelOps leverages these tools to maintain a clear lineage of models, enabling smooth transitions between different stages of the model lifecycle and ensuring compliance with regulatory requirements.\n\n\n\n\n\n\n\n\n\n\nModel Deployment\n\n\n\n\n\nModel deployment focuses on integrating trained models into production systems to generate predictions or support decision-making. Deployment strategies vary depending on the use case, ranging from batch inference to real-time inference.\n\nWhy It Matters: Deployment bridges the gap between experimentation and real-world application, ensuring that models deliver value in production. Reliable deployment frameworks are critical for handling different environments, whether on local servers, cloud platforms, or edge devices (i.e. your mobile phone).\nTools: Frameworks like Docker, Kubernetes, FastAPI, and TensorFlow Serving simplify deployment by providing scalable and platform-agnostic solutions.\nChallenges: Deploying models across environments introduces complexities such as infrastructure compatibility, scalability, and latency requirements. ModelOps addresses these challenges by standardizing deployment workflows.\nIntegration in ModelOps: ModelOps ensures that deployment pipelines are repeatable, reliable, and easy to scale, minimizing disruptions during the transition to production.\n\n\n\n\n\n\n\n\n\n\nModel Monitoring\n\n\n\n\n\nMonitoring deployed models is essential for detecting and addressing issues like data drift, concept drift, and performance degradation. Without proper monitoring, even high-performing models can lose accuracy over time as data patterns change.\n\nWhy It Matters: Real-time monitoring is critical for mission-critical applications where undetected performance issues can lead to significant consequences. Monitoring also provides insights into the model’s behavior, helping teams optimize and retrain when needed.\nTools: Platforms such as Prometheus, Evidently AI, and Arize AI enable teams to track key metrics, identify anomalies, and visualize changes in data and performance over time.\nIntegration in ModelOps: ModelOps incorporates continuous monitoring as a feedback loop, ensuring that models remain relevant and accurate throughout their operational lifespan.",
    "crumbs": [
      "ModelOps",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>The Role of ModelOps</span>"
    ]
  },
  {
    "objectID": "05-modelops-role.html#why-modelops-is-crucial",
    "href": "05-modelops-role.html#why-modelops-is-crucial",
    "title": "5  The Role of ModelOps",
    "section": "5.2 Why ModelOps is Crucial",
    "text": "5.2 Why ModelOps is Crucial\nModelOps is a critical pillar of ML workflows, addressing the unique challenges associated with managing models at scale while ensuring their reliability, reproducibility, and compliance. Its importance lies in its ability to provide a structured, scalable framework for operationalizing ML systems. By key concerns such as scalability, reproducibility, collaboration, performance optimization, and transparency, ModelOps ensures that models are not just functional but also robust and adaptable in dynamic production environments.\n\n\n\n\n\n\nScalability\n\n\n\n\n\nIn ML systems, scalability is essential as models often need to handle large volumes of data and serve predictions to diverse user bases in real time. ModelOps facilitates scalability by standardizing deployment workflows, allowing organizations to deploy, monitor, and manage multiple models across various environments, from cloud-based systems to edge devices.\n\nTying to Design Principles: Scalability ensures that the system can accommodate growing demands without degradation in performance. Scalability also aligns with the principle of modularity, as ModelOps allows individual components (e.g., model training, inference) to be independently scaled. It also supports efficiency, ensuring that resources are optimally allocated to meet growing demands without overprovisioning.\nExample: Consider a real-time recommendation engine for a global e-commerce platform during peak shopping periods like Black Friday. The system must serve personalized recommendations to millions of users simultaneously. ModelOps enables the pipeline to auto-scale its deployment across multiple cloud regions, ensuring fast response times and consistent user experience, even during traffic surges.\n\n\n\n\n\n\n\n\n\n\nReproducibility\n\n\n\n\n\nReproducibility\nReproducibility ensures that machine learning models and their results can be reliably recreated, which is vital for auditing, debugging, and compliance. ModelOps facilitates reproducibility by standardizing the tracking of datasets, code, hyperparameters, and model versions throughout the lifecycle. This structured approach ensures that teams can pinpoint how specific outcomes were achieved and replicate them under similar conditions.\n\nTying to Design Principles: Reproducibility aligns with the principles of traceability and abstraction. By maintaining a clear record of every step in the model development process, ModelOps creates a transparent environment where workflows are easily understood and retraced. Abstraction ensures that complexity is encapsulated, making it easier to replicate specific processes.\nExample: Imagine a financial institution building a credit risk model. To ensure compliance with regulatory standards, the institution must demonstrate how the model was trained and how predictions are derived. ModelOps provides a comprehensive audit trail, from the version of the training dataset to the specific parameters used in the model, ensuring both internal and external stakeholders can validate the model’s integrity.\n\nBy embedding reproducibility into ML workflows, ModelOps not only builds trust in machine learning systems but also ensures their longevity and adaptability in dynamic business environments.\n\n\n\n\n\n\n\n\n\nCollaboration\n\n\n\n\n\nCollaboration\nCollaboration is a cornerstone of successful machine learning projects, as they often involve cross-functional teams, including data scientists, engineers, domain experts, and business stakeholders. ModelOps enhances collaboration by creating a structured framework that promotes transparency, knowledge sharing, and streamlined workflows. It ensures that all team members can contribute effectively without being bogged down by miscommunication or inefficiencies.\n\nTying to Design Principles: Collaboration directly supports the principles of modularity and clarity. Modularity allows different teams to work on separate components of the ML pipeline — such as model training, experimentation or deployment — without interfering with each other. Clarity ensures that the work is well-documented and understandable, fostering seamless communication across teams.\nExample: Consider a scenario where a healthcare organization is building a model to predict patient readmissions. The data engineering team preprocesses patient data, the data science team experiments with various algorithms, and the operations team deploys the final model. With a well-implemented ModelOps framework, all teams can track progress, share insights, and coordinate changes in a unified platform, reducing bottlenecks and improving productivity.\n\nBy fostering a collaborative environment, ModelOps ensures that teams can leverage diverse expertise, align on project goals, and deliver robust ML systems more efficiently. This shared understanding ultimately leads to models that are more effective and aligned with business needs.\n\n\n\n\n\n\n\n\n\nPerformance and Reliability\n\n\n\n\n\nPerformance and reliability are critical to the success of machine learning systems in production. A well-implemented ModelOps framework ensures that models not only meet performance benchmarks during deployment but also maintain their reliability over time, even as data distributions shift or system requirements evolve.\n\nEnsuring Consistency: ModelOps frameworks provide the tools to continuously monitor and evaluate models, ensuring they perform as expected across diverse scenarios. Real-time monitoring detects issues like data drift or concept drift, which can degrade model accuracy, enabling proactive retraining or adjustments.\nTying to Design Principles: Performance and reliability in ModelOps align directly with the principles of robustness, scalability, and monitorability:\n\nRobustness: Ensures models perform reliably under changing conditions, minimizing the risk of failure in unpredictable environments.\nScalability: Allows for seamless handling of growing data volumes or user loads without sacrificing model performance.\nMonitorability: Facilitates ongoing tracking of key metrics, providing insights into model behavior and enabling quick resolution of potential issues.\n\nExample: Imagine a fraud detection system for a financial institution. Such a system must operate reliably under peak transaction loads, such as during holiday shopping periods, while maintaining high accuracy. A robust ModelOps framework ensures the system can scale to handle the load, monitors performance metrics in real-time, and flags any unusual patterns, such as increased false positives or concept drift.\n\nBy prioritizing performance and reliability through ModelOps, organizations ensure that machine learning systems consistently meet their objectives, adapt to changing environments, and deliver dependable results in mission-critical applications.\n\n\n\n\n\n\n\n\n\nRegulatory Compliance\n\n\n\n\n\nRegulatory compliance is an increasingly critical consideration in machine learning, particularly in industries like finance, healthcare, and e-commerce. A robust ModelOps framework provides the transparency, traceability, and governance needed to meet legal and ethical standards while maintaining operational efficiency.\n\nEnsuring Compliance: ModelOps ensures that every step in the lifecycle of a machine learning model—data preprocessing, training, deployment, and monitoring—follows regulatory guidelines. Features such as model lineage tracking, automated logging, and reproducibility help organizations demonstrate adherence to data privacy laws like GDPR, HIPAA, or CCPA.\nTying to Design Principles: ModelOps directly supports the principles of transparency, reproducibility, and governance:\n\nTransparency: By documenting the end-to-end lifecycle of a model, ModelOps enables stakeholders to understand how predictions are made, which is critical for audits and stakeholder trust.\nReproducibility: Ensures that models can be re-created with the same results, supporting audits and enabling accountability.\nGovernance: Provides mechanisms to enforce consistent standards, policies, and workflows, reducing the risk of non-compliance.\n\nExample: Consider a healthcare organization using an ML model to predict patient readmissions. Regulatory compliance frameworks, such as HIPAA, require stringent controls on how patient data is handled, tracked, and used for predictions. A strong ModelOps system ensures all data is anonymized during preprocessing, tracks changes to the model, and logs every prediction made, providing a clear audit trail.\n\nBy embedding regulatory compliance into the ModelOps framework, organizations not only mitigate legal risks but also build trust with customers and stakeholders, positioning themselves as leaders in ethical and responsible AI.\n\n\n\nBy addressing these critical aspects — scalability, reproducibility, collaboration, performance optimization, and compliance — ModelOps ensures that ML systems are robust, reliable, and aligned with organizational goals. It integrates seamlessly into the larger MLOps framework, building on the foundational principles of DataOps to enable the successful deployment and operation of machine learning models in production. As ML applications continue to scale and diversify, ModelOps remains indispensable for meeting the demands of modern, data-driven organizations.",
    "crumbs": [
      "ModelOps",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>The Role of ModelOps</span>"
    ]
  },
  {
    "objectID": "05-modelops-role.html#challenges-in-implementing-modelops",
    "href": "05-modelops-role.html#challenges-in-implementing-modelops",
    "title": "5  The Role of ModelOps",
    "section": "5.3 Challenges in Implementing ModelOps",
    "text": "5.3 Challenges in Implementing ModelOps\nImplementing ModelOps, while essential for managing the lifecycle of machine learning models effectively, presents unique challenges. These challenges often arise from the technical complexity of integrating systems, the resource demands of infrastructure, the need for diverse expertise across teams, and the rapid pace of innovation in machine learning technology. Addressing these issues requires a combination of strategic planning, the right tools, and a commitment to continuous improvement.\n\n\n\n\n\n\nIntegration Complexity\n\n\n\n\n\nOne of the most significant hurdles in implementing ModelOps is achieving seamless interoperability between the myriad tools and systems used throughout the ML lifecycle. Data preprocessing, model training, deployment, and monitoring often involve different platforms, each with its own requirements and constraints.\n\nChallenge: Ensuring that tools for data versioning, experiment tracking, model serving, and monitoring work cohesively can lead to integration bottlenecks and workflow inefficiencies.\nExample: A team using separate tools like DVC for data versioning, MLflow for experiment tracking, and Kubernetes for deployment may struggle to integrate these systems into a unified pipeline.\nMitigation: To overcome this, organizations should adopt modular and standardized workflows that use APIs or connectors to bridge tools. Platforms offering end-to-end solutions, such as Weights & Biases or Vertex AI, can simplify integration efforts.\n\n\n\n\n\n\n\n\n\n\nInfrastructure Costs\n\n\n\n\n\nDeploying and monitoring large-scale machine learning models require significant computational resources, especially for real-time applications or systems handling high data volumes. The cost of scaling infrastructure to meet these demands can be prohibitive for many organizations.\n\nChallenge: Balancing the need for robust infrastructure with budget constraints can limit an organization’s ability to scale efficiently.\nExample: A real-time fraud detection system that ingests and analyzes thousands of transactions per second may require costly GPU clusters and distributed systems to maintain low latency and reliability.\nMitigation: Leveraging cloud-based solutions such as AWS SageMaker, Google AI Platform, or Azure ML can help organizations scale on-demand, reducing upfront costs. Cost-efficient strategies like model optimization (e.g., quantization, pruning) can also minimize resource usage without sacrificing performance.\n\n\n\n\n\n\n\n\n\n\nTeam Expertise\n\n\n\n\n\nModelOps spans a broad spectrum of tasks, requiring expertise in data science, software engineering, and DevOps. The need for such cross-functional skills can create gaps in knowledge and hinder implementation.\n\nChallenge: Building and managing a team with the diverse skill set necessary for ModelOps can be challenging, especially for organizations new to ML systems.\nExample: A data science team may excel in model development but lack the engineering expertise to deploy and monitor models in production environments.\nMitigation: Organizations can bridge these gaps by fostering collaboration between teams, investing in upskilling initiatives, and adopting tools that abstract away technical complexity, such as FastAPI for deployment or Evidently AI for monitoring.\n\n\n\n\n\n\n\n\n\n\nEvolving Standards\n\n\n\n\n\nThe rapid pace of advancements in machine learning technology introduces a moving target for ModelOps implementation. New tools, techniques, and best practices emerge frequently, requiring organizations to adapt continuously.\n\nChallenge: Staying current with evolving standards can be overwhelming, leading to technical debt if systems become outdated or incompatible with newer workflows.\nExample: A company might invest heavily in an experiment tracking tool only to find that a newer, more efficient tool becomes the industry standard shortly thereafter.\nMitigation: To remain agile, organizations should adopt flexible, modular architectures that allow for easy integration of new tools and technologies. Encouraging a culture of continuous learning and staying engaged with the broader ML community can also help teams keep pace with industry changes.\n\n\n\n\nModelOps is a cornerstone of scalable, reliable machine learning systems, but its implementation is fraught with challenges. From integrating diverse tools and managing infrastructure costs to addressing skill gaps and adapting to an ever-changing technological landscape, organizations must navigate significant complexities. By leveraging modular designs, scalable infrastructure, continuous training, and strategic tool adoption, teams can overcome these obstacles and build robust ModelOps workflows that support the evolving demands of machine learning at scale.",
    "crumbs": [
      "ModelOps",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>The Role of ModelOps</span>"
    ]
  },
  {
    "objectID": "05-modelops-role.html#summary",
    "href": "05-modelops-role.html#summary",
    "title": "5  The Role of ModelOps",
    "section": "5.4 Summary",
    "text": "5.4 Summary\nModelOps is a vital component of the MLOps framework, bridging the gap between data preparation and operationalizing machine learning models in production. This chapter explored the definition and importance of ModelOps, its role in managing the end-to-end lifecycle of machine learning models, and its key components, including model training, experiment tracking, model management, deployment, and monitoring. By ensuring scalability, reproducibility, collaboration, performance, and compliance, ModelOps provides the foundation for building reliable and impactful machine learning systems.\nDespite its critical importance, implementing ModelOps comes with its challenges. Integration complexities, infrastructure costs, the need for cross-functional expertise, and rapidly evolving ML standards are obstacles that organizations must overcome. However, these challenges are not insurmountable. With careful planning, strategic use of tools, and adherence to design principles such as modularity, scalability, and automation, teams can build robust ModelOps pipelines that support sustainable machine learning operations.\nAs we move forward, the next few chapters will delve into practical strategies, tools, and workflows that address these challenges and prepare you to successfully apply sound ModelOps principles. From experiment tracking to model deployment and monitoring, these chapters will equip you with the knowledge and skills needed to excel in managing machine learning systems at scale.",
    "crumbs": [
      "ModelOps",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>The Role of ModelOps</span>"
    ]
  },
  {
    "objectID": "05-modelops-role.html#exercise",
    "href": "05-modelops-role.html#exercise",
    "title": "5  The Role of ModelOps",
    "section": "5.5 Exercise",
    "text": "5.5 Exercise\n\nExercise: Relating MLOps Research to Practical ModelOps Principles\nThis exercise will require you to read the paper Machine Learning Operations (MLOps): Overview, Definition, and Architecture (Kreuzberger, Kühl, and Hirschl 2023) and relate its key concepts to the ideas presented in the last few chapters.\n\n\n\n\n\n\nMLOps Definition\n\n\n\n\n\n\nWhat is the paper’s definition of MLOps?\nHow does this compare to our discussion thus far around DataOps, ModelOps & DevOps?\n\n\n\n\n\n\n\n\n\n\nPrinciples\n\n\n\n\n\n\nWhat are the 9 principles of MLOps proposed by the paper?\nDiscuss how these principles are reflected in what you’ve learned thus far about DataOps, ModelOps & DevOps?\n\n\n\n\n\n\n\n\n\n\nTechnical Components\n\n\n\n\n\n\nWhat are the 9 technical components proposed by the paper that need to be implemented in an ML system?\nDiscuss how these principles are reflected in what you’ve learned thus far about DataOps, ModelOps & DevOps?\n\n\n\n\n\n\n\n\n\n\nCollaboration Across Roles\n\n\n\n\n\n\nShould we expect a data scientist alone to achieve the goals of MLOps?\nIf not, what roles are necessary in order to realize MLOps?\nSpecific to this chapter, what roles collaborate and how do they collaborate to successfully implement ModelOps?\n\n\n\n\n\n\n\n\n\n\nCase Study\n\n\n\n\n\nRevisit the hospital readmission prediction case study exercise from Chapter 2.\nUsing the Architecture and Workflow section and Figure 4 as a guide…\n\nIdentify questions you would need to answer to start building out the project architecture (i.e. a feature engineering, model experimentation, and automated ML workflow pipeline).\nIdentify the roles (i.e. data engineer, ML engineer, business stakeholder) you would need to collaborate to answer these questions.\nHow would you envision this kind of model being deployed and how often do you think the model would need to be updated? What would determine if this model needs to be updated?\nIdentify challenges you think you will encounter in building out this pipeline for this specific type of problem (i.e. Do you think there will be regulatory challenges? Maybe there will be system integration challenges since many hospitals have antiquated systems.)\n\n\n\n\n\n\n\n\nKreuzberger, Dominik, Niklas Kühl, and Sebastian Hirschl. 2023. “Machine Learning Operations (Mlops): Overview, Definition, and Architecture.” IEEE Access 11: 31866–79.",
    "crumbs": [
      "ModelOps",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>The Role of ModelOps</span>"
    ]
  },
  {
    "objectID": "06-modelops-experimenting.html",
    "href": "06-modelops-experimenting.html",
    "title": "6  Model Training and Experiment Tracking",
    "section": "",
    "text": "6.1 The Role of Experiment Tracking\nModel training is the cornerstone of machine learning, where algorithms learn patterns from data to make predictions or decisions. The process involves feeding a machine learning model with labeled data, enabling it to map inputs to desired outputs. This stage is critical because the effectiveness of the entire ML system hinges on the model’s ability to generalize from training data to unseen scenarios. However, achieving high performance is rarely straightforward and often requires iterative experimentation.\nTraining a model is not a one-and-done process. It involves an iterative cycle of hypothesis testing, parameter tuning, and evaluation to optimize performance. Data scientists experiment with hyperparameters, datasets, preprocessing techniques, and algorithms to achieve the best outcomes. Each experiment builds on the previous, gradually refining the model’s capabilities. This trial-and-error approach, while powerful, introduces complexities, especially when dealing with multiple experiments, diverse datasets, and varying metrics.\nThis is where experiment tracking becomes indispensable. Experiment tracking provides a structured approach to documenting every aspect of the training process, including hyperparameters, datasets, metrics, and results. By systematically recording these details, experiment tracking enables reproducibility, facilitates performance comparisons, and enhances collaboration among team members. Without it, teams risk losing valuable insights, duplicating efforts, or struggling to identify why a particular experiment succeeded or failed.\nIn this chapter, we will explore the concepts, tools, and best practices for model training and experiment tracking. By the end, you will understand how to set up workflows that not only optimize model performance but also ensure transparency, reproducibility, and efficiency in machine learning projects.\nExperiment tracking is a cornerstone of effective model training and machine learning workflows. It ensures that the process of developing and refining machine learning models is both systematic and reproducible. Without robust experiment tracking, teams can quickly lose visibility into the details of their experiments, leading to inefficiencies, redundancies, and missed opportunities for optimization.",
    "crumbs": [
      "ModelOps",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Model Training and Experiment Tracking</span>"
    ]
  },
  {
    "objectID": "06-modelops-experimenting.html#the-role-of-experiment-tracking",
    "href": "06-modelops-experimenting.html#the-role-of-experiment-tracking",
    "title": "6  Model Training and Experiment Tracking",
    "section": "",
    "text": "Why Experiment Tracking is Crucial\nMachine learning inherently involves iterative experimentation, where data scientists test various combinations of features, algorithms, hyperparameters, datasets, and preprocessing techniques.\n\n\n\n\n\n\nFor example, consider building a model to predict customer churn. A data scientist might experiment with different features, such as customer demographics, purchase history, and customer support interactions, to determine which combinations provide the most predictive power. They may even experiment with different feature engineering approaches such as one-hot encoding versus label encoding versus embeddings.\nSimultaneously, they might test various algorithms, such as logistic regression, random forests, or gradient boosting, each with its unique strengths. Within each algorithm, the data scientist adjusts hyperparameters like learning rates, tree depths, or regularization terms to optimize performance.\n\n\n\nTracking these experiments is vital for:\n\nReproducibility: In machine learning, reproducibility is paramount. Experiment tracking allows practitioners to retrace their steps and recreate previous results by logging hyperparameters, datasets, metrics, and configurations. This ensures that successful experiments can be reliably reproduced and built upon.\nPerformance Comparison: With multiple experiments generating diverse results, experiment tracking provides a systematic way to compare performance across iterations. By maintaining a history of experiments and their outcomes, data scientists can identify which configurations yield the best results and uncover patterns for improvement.\n\n\n\nFacilitating Collaboration\nExperiment tracking fosters collaboration by creating a shared repository of insights and progress across team members. When data scientists and engineers work together on complex projects, a robust tracking system offers:\n\nTransparency: Everyone on the team can view the history of experiments, including the rationale behind each decision and the results achieved. This shared knowledge base reduces silos and ensures alignment.\nKnowledge Sharing: Experiment tracking serves as a centralized resource for storing valuable learnings, enabling new team members to onboard quickly and contribute effectively.\nAccountability: By maintaining a detailed log of decisions and results, experiment tracking helps teams remain accountable for their work, supporting better communication and project management.\n\n\n\nChallenges Without a Tracking System\nWithout a dedicated experiment tracking system, managing experiments can quickly become chaotic, especially as the scale and complexity of machine learning projects grow. Common challenges include:\n\nLoss of Information: In the absence of structured tracking, valuable details like hyperparameter settings, dataset versions, or preprocessing techniques may be lost or poorly documented, making it difficult to recreate successful experiments.\nDuplication of Effort: Team members may unknowingly repeat similar experiments, wasting time and resources that could be better spent exploring new avenues.\nInefficient Debugging: When issues arise, the lack of a tracking system complicates the process of identifying which experiment or configuration caused the problem.\nHindered Scaling: As the number of experiments grows, managing them without a system becomes unmanageable, leading to a lack of focus and slower progress.\n\nBy addressing these challenges, experiment tracking systems provide a structured approach to managing the complexities of model training, ultimately enhancing efficiency, collaboration, and the quality of machine learning workflows. In the next section, we will explore tools and techniques for implementing effective experiment tracking systems.",
    "crumbs": [
      "ModelOps",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Model Training and Experiment Tracking</span>"
    ]
  },
  {
    "objectID": "06-modelops-experimenting.html#tools-for-experiment-tracking",
    "href": "06-modelops-experimenting.html#tools-for-experiment-tracking",
    "title": "6  Model Training and Experiment Tracking",
    "section": "6.2 Tools for Experiment Tracking",
    "text": "6.2 Tools for Experiment Tracking\nExperiment tracking tools streamline the process of managing and documenting machine learning experiments, making it easier to record hyperparameters, metrics, datasets, and results. By providing structured repositories for experiment metadata, these tools enhance reproducibility, foster collaboration, and support performance comparisons. Below, we explore three popular experiment tracking tools — MLflow, Weights & Biases, and Comet.ml — and discuss their unique features and strengths.\n\n\n\n\n\n\nMLflow\n\n\n\n\n\nMLflow is an open-source platform designed to manage the end-to-end machine learning lifecycle. Its experiment tracking module allows users to log parameters, metrics, and artifacts for each run.\n\nFeatures:\n\nLogs hyperparameters, metrics, and output files.\nIntegrates with popular libraries like TensorFlow, PyTorch, and Scikit-learn.\nOffers a user-friendly interface to compare experiments.\nIncludes a model registry for tracking model versions and deployment status.\n\nStrengths:\n\nEasy to set up and use with Python scripts or Jupyter notebooks.\nStrong focus on model versioning and lifecycle management.\nOpen-source, making it cost-effective and extensible.\n\nWhen to Use:\n\nIdeal for teams that prefer open-source solutions.\nWorks well for workflows with minimal external tool dependencies.\nSuitable for projects where model versioning is a priority.\n\n\n\n\n\n\n\n\n\n\n\nWeights & Biases\n\n\n\n\n\nWeights & Biases is a robust platform built for tracking experiments, collaborating on results, and visualizing model performance in real time.\n\nFeatures:\n\nTracks hyperparameters, metrics, datasets, and visualizations for experiments.\nProvides live dashboards to monitor experiment progress.\nEnables team collaboration with project workspaces and shared reports.\nIntegrates seamlessly with frameworks like Keras, PyTorch, and TensorFlow.\n\nStrengths:\n\nExcellent for teams with collaborative workflows.\nOffers detailed visualizations for experiment analysis.\nSupports large-scale projects with multiple contributors and pipelines.\n\nWhen to Use:\n\nPerfect for teams working on collaborative machine learning projects.\nBest for scenarios where real-time insights and advanced visualizations are critical.\nParticularly useful for distributed teams needing shared dashboards.\n\n\n\n\n\n\n\n\n\n\n\nComet.ml\n\n\n\n\n\nComet.ml is a powerful platform for managing, visualizing, and sharing experiments. It focuses on providing actionable insights and integrating with existing workflows.\n\nFeatures:\n\nLogs experiment parameters, metrics, assets, and source code.\nProvides real-time dashboards for tracking performance.\nOffers integrations with popular frameworks and cloud services.\nIncludes team collaboration features like shared experiment spaces.\n\nStrengths:\n\nComprehensive real-time insights and monitoring.\nExtensive integrations with cloud-based workflows.\nAllows easy sharing and exporting of experiment results.\n\nWhen to Use:\n\nIdeal for teams requiring real-time experiment tracking and reporting.\nSuitable for workflows heavily reliant on cloud environments.\nWorks well for organizations needing robust integration capabilities.\n\n\n\n\n\nEach tool offers unique strengths, and the choice depends on the team’s workflow, priorities, and resources. Below is a comparison to help select the right tool:\n\n\n\n\n\n\n\n\n\nFeature/Tool\nMLflow\nWeights & Biases\nComet.ml\n\n\n\n\nEase of Use\nSimple and intuitive\nUser-friendly with rich features\nEasy setup with intuitive UI\n\n\nCollaboration\nBasic\nAdvanced collaborative workspaces\nShared experiment spaces\n\n\nVisualization\nModerate\nAdvanced real-time dashboards\nReal-time insights\n\n\nIntegrations\nStrong support for ML libraries\nBroad support for frameworks\nExtensive cloud integrations\n\n\nBest For\nModel versioning and lifecycle\nTeam collaboration and visualization\nReal-time monitoring and insights\n\n\n\nExperiment tracking is critical for modern machine learning workflows, and the choice of tool depends on the specific needs of the project. Whether prioritizing collaboration, scalability, or integration, these tools provide robust capabilities to manage and optimize experiments effectively. In the upcoming sections, we will explore practical examples to demonstrate how these tools fit into end-to-end workflows.\n\n\n\n\n\n\nWhile this section focuses on MLflow, Weights & Biases, and Comet.ml, it’s important to note that other experimentation tracking tools are also available. For example, DVC (Data Version Control), while primarily known for data versioning, also supports experiment tracking by managing metadata and creating reproducible pipelines. Tools like DVC are particularly useful when experiment tracking is closely tied to versioning datasets and model artifacts. Exploring these alternatives can provide additional flexibility based on your specific project requirements and team preferences.",
    "crumbs": [
      "ModelOps",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Model Training and Experiment Tracking</span>"
    ]
  },
  {
    "objectID": "06-modelops-experimenting.html#key-components-to-track",
    "href": "06-modelops-experimenting.html#key-components-to-track",
    "title": "6  Model Training and Experiment Tracking",
    "section": "6.3 Key Components to Track",
    "text": "6.3 Key Components to Track\nEffective experiment tracking in machine learning involves systematically logging key components of your experiments. This not only ensures reproducibility but also allows for meaningful comparisons, collaboration, and continuous improvement. Below, we discuss the main components to track and why each is critical for successful machine learning workflows.\n\n\n\n\n\n\nExperiment Details\n\n\n\n\n\n\nWhat to Track: Experiment names, descriptions, and objectives.\nWhy It Matters: Clear documentation about the purpose and context of each experiment is essential for managing complex workflows. Without proper naming and descriptions, experiments can become difficult to distinguish, especially when managing numerous iterations. This clarity allows data scientists and engineers to:\n\nQuickly Identify Relevant Experiments: Teams can easily locate specific experiments to analyze results or refine models without sifting through unrelated runs.\nProvide Context for Results: Detailed descriptions capture the “why” behind an experiment, such as testing a hypothesis or exploring a new feature, which is invaluable for understanding outcomes.\nFacilitate Collaboration: With well-documented experiments, team members can seamlessly pick up where others left off, reducing duplication of effort and enhancing collective productivity.\nEnsure Long-Term Usability: Months after running experiments, clear documentation helps recall why certain configurations were tested, aiding in retrospective analysis or compliance audits.\n\n\n\n\n\n\n\n\n\n\n\nDataset and Preprocessing\n\n\n\n\n\n\nWhat to Track: Details about the dataset (e.g., source, version, size) and preprocessing steps (e.g., scaling, feature selection, encoding).\nWhy It Matters: Documenting the dataset and its transformations ensures reproducibility and accountability. It also helps in understanding how changes in data preprocessing affect model outcomes.\n\n\n\n\n\n\n\n\n\n\nHyperparameters and Model Configurations\n\n\n\n\n\n\nWhat to Track: Hyperparameters (e.g., learning rate, batch size) and model configurations (e.g., max depth for trees, kernel type for SVMs).\nWhy It Matters: Logging hyperparameters enables teams to understand how specific configurations impact model performance. Without this, reproducing successful experiments or diagnosing underperformance becomes nearly impossible.\n\n\n\n\n\n\n\n\n\n\nPerformance Metrics\n\n\n\n\n\n\nWhat to Track: Evaluation metrics such as RMSE, MAE, accuracy, or F1-score.\nWhy It Matters: Metrics provide a quantitative basis for comparing experiments and determining the best-performing model. Tracking these consistently over time helps identify performance trends.\n\n\n\n\n\n\n\n\n\n\nModel Artifacts\n\n\n\n\n\n\nWhat to Track: Trained models, including their weights and configurations, and any associated metadata such as example input and model architecture.\nWhy It Matters: Storing model artifacts ensures that the exact model version can be retrieved for inference, further training, or deployment.\n\n\n\n\n\n\n\n\n\n\nEnvironment and Dependencies\n\n\n\n\n\n\nWhat to Track: Information about the software environment, including library versions, frameworks, and system dependencies.\nWhy It Matters: Capturing environmental details ensures consistency across experiments, making it possible to reproduce results in the same setup.\n\n\n\n\nThese components form the backbone of a well-structured experiment tracking workflow, ensuring that every step of the machine learning lifecycle is documented, reproducible, and actionable. In the next section, we’ll bring these components to life with a hands-on example using MLflow. This will demonstrate how to implement an experiment tracking system in practice.",
    "crumbs": [
      "ModelOps",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Model Training and Experiment Tracking</span>"
    ]
  },
  {
    "objectID": "06-modelops-experimenting.html#sec-experiment-tracking",
    "href": "06-modelops-experimenting.html#sec-experiment-tracking",
    "title": "6  Model Training and Experiment Tracking",
    "section": "6.4 Hands-On Example: Implementing Experiment Tracking",
    "text": "6.4 Hands-On Example: Implementing Experiment Tracking\nIn this section, we’ll demonstrate an experiment tracking workflow using MLflow. We’ll highlight the key components of experiment tracking as we log a few model experiments, showcasing how MLflow helps to track, compare, and analyze their results systematically.\n\n\n\n\n\n\nFor this example, we’re going to pretent that we are data scientists for a national grocery retailer and we work on a team who’s responsibility is to forecast demand for produce. For this project, we are going to forecast demand specifically for apples.\n\n\n\n\nBasic Requirements\nIf you’d like to follow along and execute this code then there are a few requirements you’ll need on your end.\n\n\n\n\n\n\nYou can find the requirements, source code for the model experimentation tracking, and helper functions here.\n\n\n\nFirst, you’ll need to make sure you have the following Python libraries installed:\n\n\n\nPython version: 3.12.7 | packaged by Anaconda, Inc. | (main, Oct  4 2024, 08:28:27) [Clang 14.0.6 ]\n\nmlflow==2.12.2\nnumpy==1.26.4\npandas==2.1.4\nscikit-learn==1.5.1\nxgboost==2.1.3\n\n\n\nNext, let’s load our required libraries. You’ll notice that we load a function from an apple_data module; this is a local module I created to help create data for this example.\n\n\nimport mlflow\nimport pandas as pd\nimport numpy as np\nfrom sklearn import linear_model\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.preprocessing import StandardScaler\n\nfrom apple_data import generate_apple_sales_data_with_promo_adjustment\n\n\n\n\nCreate Experimentation Project\nThe first step is to create a new experiment. Since we are forecasting the demand of apples we’ll make it obvious in our project name.\n\n\n# Set experiment name\nmlflow.set_experiment(\"Forecasting Apple Demand\")\n\n&lt;Experiment: artifact_location='file:///Users/b294776/Desktop/workspace/training/UC/uc-bana-7075/ModelOps/mlruns/186119791991456899', creation_time=1737915596015, experiment_id='186119791991456899', last_update_time=1737915596015, lifecycle_stage='active', name='Forecasting Apple Demand', tags={}&gt;\n\n\n\nOnce you’ve run this code, you will notice an mlruns directory created in your current working directory. This is where all the parameters, metrics, and artifacts that we log for each experiment will be stored.\n\n\n\n\n\n\nDirectory Layout\n\n\n\n\nFigure 6.2: Directory layout after creating a new MLflow experiment. The mlruns directory will contain all the logs, parameters, metrics, and artifacts that we log for each experiment.\n\n\n\nMLflow comes with a user-friendly interface that allows you to visualize and manage your experiments. By running the command mlflow ui in your terminal, MLflow will start a local server and provide a URL (typically http://localhost:5000 or something similiar). The following is the output I get when I run mlflow ui:\nmlflow ui\n[2025-01-21 11:44:21 -0500] [62996] [INFO] Starting gunicorn 22.0.0\n[2025-01-21 11:44:21 -0500] [62996] [INFO] Listening at: http://127.0.0.1:5000 (62996)\n[2025-01-21 11:44:21 -0500] [62996] [INFO] Using worker: sync\n[2025-01-21 11:44:21 -0500] [62997] [INFO] Booting worker with pid: 62997\n[2025-01-21 11:44:21 -0500] [62998] [INFO] Booting worker with pid: 62998\n[2025-01-21 11:44:21 -0500] [62999] [INFO] Booting worker with pid: 62999\n[2025-01-21 11:44:21 -0500] [63001] [INFO] Booting worker with pid: 63001\nI can then click on the http://127.0.0.1:5000 URL listed in the output and this will open the MLflow UI in your web browser, where you can view detailed information about your experiments, including parameters, metrics, and artifacts. This interface makes it easy to compare different runs and track the progress of your machine learning projects.\n\n\n\n\n\n\nInitially, this UI will be empty because we haven’t ran any experiments yet but you can keep it open as we run the experiments that follow and see the dashboard update.\n\n\n\n\n\n\n\n\n\nMLflow Empty UI\n\n\n\n\nFigure 6.3: MLflow UI when no experiments have been run yet. This interface will populate with experiment details as we log our runs. Also, note the “Add Description” next to the experiment name; this is a great place to add clear documentation about the purpose and context of your experiment.\n\n\n\n\n\nSynthetic Training Data\nThe data that we will use for our ML modeling will be synthetic apple data created by the code in the apple_data.py module. This module generates a dataset that simulates apple demand, including features such as date, weather conditions, and promotional activities. By using synthetic data, we can control the complexity and characteristics of the dataset, ensuring it is suitable for demonstrating the experiment tracking workflow without relying on proprietary or sensitive real-world data.\n\n\ndata = generate_apple_sales_data_with_promo_adjustment(base_demand=1_000, n_rows=1_000)\n\ndata.head()\n\n\n\n\n\n\n\n\ndate\naverage_temperature\nrainfall\nweekend\nholiday\nprice_per_kg\npromo\ndemand\nprevious_days_demand\n\n\n\n\n0\n2022-05-03 13:19:56.029453\n30.584727\n6.786845\n0\n0\n2.502464\n0\n845\n845.0\n\n\n1\n2022-05-04 13:19:56.029452\n15.465069\n9.716520\n0\n0\n1.871180\n0\n879\n845.0\n\n\n2\n2022-05-05 13:19:56.029451\n10.786525\n1.099836\n0\n0\n1.149160\n0\n973\n879.0\n\n\n3\n2022-05-06 13:19:56.029449\n23.648154\n9.578136\n0\n0\n0.891414\n0\n969\n973.0\n\n\n4\n2022-05-07 13:19:56.029448\n13.861391\n4.693826\n1\n0\n0.737711\n0\n1173\n969.0\n\n\n\n\n\n\n\n\nNext, we will create out training and validation data splits:\n\n\n# Split the data into features and target and drop irrelevant date field and target field\nX = data.drop(columns=[\"date\", \"demand\"])\ny = data[\"demand\"]\n\n# Split the data into training and validation sets\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n\n\n\n\nExperiment 1: Regularized Regression\nFor the first experiment we’ll train a regularized regression model. To do so we:\n\nScale our training data (distributional requirement of regularized regression)\nTrain our model\nEvaluate the results\nLog our experiment run with MLFlow\n\n\n\n# Scale the data\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_val_scaled = scaler.transform(X_val)\n\n# Identify any feature transformations\nfeature_params = {\"preprocessing\": \"StandardScaler\"}\n\n\n\n\nmodel_params = {\n    \"alpha\": 0.5,\n}\n\n# Train the Ridge model\nreg = linear_model.Ridge(**model_params)\n\n# Fit the model on the training data\nreg.fit(X_train_scaled, y_train)\n\nRidge(alpha=0.5)In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.  Ridge?Documentation for RidgeiFittedRidge(alpha=0.5) \n\n\n\n\n\n# Predict on the validation set\ny_pred = reg.predict(X_val_scaled)\n\n# Calculate error metrics\nmae = mean_absolute_error(y_val, y_pred)\nmse = mean_squared_error(y_val, y_pred)\nrmse = np.sqrt(mse)\nr2 = r2_score(y_val, y_pred)\n\n# Assemble the metrics we're going to write into a collection\nmetrics = {\"mae\": mae, \"mse\": mse, \"rmse\": rmse, \"r2\": r2}\nmetrics\n\n{'mae': 47.61161452517159,\n 'mse': 3753.065769574699,\n 'rmse': 61.26227035928965,\n 'r2': 0.9001467080801084}\n\n\n\nThis next code chunk will log all the items we want to track into an experiment run titled “Regularized Regression”. In this example we are logging the training data, feature engineering steps applied, the hyperparameters applied to this model (i.e. alpha), the model results, and the actual model itself. Also, MLflow automatically tracks aspects of the environment, such as library versions and Python dependencies, and will log this information as well.\n\n\nrun_name = \"Regularized Regression\"\nartifact_path = \"artifacts\"\n\n# Initiate the MLflow run context\nwith mlflow.start_run(run_name=run_name) as run:\n\n    # Log dataset and preprocessing details\n    training_data = pd.concat([X_train, y_train], axis=1)\n    training_input = mlflow.data.from_pandas(training_data, targets='demand')\n    mlflow.log_input(training_input, context=\"training data\")\n    mlflow.log_params(feature_params)\n\n    # Log the parameters used for the model fit\n    mlflow.log_params(model_params)\n\n    # Log the error metrics that were calculated during validation\n    mlflow.log_metrics(metrics)\n\n    # Log an instance of the trained model for later use\n    mlflow.sklearn.log_model(sk_model=reg, input_example=X_val_scaled, artifact_path=artifact_path)\n\n\nNow, if we look at the MLFlow UI, we’ll see our experiment run:\n\n\n\n\n\n\nMLflow Empty UI\n\n\n\n\nFigure 6.4: MLflow UI after we ran our initial regularized regression experiment.\n\n\n\nAnd if we click on the experiment run we can see the information logged with that experiment:\n\n\n\n\n\n\n\n\n\n\n\n(a) Experiment Info\n\n\n\n\n\n\n\n\n\n\n\n(b) Experiment Artifacts\n\n\n\n\n\n\n\nFigure 6.5: We can see various details of the regularized regression experiment run in the MLflow UI such as the logged hyperparameter values, the model evaluation metrics, and even the artifacts logged such as the model and environment requirements to recreate the model.\n\n\n\n\n\nAdditional Experiments\nIf you take a look at the model experimentation notebook you will see that we followed this up with 3 additional experiment runs:\n\nA random forest model with set hyperparameter values\nA random forest hyperparameter grid search\nA regularized regression hyperparameter grid search\n\nEach experiment run followed a similar process to log the experiment run details in MLFlow. Consequently, our MLFlow UI now shows 4 different experiments runs. The UI also allows us to compare the different experiment runs across our evaluation metrics.\n\n\n\n\n\n\nExperiment Comparison\n\n\n\n\nFigure 6.6: Comparing the model evaluation metrics for the various experiments.\n\n\n\n\n\n\n\n\n\nThis hands-on example demonstrates just some of the basic functionalities of MLflow’s experiment tracking capabilities. MLflow offers a wide range of features for more advanced experiment tracking and comparison capabilities. To explore these capabilities further, check out the MLflow documentation.",
    "crumbs": [
      "ModelOps",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Model Training and Experiment Tracking</span>"
    ]
  },
  {
    "objectID": "06-modelops-experimenting.html#common-challenges",
    "href": "06-modelops-experimenting.html#common-challenges",
    "title": "6  Model Training and Experiment Tracking",
    "section": "6.5 Common Challenges",
    "text": "6.5 Common Challenges\nModel training and experimentation tracking are essential for building effective machine learning systems, but they come with notable challenges:\n\n\n\n\n\n\nManaging a High Volume of Experiments\n\n\n\n\n\nAs projects grow, teams often run dozens—or even hundreds—of experiments to optimize models. Without a structured tracking system, it becomes difficult to organize, retrieve, and compare results.\nSolution: Use centralized tools like MLflow or Weights & Biases to log experiments automatically and enable searchability across iterations.Moreover, its important to establish how to organize experiment runs so as the volume of runs increase, organization and searchability remain intact.\n\n\n\n\n\n\n\n\n\nMaintaining Consistency in Logging Practices\n\n\n\n\n\nInconsistent logging of hyperparameters, metrics, or datasets can lead to confusion and reproducibility issues.\nSolution: Establish clear team-wide guidelines for experiment tracking, specifying what should be logged (e.g., hyperparameters, datasets, metrics) and how to format entries.\n\n\n\n\n\n\n\n\n\nCollaborating Across Teams\n\n\n\n\n\nCollaboration between data scientists, engineers, and stakeholders can become fragmented when different teams use varying tools or workflows.\nSolution: Adopt platforms that support shared access, real-time updates, and version control. Tools like DVC, MLflow, and Comet.ml facilitate collaborative experimentation and model management that can make enterprise-wide collaboration easier.\n\n\n\nBy addressing these challenges through robust tools and consistent practices, teams can streamline workflows, enhance collaboration, and improve the overall quality of their machine learning systems.\n\n\n\n\n\n\nTo explore more strategies for overcoming these challenges:\n\nExperiment Tracking Best Practices (Weights & Biases)\nEffective Experimentation with MLflow",
    "crumbs": [
      "ModelOps",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Model Training and Experiment Tracking</span>"
    ]
  },
  {
    "objectID": "06-modelops-experimenting.html#summary",
    "href": "06-modelops-experimenting.html#summary",
    "title": "6  Model Training and Experiment Tracking",
    "section": "6.6 Summary",
    "text": "6.6 Summary\nIn this chapter, we explored the critical aspects of model training and experiment tracking, emphasizing the importance of structured workflows for managing machine learning experiments. We covered key components to track—datasets, hyperparameters, metrics, and model artifacts—and demonstrated how tools like MLflow can streamline this process. Additionally, we addressed common challenges such as managing high experiment volumes, maintaining consistency, and fostering collaboration across teams.\nExperiment tracking is a cornerstone of ModelOps, ensuring reproducibility, performance comparison, and effective collaboration. By establishing robust tracking workflows, teams can optimize their machine learning models while maintaining clarity and organization.\nIn the next chapter, we will build on this foundation by delving into model versioning and registration, showcasing how to manage and deploy trained models systematically. This step will further integrate and solidify the principles of scalable and reliable ModelOps practices.",
    "crumbs": [
      "ModelOps",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Model Training and Experiment Tracking</span>"
    ]
  },
  {
    "objectID": "06-modelops-experimenting.html#sec-model-experimentation-exercise",
    "href": "06-modelops-experimenting.html#sec-model-experimentation-exercise",
    "title": "6  Model Training and Experiment Tracking",
    "section": "6.7 Exercise",
    "text": "6.7 Exercise\nThis exercise has three parts: conceptual design, hands-on experimentation, and reflection on design principles. The goal is to gain practical experience in experiment tracking with MLflow while considering how key principles of good ML system design apply to model experimentation.\n\n\n\n\n\n\nContext for the Exercise\n\n\n\n\n\nImagine you are working as a data scientist for Zillow, a company known for its real estate insights and services. Your task is to develop a machine learning model that predicts home prices in California. This model will help Zillow provide more accurate price estimates for listings, improving user experience and market insights.\nYou’ll use the California Housing dataset to simulate this analysis, focusing on building and tracking experiments to evaluate different models and techniques. By leveraging experiment tracking with MLflow, you’ll ensure that your workflow is structured, reproducible, and aligned with industry standards for machine learning system design.\n\n\n\n\n\n\n\n\n\nPart 1: Conceptual Design\n\n\n\n\n\nBefore diving into implementation, think through the design of an experiment tracking workflow for the California Housing dataset. Consider the following:\n\nExperiment Objectives:\n\nDefine the purpose of the experiments. For example:\n\nCompare the performance of different regression models on the California Housing dataset.\nEvaluate the impact of feature engineering or hyperparameter tuning.\n\n\nKey Components to Track:\n\nIdentify what you need to log during the experiments:\n\nExperiment run metadata - what name and description would you include as metadata?\nModel training data - are there any preprocessing/feature engineering steps you’ll need to perform and log?\nWhat models do you want to experiment with?\nWhat hyperparameters need to be tracked for each model?\nWhich evaluation metrics do you want to assess (e.g., RMSE, MAE, R²)?\nAnything else you should track?\n\n\nOutcome Goals:\n\nDefine success criteria for the experiments:\n\nWhich metrics will determine the best model?\nHow will you compare results across experiments?\n\n\n\nDocument your conceptual plan in a short paragraph or diagram.\n\n\n\n\n\n\n\n\n\nPart 2: Hands-On Experimentation\n\n\n\n\n\nNow implement your design using the California Housing dataset and MLflow. Follow these steps:\n\nSet Up Your Environment:\n\nInstall necessary libraries:\npip install mlflow scikit-learn pandas matplotlib\nImport required modules:\nimport mlflow\nimport mlflow.sklearn\nfrom sklearn.datasets import fetch_california_housing\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n\nCreate an MLflow Experiment:\n\nInitialize and name your MLflow experiment:\nmlflow.set_experiment(\"&lt;Experiment name&gt;\")\n\nPrepare the Dataset:\n\nLoad and split the data:\ndata = fetch_california_housing(as_frame=True)\nX = data.data\ny = data.target\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\nTrain and Log Models:\n\nTrain at least three models (e.g., Random Forest, Linear Regression, Decision Tree).\nFor each model, log the key components identified in Part 1:\n\nTraining data details.\nHyperparameters.\nMetrics.\nModel artifacts.\n\n\nCompare Results in MLflow:\n\nLaunch the MLflow UI to compare experiment results.\nIdentify the best-performing model based on metrics like RMSE or R².\nExamine the logged parameters and artifacts of the best model.\n\n\n\n\n\n\n\n\n\n\n\nPart 3: Reflection on Design Principles\n\n\n\n\n\nGo back to Chapter 1.3 and reflect on how the experiment tracking workflow aligns with at least 4 of the principles discussed. For example:\n\nModularity:\n\nHow did separating the data preparation, model training, and logging components make the workflow more organized and reusable? Could this be improved?\n\nReproducibility:\n\nHow did MLflow’s logging features ensure reproducibility of experiments, enabling you to retrace steps for the best-performing model?\n\nScalability:\n\nConsider how this workflow might scale to larger datasets, more complex model comparisons, or a higher volume of experiment runs.\n\nAbstraction:\n\nReflect on how MLflow abstracted away many tracking complexities, allowing you to focus on experimentation.",
    "crumbs": [
      "ModelOps",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Model Training and Experiment Tracking</span>"
    ]
  },
  {
    "objectID": "07-modelops-versioning.html",
    "href": "07-modelops-versioning.html",
    "title": "7  Model Versioning and Reproducibility",
    "section": "",
    "text": "7.1 The Need for Model Versioning\nAs machine learning systems become more integral to business operations, the need for reliable, traceable, and maintainable workflows grows exponentially. Model versioning and reproducibility lie at the heart of achieving this reliability, forming the foundation for robust ModelOps practices. These concepts ensure that teams can iterate on models, track their evolution, and reproduce results across different environments and timelines, even in the face of complex pipelines and evolving data.\nIn the previous chapter, we explored the importance of experiment tracking, which enables teams to document the evolution of models by logging hyperparameters, datasets, metrics, and results for each experiment. While experiment tracking provides a granular view of individual runs and their outcomes, model versioning builds on this by offering a systematic way to manage and track the lifecycle of fully trained models. Together, these practices ensure that the best-performing models identified during experimentation can be efficiently deployed, monitored, and revisited when necessary.\nModel versioning involves systematically managing multiple iterations of machine learning models, capturing changes in architectures, hyperparameters, training data, and evaluation metrics. By maintaining clear records of model versions, teams can track progress, compare performance, and ensure seamless handoffs between development and deployment stages. For example, versioning allows data scientists to confidently deploy the best-performing models identified during the experimentation phase while maintaining the ability to revert to earlier versions if needed.\nReproducibility ensures that experiments and results can be reliably recreated, which complements model versioning by providing consistency across environments. This requires capturing all the components that influence model training, including data versions, preprocessing steps, random seeds, and dependencies. Together, versioning and reproducibility are critical for debugging, auditing, and building trust in machine learning systems. Without them, even minor discrepancies in results can lead to significant challenges in troubleshooting and compliance.\nThis chapter builds on the previous chapter to demonstrate how model versioning and reproducibility come to life in a real-world scenario. By integrating the principles of experiment tracking with robust versioning practices, we will illustrate how to maintain a transparent and scalable workflow. By the end of this chapter, you will understand how model versioning and reproducibility complement experiment tracking and learn to implement these practices effectively in your machine learning projects.\nIn the rapidly evolving field of machine learning, managing models is no small feat. The lifecycle of a machine learning model is iterative, often requiring multiple rounds of experimentation, updates, and deployments. Without a structured approach to versioning, this complexity can lead to challenges in maintaining consistency, ensuring reproducibility, and managing multiple iterations simultaneously deployed across various business processes.",
    "crumbs": [
      "ModelOps",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Model Versioning and Reproducibility</span>"
    ]
  },
  {
    "objectID": "07-modelops-versioning.html#the-need-for-model-versioning",
    "href": "07-modelops-versioning.html#the-need-for-model-versioning",
    "title": "7  Model Versioning and Reproducibility",
    "section": "",
    "text": "Challenges of Managing Multiple Models\nMachine learning systems rarely rely on a single model. Instead, organizations frequently manage multiple models, each tailored to specific use cases, business processes, or datasets. For example, an e-commerce platform may deploy separate models for product recommendations, dynamic pricing, and customer churn prediction. Additionally, even within a single use case, data scientists often iterate on models, creating slightly different versions to test new features, hyperparameters, or datasets.\nThis proliferation of models introduces several challenges:\n\n\n\n\n\n\nInconsistency\n\n\n\n\n\nIt becomes difficult to ensure consistency in results if the lineage and differences between model versions are unclear.\n\n\n\n\n\n\n\n\n\nOperational Complexity\n\n\n\n\n\nManaging multiple models across environments (e.g., testing, staging, production) can lead to confusion about which model is live or should be retrained.\n\n\n\n\n\n\n\n\n\nDeployment Confusion\n\n\n\n\n\nOrganizations may inadvertently deploy outdated or suboptimal models, undermining the business objectives they aim to support.\n\n\n\n\n\n\n\n\n\nReal-world examples highlight these challenges. For instance, Booking.com reported in their paper 150 Successful Machine Learning Models: 6 Lessons Learned at Booking.com that the lack of clear versioning early on hindered their scalability and led to inefficiencies in updating and deploying models.\n\n\n\n\n\nVersioning for Traceability and Consistency\nModel versioning is a critical practice that provides traceability throughout the lifecycle of a machine learning model. By versioning models, organizations can:\n\nLink Experiments to Deployment: Each model deployed to production can be traced back to the specific experiment or set of experiments that informed its development, including the dataset, preprocessing steps, and hyperparameters used.\nAudit Performance: Versioning allows organizations to compare historical performance metrics against current results to determine if changes have introduced regressions or improvements.\nFacilitate Rollbacks: If a newly deployed model underperforms or introduces unintended biases, versioning ensures that the organization can quickly revert to a previous, more reliable version.\n\n\n\nExamples of When Model Versioning is Essential\nVersioning models is particularly crucial in the following scenarios:\n\n\n\n\n\n\nRetraining with Updated Data\n\n\n\n\n\nWhen new data becomes available, retraining models often results in improved accuracy. Versioning ensures that stakeholders can differentiate between the original and updated models and evaluate performance gains.\nExample: A weather forecasting system regularly retrains models with the latest meteorological data. Versioning ensures traceability between the datasets and the updated predictions.\n\n\n\n\n\n\n\n\n\nHyperparameter Tuning\n\n\n\n\n\nSmall tweaks in hyperparameters can lead to significant performance differences. Versioning ensures that the optimal configuration is clearly documented and reproducible.\nExample: A fraud detection system adjusts sensitivity thresholds to minimize false positives. By versioning each iteration, teams can identify the version with the best balance of precision and recall.\n\n\n\n\n\n\n\n\n\nMultiple Models for the Same Business Process\n\n\n\n\n\nOften, organizations deploy multiple models to serve the same process but target different subgroups or geographic regions. Versioning helps manage this complexity.\nExample: A recommendation engine deploys region-specific models for North America, Europe, and Asia. Versioning ensures clarity in model assignments and simplifies future updates.\n\n\n\n\n\n\n\n\n\nRegulatory and Compliance Requirements\n\n\n\n\n\nFor industries with stringent regulatory requirements, such as finance and healthcare, versioning is essential for audits and compliance.\nExample: A credit scoring model must demonstrate consistency with historical performance when audited. Versioning ensures all artifacts, from datasets to hyperparameters, are well-documented and reproducible.\n\n\n\nModel versioning builds directly on the principles introduced in the previous chapter on experiment tracking. While experiment tracking captures the journey of a model during development, versioning ensures that this journey remains accessible and reproducible as the model evolves. Together, these practices provide a comprehensive framework for managing machine learning systems.",
    "crumbs": [
      "ModelOps",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Model Versioning and Reproducibility</span>"
    ]
  },
  {
    "objectID": "07-modelops-versioning.html#key-components-of-model-versioning",
    "href": "07-modelops-versioning.html#key-components-of-model-versioning",
    "title": "7  Model Versioning and Reproducibility",
    "section": "7.2 Key Components of Model Versioning",
    "text": "7.2 Key Components of Model Versioning\nModel versioning builds upon the principles and practices of experiment tracking, serving as a bridge between experimentation and production. While experiment tracking documents the various iterations, configurations, and metrics of machine learning experiments, model versioning focuses on systematically capturing, storing, and managing these components to ensure traceability and reproducibility in production environments.\nThis continuity between experiment tracking and model versioning is essential for creating scalable, maintainable, and reliable machine learning workflows. Below, we revisit some of the key components from experiment tracking and highlight how their roles evolve in the context of model versioning.\n\n\n\n\n\n\nDatasets\n\n\n\n\n\n\nExperiment Tracking Context: During experimentation, training datasets are logged to ensure that each experiment run is linked to the specific data used for training and validation. We saw this in Section 6.4 where the training datasets for each experiment run was logged. This helps data scientists analyze the impact of data and feature engineering variations on model performance.\nIn Model Versioning: Datasets are versioned alongside models to maintain traceability through deployment and future use. Consequently, if we were to version the best-performing model in the apple demand forecasting example (Section 6.4), the training datasets used for this model would also be stored/linked to ensure that retraining or debugging efforts can recreate the exact conditions under which a versioned/deployed model was developed.\nWhy It Matters: This linkage ensures that models can be reproduced and validated under the same data conditions, making it easier to address drift, audit decisions, or meet regulatory requirements.\n\n\n\n\n\n\n\n\n\n\nHyperparameters\n\n\n\n\n\n\nExperiment Tracking Context: Hyperparameters like learning rates, batch sizes, and optimization strategies are logged to document how they influence model performance.\nIn Model Versioning: The hyperparameters for the best-performing model are saved as part of the model metadata, ensuring they can be reused for retraining or deployment. For instance, if a random forest model performs best then its tree depth, number of estimators, splitting criteria, and any other hyperparameters should be preserved as a model is versioned and deployed.\nWhy It Matters: Consistent hyperparameter tracking enables reproducibility and helps optimize deployment configurations without re-running unnecessary experiments.\n\n\n\n\n\n\n\n\n\n\nMetrics\n\n\n\n\n\n\nExperiment Tracking Context: Metrics such as RMSE, accuracy, or precision are logged to evaluate and compare model performance across experiments.\nIn Model Versioning: Metrics become part of the versioned model’s metadata, serving as critical benchmarks for deployment decisions. For example, if a model is versioned and deployed, then this model is often referred to as a champion model. Future model modifications are often referred to as challengers. In order to compare champion and challenger models, we must continue to have their evaluation metrics stored alongside them so that they can be compared to determine if a challenger model should become the new champion model.\nWhy It Matters: Storing metrics alongside model versions ensures that deployment decisions are informed by objective performance comparisons.\n\n\n\n\n\n\n\n\n\n\nModel Artifacts\n\n\n\n\n\n\nExperiment Tracking Context: During experimentation, model artifacts (e.g., weights, configuration files, saved model – .pkl, .pb) are usually logged as we demonstrated in Section 6.4.\nIn Model Versioning: The trained model artifacts are also preserved as part of the versioning process. These artifacts represent the operational core of the machine learning workflow and must be reliably stored for deployment and retraining.\nWhy It Matters: By versioning artifacts, teams ensure that deployed models can be reloaded, audited, and updated without ambiguity and ensures the exact prediction logic can be reproduced when needed.\n\n\n\n\n\n\n\n\n\n\nDeployment Metadata\n\n\n\n\n\n\nExperiment Tracking Context: During experiment tracking, environment configurations, runtime dependencies, and scaling parameters can be logged but are not always done so.\nIn Model Versioning: However, for models that are versioned and intended to be deployed, this information becomes critical to facilitate seamless transitions of the model from development to production. This information often become referred to as deployment metadata or runtime infrastructure.\nWhy It Matters: Incorporating deployment metadata ensures that models function as expected in production, regardless of the environment. For example, specifying dependency versions prevents compatibility issues when deploying a forecasting model that relies on Python 3.12 or newer.\n\n\n\n\nModel versioning builds directly on experiment tracking by formalizing the transition from experimentation to operationalization. In our apple demand forecasting example, experiment tracking allowed us to document how different preprocessing techniques and hyperparameter configurations influenced model performance. Model versioning took these records and added structured management of the selected model artifacts, datasets, and deployment settings, ensuring that the model could be deployed reliably and reproduced when needed.\nThis continuity not only simplifies workflows but also ensures adherence to critical design principles like reproducibility, scalability, and traceability, which are essential for robust machine learning systems.",
    "crumbs": [
      "ModelOps",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Model Versioning and Reproducibility</span>"
    ]
  },
  {
    "objectID": "07-modelops-versioning.html#tools-for-model-versioning-and-reproducibility",
    "href": "07-modelops-versioning.html#tools-for-model-versioning-and-reproducibility",
    "title": "7  Model Versioning and Reproducibility",
    "section": "7.3 Tools for Model Versioning and Reproducibility",
    "text": "7.3 Tools for Model Versioning and Reproducibility\nIn the previous chapter on experiment tracking (Chapter 6), we explored tools like MLflow, Weights & Biases, and Comet.ml, which are pivotal for documenting and tracking experimentation. Building on that foundation, model versioning tools extend these capabilities to ensure the systematic management of trained models, artifacts, datasets, and deployment configurations. Below, we’ll quickly explore tools specifically designed to address the challenges of versioning and reproducibility.\n\n\n\n\n\n\nMLflow Model Registry\n\n\n\n\n\nMLflow’s Model Registry provides a robust solution for managing the lifecycle of machine learning models as part of its broader tracking ecosystem.\n\nKey Features:\n\nCentral repository for storing, annotating, and managing model versions.\nTrack model stages such as staging, production, and archived.\nCompare versions and collaborate using built-in commentary features.\n\nUse Case in Our Pipeline: After identifying the best-performing apple demand forecasting model, the MLflow Model Registry enables seamless tracking of version updates, fostering reproducibility and transparency in deployment.\nWhy It Matters: Centralizing model versioning and metadata enhances collaboration, traceability, and governance across teams.\n\n\n\n\n\n\n\n\n\n\nDVC (Data Version Control)\n\n\n\n\n\nDVC was introduced in Section 4.3 where we demonstrated its capability to version datasets in a data pipeline. Beyond data, DVC is also a powerful tool for managing machine learning models and their associated artifacts.\n\nKey Features:\n\nVersion control for datasets, preprocessing scripts, and trained models, enabling end-to-end reproducibility.\nIntegrates seamlessly with Git to provide structured versioning for machine learning workflows.\nSupports storage of large files (e.g., models and datasets) in cloud platforms like AWS S3, Google Cloud Storage, or Azure Blob.\n\nUse Case in Our Pipeline: DVC can be used to version the trained apple forecasting models, ensuring that each iteration is traceable alongside the datasets and preprocessing scripts used in training.\nWhy It Matters: By providing a unified approach to versioning data, code, and models, DVC ensures that every component of the ML workflow is reproducible and accessible.\n\n\n\n\n\n\n\n\n\n\nWeights & Biases Model Management\n\n\n\n\n\nWeights & Biases (W&B), known for its experiment tracking capabilities, also includes features for managing models and artifacts.\n\nKey Features:\n\nIntegrate model artifact tracking seamlessly with experiment logs.\nStore and compare multiple versions of models alongside datasets and metrics.\nManage deployment-ready models and track their history across environments.\n\nUse Case in Our Pipeline: W&B allows us to log and compare various versions of the apple forecasting model, ensuring we retain all metadata and performance metrics for evaluation.\nWhy It Matters: Combining experiment tracking and model versioning in one platform simplifies workflows and avoids fragmented systems.\n\n\n\n\n\n\n\n\n\n\nGit-LFS and Git for Models\n\n\n\n\n\nGit, paired with Git Large File Storage (LFS), is a lightweight option for tracking machine learning artifacts.\n\nKey Features:\n\nTracks changes in code, datasets, and configurations.\nGit-LFS efficiently stores large binary files, such as trained model weights.\n\nUse Case in Our Pipeline: By leveraging Git-LFS, the apple forecasting model files and associated configurations can be tracked alongside the version-controlled codebase.\nWhy It Matters: Using Git for model versioning integrates naturally into existing software development workflows, minimizing the need for additional tools.\n\n\n\n\n\n\n\n\n\n\nTensorFlow Serving\n\n\n\n\n\nTensorFlow Serving is a specialized system for serving machine learning models in production environments.\n\nKey Features:\n\nNative support for versioning TensorFlow models, ensuring smooth updates without interrupting existing services.\nOptimized for high-performance serving of real-time and batch predictions.\nIncludes automatic model version management and rollback capabilities.\n\nUse Case in Our Pipeline: TensorFlow Serving can manage the deployment of multiple apple forecasting model versions, ensuring users seamlessly receive predictions from the best-performing model while enabling rapid updates.\nWhy It Matters: TensorFlow Serving excels at operationalizing machine learning models, with built-in versioning and deployment features designed for scalability and reliability.\n\n\n\n\n\n\n\n\n\n\nNeptune.ai\n\n\n\n\n\nNeptune.ai is a specialized tool designed for tracking, organizing, and managing machine learning models and experiments.\n\nKey Features:\n\nCentralized dashboard for tracking model artifacts and metrics.\nEasy-to-use interface for comparing model versions and their configurations.\nStrong integration capabilities with popular ML frameworks like TensorFlow and PyTorch.\n\nUse Case in Our Pipeline: Neptune.ai can be used to track all iterations of the apple forecasting model and visualize performance metrics over time.\nWhy It Matters: Neptune.ai provides advanced comparison and collaboration features, ideal for teams working on diverse ML projects.\n\n\n\n\n\n\n\n\n\n\nBentoML\n\n\n\n\n\nBentoML is a specialized framework designed to simplify packaging, versioning, and deploying machine learning models.\n\nKey Features:\n\nLightweight framework for packaging and serving models.\nBuilt-in versioning for models, ensuring that all deployment-ready versions are tracked and reproducible.\nFlexible deployment options for cloud, edge, or on-premise environments.\n\nUse Case in Our Pipeline: BentoML could be used to package and deploy different versions of the apple forecasting model while ensuring that deployment configurations are version-controlled.\nWhy It Matters: BentoML’s focus on versioning deployment-ready models makes it a strong complement to tools like MLflow and DVC.\n\n\n\n\nThe choice of tools depends on the specific needs of your team and infrastructure:\n\nTeams already using MLflow for tracking experiments will benefit from its integrated Model Registry for managing versions.\nFor large-scale datasets and models, DVC offers a comprehensive solution that pairs well with Git workflows.\nOrganizations looking for deployment-specific tools may prefer BentoML or TensorFlow Serving.\nFor advanced dashboarding and visualization, Neptune.ai provides powerful comparison capabilities.\n\nBy aligning tools with workflow requirements, teams can establish robust model versioning practices that seamlessly extend the experiment tracking processes outlined in the previous chapter.",
    "crumbs": [
      "ModelOps",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Model Versioning and Reproducibility</span>"
    ]
  },
  {
    "objectID": "07-modelops-versioning.html#sec-model-version-example",
    "href": "07-modelops-versioning.html#sec-model-version-example",
    "title": "7  Model Versioning and Reproducibility",
    "section": "7.4 Hands-On Example: Implementing Model Versioning",
    "text": "7.4 Hands-On Example: Implementing Model Versioning\nIn the previous chapter, we explored how MLflow can be used to track experiments, documenting essential components like datasets, hyperparameters, and metrics for apple demand forecasting models (see Section 6.4). This experiment tracking provided a solid foundation for organizing and comparing various model iterations. However, tracking experiments is only part of the journey. Once a model is ready to transition from experimentation to production, effective management and versioning become critical.\nThis section builds on the previous hands-on example by demonstrating how to leverage the MLflow Model Registry to implement model versioning. Model versioning ensures that every model iteration—along with its configuration, artifacts, and performance metrics—is systematically managed. It also facilitates reproducibility, traceability, and seamless lifecycle transitions.\nIn this hands-on example, we’ll revisit the apple demand forecasting problem and illustrate how to register, manage, and compare multiple model versions using the MLflow Model Registry. By the end of this section, you will understand how to:\n\nRegister models and document their key attributes.\nManage multiple versions of a model and promote them across lifecycle stages.\nCompare model versions to identify the best-performing iteration.\n\nThrough this process, you’ll see how model versioning not only enhances organization and collaboration but also lays the groundwork for deploying reliable models in production. Let’s dive in!\n\nSetting the Stage\nBefore diving into model versioning, let’s recap where we left off in the previous chapter. In the apple demand forecasting project, we trained and tracked multiple models using MLflow’s experiment tracking capabilities. Each experiment logged essential details, including:\n\nThe dataset used for training.\nFeature engineering steps applied.\nHyperparameters for the model.\nEvaluation metrics such as mean absolute error (MAE) and root mean squared error (RMSE).\nArtifacts, including the trained model and any visualizations.\n\nNow, we’ll build on that foundation by focusing on versioning these models. The MLflow Model Registry provides a structured way to:\n\nRegister Models: Each trained model can be registered and stored with its corresponding metadata.\nVersion Models: Multiple versions of a model can be tracked, allowing you to maintain a history of iterations.\nFacilitate Collaboration: Teams can add notes, tags, aliases, and approval statuses to provide transparency and coordination during the model lifecycle.\n\nIf you want to follow along with this example, ensure that you have the following prerequisites set up:\n\nA working MLflow environment with the MLflow Tracking Server enabled. If you’re using the notebook from the last chapter, it already tracks experiments to a local MLflow server.\nThe code and dataset from the apple demand forecasting example. This includes the data preprocessing and modeling pipeline we previously implemented.\nAccess to the MLflow Model Registry via the MLflow UI.\n\n\n\n\n\n\n\nIf you followed along in Section 6 then you will be all set to follow along in this section!\n\n\n\nWith these components in place, we’ll demonstrate how to extend the workflow by registering and managing models in the MLflow Model Registry. By the end of this section, you’ll see how model versioning creates a structured and traceable process, ensuring that each model iteration is well-documented and ready for production deployment.\n\n\nRegistering Models\nModel registration is a critical step in model versioning and reproducibility. It allows you to systematically manage, track, and deploy models in a structured manner. In this section, we demonstrate two approaches to registering models in MLflow:\n\nUsing the MLflow UI to register a model from a previously logged experiment.\nUsing code to programmatically register a model during training.\n\n\nMethod 1: Registering a Model Using the MLflow UI\nThis method leverages the MLflow user interface to manually register a model from a previously logged experiment.\n\nOpen the MLflow UI:\n\nStart the MLflow server by running mlflow ui in your terminal.\nNavigate to http://localhost:5000 (or the local URL provided when you run mlflow ui).\n\nLocate the Experiment:\n\nIn the “Experiments” section, find the experiment you created in the last chapter (e.g., “Apple Demand Forecasting”).\nSelect an experiment run, and review the logged parameters, metrics, and artifacts. \n\nRegister the Model:\n\nUnder the “Artifacts” section, click on the model artifact to open its details.\nClick the Register Model button. \nProvide a name for the model (e.g., apple_demand), and confirm. \nNow, if you navigate to the “Models” tab in the MLflow UI, you’ll see the newly registered model. \n\nAdding Metadata::\n\nClick on the registered model name to see its details.\nWe can use the Tags and Aliases features to add metadata about the model. This can be helpful to annotate model versions with their status. For example,\n\nYou could apply a tag validation_status with a value pending to a model version while it is being validated or going through the final reviews prior to deploying. You can then update the tag value to passed when it has passed any additional validation requirements (i.e. smoke tests, performance tests) and is ready for deployment.\nAnd you can use Aliases to provide a flexible way to create named references for particular model versions - such as champion and challenger. \n\n\n\n\n\n\n\n\nWhy It Matters: Tags and aliases improve model lifecycle management by providing quick, meaningful insights into the status and usage of models. This metadata helps teams identify which versions are in production, under review, or awaiting deployment, ensuring better coordination and traceability.\n\n\n\n\n\n\nMethod 2: Registering a Model Using Code\nFor workflows requiring automation, you can register models programmatically within your code. There’s actually a few different ways you can do this.\n\n\n\n\n\n\nSee this notebook for the entire source code.\n\n\n\nThe first is to search existing runs in our experiment:\n\n\n# check out the existing model runs\nall_runs = mlflow.search_runs(search_all_experiments=True)\nprint(all_runs)\n\n                             run_id       experiment_id    status  \\\n0  1d4f349e3edc481685c691ef773dfb7e  186119791991456899  FINISHED   \n1  9729fd97ce074ee2862cc32e1089c513  186119791991456899  FINISHED   \n2  3a460bec71464493bdc4da5ec9537796  186119791991456899  FINISHED   \n3  dfe70656a2f64c11b35078e288f962ab  186119791991456899  FINISHED   \n\n                                        artifact_uri  \\\n0  file:///Users/b294776/Desktop/workspace/traini...   \n1  file:///Users/b294776/Desktop/workspace/traini...   \n2  file:///Users/b294776/Desktop/workspace/traini...   \n3  file:///Users/b294776/Desktop/workspace/traini...   \n\n                        start_time                         end_time  \\\n0 2025-01-26 18:21:05.944000+00:00 2025-01-26 18:21:11.317000+00:00   \n1 2025-01-26 18:21:00.330000+00:00 2025-01-26 18:21:05.873000+00:00   \n2 2025-01-26 18:20:01.595000+00:00 2025-01-26 18:20:04.736000+00:00   \n3 2025-01-26 18:19:56.389000+00:00 2025-01-26 18:20:01.247000+00:00   \n\n   metrics.rmse  metrics.r2  metrics.mae  metrics.mse  ... params.bootstrap  \\\n0     61.285576    0.900071    47.628141  3755.921850  ...             None   \n1     64.496897    0.889324    50.436906  4159.849675  ...             True   \n2     64.662326    0.888755    50.439003  4181.216379  ...             True   \n3     61.262270    0.900147    47.611615  3753.065770  ...             None   \n\n  params.min_samples_split params.n_estimators params.oob_score  \\\n0                     None                None             None   \n1                       15                 200             None   \n2                       10                 100            False   \n3                     None                None             None   \n\n  params.random_state tags.mlflow.source.type tags.mlflow.user  \\\n0                None                   LOCAL          b294776   \n1                None                   LOCAL          b294776   \n2                 888                   LOCAL          b294776   \n3                None                   LOCAL          b294776   \n\n                            tags.mlflow.runName  \\\n0  Regularized Regression Hyperparameter Tuning   \n1           Random Forest Hyperparameter Tuning   \n2                                 Random Forest   \n3                        Regularized Regression   \n\n                       tags.mlflow.log-model.history  \\\n0  [{\"run_id\": \"1d4f349e3edc481685c691ef773dfb7e\"...   \n1  [{\"run_id\": \"9729fd97ce074ee2862cc32e1089c513\"...   \n2  [{\"run_id\": \"3a460bec71464493bdc4da5ec9537796\"...   \n3  [{\"run_id\": \"dfe70656a2f64c11b35078e288f962ab\"...   \n\n                             tags.mlflow.source.name  \n0  /opt/anaconda3/lib/python3.12/site-packages/ip...  \n1  /opt/anaconda3/lib/python3.12/site-packages/ip...  \n2  /opt/anaconda3/lib/python3.12/site-packages/ip...  \n3  /opt/anaconda3/lib/python3.12/site-packages/ip...  \n\n[4 rows x 24 columns]\n\n\n\nWe can then use this info to extract the run we care about and then use mlflow.register_model() to register the model.\n\n\n# extract model run ID for tuned random forest model\nrun = all_runs['tags.mlflow.runName'] == 'Random Forest Hyperparameter Tuning'\nrun_id = all_runs[run]['run_id'].iloc[0]\n\n\n\n\n# register this model\nresult = mlflow.register_model(f'runs:/{run_id}', 'apple_demand')\n\n\nNow, if we go back to our UI, we’ll see that we have a new registered model\n\n\n\nRegistered RF Model via Code\n\n\nAn alternative, is to register the model during the training run, which helps allow automation within your code. Below is an example of registering an XGBoost model during training:\n\n\n# Create data\ndata = generate_apple_sales_data_with_promo_adjustment(base_demand=1_000, n_rows=1_000)\nX = data.drop(columns=[\"date\", \"demand\"])\ny = data[\"demand\"]\n\n# Split the data into training and validation sets\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Train an XGBoost model\nxgb_model = XGBRegressor(n_estimators=100, learning_rate=0.1, max_depth=5, random_state=42)\nxgb_model.fit(X_train, y_train)\n\n# Evaluate the model\ny_pred = xgb_model.predict(X_val)\nrmse = np.sqrt(mean_squared_error(y_val, y_pred))\n\n# Log experiment details\nwith mlflow.start_run(run_name=\"XGBoost Model\"):\n    mlflow.log_param(\"model_type\", \"XGBoost\")\n    mlflow.log_param(\"n_estimators\", 100)\n    mlflow.log_param(\"learning_rate\", 0.1)\n    mlflow.log_param(\"max_depth\", 5)\n    mlflow.log_metric(\"rmse\", rmse)\n    mlflow.xgboost.log_model(xgb_model, artifact_path=\"artifacts\")\n\n    # Register model programmatically\n    active_run = mlflow.active_run().info.run_id\n    model_uri = f\"runs:/{active_run}/model\"\n    registered_model = mlflow.register_model(model_uri=model_uri, name=\"apple_demand\")\n\n    # Add metadata: Tags and Aliases\n    client = mlflow.tracking.MlflowClient()\n    client.set_registered_model_tag(\n        registered_model.name, \"validation_status\", \"pending\"\n    )\n    client.set_registered_model_alias(\n        registered_model.name, \"challenger\", version=registered_model.version\n    )\n\n\n\n\n\n\n\n\nIn the above code snippet, if a registered model with the name doesn’t exist, the method registers a new model and creates Version 1. If a registered model with the name exists, the method creates a new model version.\nAlso, note how you can even add tags and aliases programmatically!\n\n\n\nNow, if we check out the MLFlow UI we’ll see our latest versioned model!\n\n\n\nAll Registered Models\n\n\n\n\nWhy Use Both Methods?\nBoth methods of registering models offer unique benefits, and understanding when to use each can enhance your workflow:\n\nUI Registration:\n\nWhen to Use: This method is ideal for manual workflows or when revisiting past experiments. It allows you to visually explore experiment details, select a specific run, and easily register its model.\nWhy It’s Useful: It simplifies navigation and is particularly helpful for users unfamiliar with coding or automation, making it accessible to a broader team of stakeholders.\n\nCode-Based Registration:\n\nWhen to Use: Best suited for automated pipelines where models are frequently trained and registered. It ensures consistency and reduces manual intervention, which is critical for scaling operations.\nWhy It’s Useful: This method integrates directly into the experimentation workflow, enabling seamless and error-free registration as part of your end-to-end process.\n\n\nCombining Both: Teams can benefit from leveraging both approaches. For example: - Use code-based registration for ongoing experiments in an automated workflow. - Use the MLflow UI to manage, review, or reassign stages for registered models, ensuring they meet lifecycle and deployment requirements.\n\n\n\nQuerying Registered Models\nYou can even query registered models:\n\n\nmlflow.search_registered_models()\n\n[&lt;RegisteredModel: aliases={'challenger': '3', 'champion': '1'}, creation_timestamp=1737916057537, description='', last_updated_timestamp=1737916154049, latest_versions=[&lt;ModelVersion: aliases=['challenger'], creation_timestamp=1737916154031, current_stage='None', description=None, last_updated_timestamp=1737916154031, name='apple_demand', run_id='021eea67d5ea4be5967ca90efe8866db', run_link=None, source='file:///Users/b294776/Desktop/workspace/training/UC/uc-bana-7075/ModelOps/mlruns/186119791991456899/021eea67d5ea4be5967ca90efe8866db/artifacts/model', status='READY', status_message=None, tags={}, user_id=None, version=3&gt;], name='apple_demand', tags={'validation_status': 'pending'}&gt;]\n\n\n\n\n\n\n\n\n\nThere’s a lot more functionality available with MLFlow Model Registery. To dig more into advanced functionality, check out the MLFlow docs: https://mlflow.org/docs/latest/model-registry.html\n\n\n\n\n\nReproducibility of Registered Model\nWhen exploring a specific versioned model in MLflow, you’ll notice a “Source Run” link associated with each registered model version. This link serves as a direct connection to the logged details of the specific run that produced the model, including its hyperparameters, datasets, evaluation metrics, and any other artifacts logged during experimentation. By providing this seamless traceability, the “Source Run” link ensures a clear lineage between the registered model and its training information. This feature is invaluable for understanding the context of a model, diagnosing issues, reproducing results, or auditing the training process, making it an essential aspect of robust model management.\n\n\n\nSource Run",
    "crumbs": [
      "ModelOps",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Model Versioning and Reproducibility</span>"
    ]
  },
  {
    "objectID": "07-modelops-versioning.html#summary",
    "href": "07-modelops-versioning.html#summary",
    "title": "7  Model Versioning and Reproducibility",
    "section": "7.5 Summary",
    "text": "7.5 Summary\nIn this chapter, we explored the critical role of model versioning and reproducibility within the ModelOps framework, emphasizing their importance for managing the lifecycle of machine learning models. Building on the experiment tracking concepts introduced in the previous chapter, we discussed how model versioning ensures traceability, facilitates collaboration, and supports robust deployment strategies. By versioning models alongside their associated metadata, configurations, and evaluation metrics, organizations can maintain a clear lineage for every model iteration, ensuring consistency and reproducibility across workflows.\nWe highlighted key components of model versioning, showing how it acts as an extension of experiment tracking, and introduced tools like MLflow, DVC, and TensorFlow Serving, which streamline versioning and foster reliable model management. Through a hands-on example, we demonstrated how to register models using MLflow, both through the user interface and programmatically, showcasing the value of tagging and aliasing for managing model stages and deployment readiness.\nAlthough this chapter focused on the fundamentals of versioning and reproducibility, we laid the foundation for the next chapter, which will delve into deploying and serving machine learning models. With deployment strategies, model lifecycle monitoring, and real-world applications ahead, the concepts explored here will serve as an essential bridge to operationalizing your models in production environments.",
    "crumbs": [
      "ModelOps",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Model Versioning and Reproducibility</span>"
    ]
  },
  {
    "objectID": "07-modelops-versioning.html#sec-model-version-exercise",
    "href": "07-modelops-versioning.html#sec-model-version-exercise",
    "title": "7  Model Versioning and Reproducibility",
    "section": "7.6 Exercise",
    "text": "7.6 Exercise\nIn this exercise, you’ll extend your work from the previous chapter’s exercise (see Exercise 6.7) to include model versioning. Building on the California home prediction task, you will use MLflow to register and version your models, enabling clear traceability and management of model iterations.\n\n\n\n\n\n\nPart 1: Conceptual Design\n\n\n\n\n\n\nUnderstanding the Need for Versioning:\n\nReflect on the experiment tracking exercise from Section 6.7. Why do you think Zillow would find it important to version the model produced for this task, especially when experimenting with different configurations or when preparing for deployment?\nList scenarios in your California home prediction task where having model versioning would provide benefits, such as:\n\nKeeping track of retrained models using updated datasets.\nTesting new algorithms or hyperparameters.\nIdentifying the best-performing model for deployment.\n\n\nDefine the Metadata to Track:\n\nConsider what metadata you would tag your models with (e.g., “validation_status”).\nThink about how aliases could help you manage and reference different model versions, such as labeling one as the “champion” model.\n\n\n\n\n\n\n\n\n\n\n\nPart 2: Hands-On Experimentation\n\n\n\n\n\n\nRegister a Model via the MLflow UI:\n\nSelect the best-performing model from the previous chapter’s exercise in the MLflow UI.\nRegister it to the MLflow Model Registry, providing an appropriate name and description.\nAdd metadata to the registered model by tagging it with a status like “pending final validation.”\nAssign an alias, such as “champion,” to signify its potential readiness for deployment.\n\nProgrammatically Register a Model:\n\nTrain a new model, such as an XGBoost regressor, using the same California housing dataset.\nLog this new model and register it programmatically in MLflow by following the example provided in this chapter.\nAdd metadata and aliases to this model programmatically.\n\nExplore the Source Run:\n\nNavigate to the “Source Run” link for one of the registered models in the MLflow UI.\nObserve how it links back to the original run, providing detailed training information.\nReflect on the importance of this feature for reproducibility and traceability.\n\n\n\n\n\n\n\n\n\n\n\nPart 3: Reflection on Design Principles\n\n\n\n\n\n\nVersioning and Reproducibility:\n\nHow does the MLflow Model Registry help ensure reproducibility and maintain a clear lineage between model versions and their training runs?\nHow could this setup scale to support a team working on the same project?\n\nMetadata and Management:\n\nReflect on how metadata (tags and aliases) simplifies managing multiple model versions in a production workflow.\nThink about potential pitfalls if metadata or aliases are inconsistently applied or not updated.\n\nScalability and Collaboration:\n\nImagine how this model versioning process could be extended for a team working collaboratively on multiple models. What practices would you recommend for effective collaboration?",
    "crumbs": [
      "ModelOps",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Model Versioning and Reproducibility</span>"
    ]
  },
  {
    "objectID": "08-modelops-deployment.html",
    "href": "08-modelops-deployment.html",
    "title": "8  Model Deployment",
    "section": "",
    "text": "8.1 Key Considerations\nModel deployment is the pivotal stage in the machine learning lifecycle where a trained and validated model transitions from development to production. While the earlier stages of the process—like model training, experimentation tracking, and versioning—focus on optimizing model performance and ensuring reproducibility, deployment brings these efforts to life by delivering actionable insights in real-world environments. A deployed model is not just a static artifact but an operational component that interacts with live data to provide predictions, influence decisions, and generate value for businesses.\nThis chapter builds upon the foundational work covered in the previous chapters. In Chapter 6, we explored experiment tracking, emphasizing the importance of documenting hyperparameters, datasets, and performance metrics. Chapter 7 introduced model versioning, ensuring traceability and reproducibility of model iterations. Now, we turn our attention to deploying models, bridging the gap between experimentation and real-world application. Effective deployment not only ensures that the best-performing models are operationalized but also lays the groundwork for scalability, reliability, and business impact.\nModel deployment involves a diverse range of considerations, from choosing the right infrastructure to implementing strategies that ensure minimal disruption during updates. This chapter will provide an introductory understanding of deployment principles, explore popular tools and frameworks, and offer a hands-on example that builds on the apple forecasting problem from previous chapters. By the end of this chapter, you’ll have a roadmap for turning your well-tracked and versioned models into deployed solutions that deliver consistent and reliable results.\nDeploying machine learning models effectively requires a strategic approach to address a variety of technical and operational factors. A successful deployment ensures that models operate efficiently, scale to meet demand, and integrate seamlessly with existing systems. Below, we outline the key considerations for model deployment and their implications in real-world scenarios.\nModel deployment is a highly collaborative effort that relies on the expertise of engineering teams to help address many of the technical complexities of integrating machine learning models into production. Although data scientists are becoming more involved in this process, you should not expect to go it alone! Rather, look for opportunities to collaborate with engineering teams as they can simplify your life. Some key areas that engineering support can help include:\nBy leveraging engineering expertise, you’ll be able to deploy models that are not only functional but also scalable, secure, and seamlessly integrated into production systems.",
    "crumbs": [
      "ModelOps",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Model Deployment</span>"
    ]
  },
  {
    "objectID": "08-modelops-deployment.html#key-considerations",
    "href": "08-modelops-deployment.html#key-considerations",
    "title": "8  Model Deployment",
    "section": "",
    "text": "Scalability\n\n\n\n\n\n\nWhat It Means: Scalability is the ability of a system to handle increased demand without performance degradation. For ML models, this means ensuring that the model can process growing volumes of data or user requests efficiently.\nWhy It Matters: Scalability ensures the system remains functional and responsive during high-demand periods, such as peak usage times for an e-commerce site or when serving real-time predictions for millions of IoT devices.\nExample: During a Black Friday sale, an e-commerce platform’s recommendation engine may need to serve 2-5 times more shoppers than normal. This ability to scale due to increased traffic allows the system to generate personalized product recommendations quickly and accurately regardless of surges in demand.\nHow to Address:\n\nCloud Scalability: Use platforms like AWS Lambda or Google Cloud Functions to automatically scale resources based on traffic. For example, serverless architecture can allocate compute resources dynamically during peak demand.\nKubernetes: Deploy models in containers managed by Kubernetes to ensure automatic scaling, load balancing, and fault tolerance across distributed systems.\nDistributed Inference Frameworks: Utilize frameworks like TensorFlow Serving or Triton Inference Server to handle high-throughput predictions by distributing workload efficiently across machines.\n\n\n\n\n\n\n\n\n\n\n\nLatency\n\n\n\n\n\n\nWhat It Means: Latency is the time between sending an input to the model and receiving the prediction. Low latency is critical for applications requiring real-time decision-making.\nWhy It Matters: High latency can make systems impractical or even dangerous in time-sensitive scenarios, such as fraud detection, autonomous driving, or live video analytics.\nExample: A credit card fraud detection system must deliver predictions within milliseconds to either approve or deny transactions, preventing fraudulent activities while minimizing user inconvenience.\nHow to Address:\n\nModel Optimization: Techniques like quantization and pruning can reduce the size and complexity of a model.\n\nQuantization: Converts model weights from high-precision (e.g., 32-bit) to lower-precision formats (e.g., 8-bit), reducing computation time without significant loss of accuracy. Read more about quantization here.\nPruning: Removes redundant weights or neurons from the model to make it smaller and faster. Read more about pruning here.\n\nEdge Computing: Deploy the model closer to where data is generated (e.g., on IoT devices or edge servers). For instance, deploying a vision model directly on a camera for anomaly detection avoids the latency of sending data to a central server.\nHardware Acceleration: Use GPUs, TPUs, or dedicated inference accelerators to speed up computations, particularly for complex models like deep neural networks.\n\n\n\n\n\n\n\n\n\n\n\nReliability\n\n\n\n\n\n\nWhat It Means: Reliability ensures that a deployed model consistently delivers accurate predictions under varying conditions, such as hardware failures, software bugs, or unexpected inputs.\nWhy It Matters: Unreliable models can undermine trust, disrupt workflows, and result in financial or reputational losses. For example, a malfunctioning model in a supply chain system could lead to delayed shipments or stockouts.\nExample: A healthcare diagnostic model must provide consistent and dependable predictions even when faced with missing or incomplete patient data.\nHow to Address:\n\nRedundancy: Use multiple instances of the model in a failover setup, ensuring that if one instance fails, another can take over seamlessly.\nTesting and Validation: Conduct rigorous testing, including stress tests, edge-case analysis, and integration testing, to identify and fix potential vulnerabilities.\nError Handling: Build robust error-handling mechanisms to gracefully manage anomalies, such as input data errors or system outages, without crashing the application.\n\n\n\n\n\n\n\n\n\n\n\nDeployment Environment\n\n\n\n\n\n\nWhat It Means: The deployment environment refers to the infrastructure where the model operates, such as cloud platforms, on-premises servers, or edge devices.\nWhy It Matters: The choice of environment impacts cost, latency, scalability, and integration with other systems.\nExample: An agriculture company deploys a model for soil health prediction on edge devices in remote fields, allowing real-time analysis without requiring constant internet connectivity.\nHow to Address:\n\nCloud Deployment: Ideal for scalable and flexible applications, cloud platforms like AWS SageMaker or Azure ML provide extensive tooling for deployment and monitoring.\nOn-Premises Deployment: Necessary for industries like finance or healthcare, where data privacy regulations require keeping data within a secure local environment.\nEdge Deployment: Use lightweight frameworks like TensorFlow Lite or ONNX Runtime to deploy models on devices with limited compute power, such as IoT sensors or mobile phones.\n\n\n\n\n\n\n\n\n\n\n\nIntegration with Existing Systems\n\n\n\n\n\n\nWhat It Means: Models often need to interact with other systems, including databases, APIs, and business applications.\nWhy It Matters: Poor integration can create bottlenecks and limit the usability of the deployed model, reducing its value to stakeholders.\nExample: A customer churn prediction model integrated with a CRM system should allow sales teams to view at-risk customers directly in their dashboard and take action to retain them.\nHow to Address:\n\nAPIs: Serve models as RESTful APIs using tools like Flask, FastAPI, or TensorFlow Serving, making them accessible to other applications.\nMiddleware: Use middleware to bridge the model with existing systems, translating predictions into actionable insights for end users.\nCollaboration with Engineers: Work closely with software engineers to ensure seamless integration into the organization’s ecosystem, including compliance with existing infrastructure standards.\n\n\n\n\n\n\n\n\n\n\n\n\nIntegration with Legacy Systems\n\n\n\n\n\nMany organizations rely on outdated systems that require engineering expertise to adapt model outputs to existing formats.\nExample: A fraud detection model producing probabilities may need middleware to translate results into binary outputs like “fraud” or “not fraud” for compatibility.\n\n\n\n\n\n\n\n\n\nInfrastructure Compatibility\n\n\n\n\n\nEngineers can help optimize deployment environments, whether models run on cloud platforms, on-premises servers, or edge devices.\nExample: Deploying a recommendation model on a cloud platform with auto-scaling ensures responsiveness during traffic surges.\n\n\n\n\n\n\n\n\n\nSecurity and Compliance\n\n\n\n\n\nEngineers can implement secure data pipelines and access controls to ensure models comply with standards like GDPR or HIPAA.\nExample: Encrypting communication channels for a healthcare model ensures patient data is protected.\n\n\n\n\n\n\n\n\n\nPerformance Optimization\n\n\n\n\n\nEngineers can help apply hardware-specific optimizations, such as leveraging GPUs or edge accelerators, to enhance model efficiency.\nExample: Optimizing a drone-based object detection model with TensorRT reduces inference latency for real-time decision-making.",
    "crumbs": [
      "ModelOps",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Model Deployment</span>"
    ]
  },
  {
    "objectID": "08-modelops-deployment.html#initial-model-deployment-strategies",
    "href": "08-modelops-deployment.html#initial-model-deployment-strategies",
    "title": "8  Model Deployment",
    "section": "8.2 Initial Model Deployment Strategies",
    "text": "8.2 Initial Model Deployment Strategies\nDeploying a machine learning model is not just about writing code—it involves critical decisions about how and where the model will operate. These choices influence latency, scalability, cost, and user experience. This section focuses on strategies for deploying models for inference, including modes of inference and deployment environments, and the factors that drive these decisions.\n\nModes of Inference\nChoosing the right inference mode is crucial for deploying machine learning models effectively. The inference mode determines how predictions are generated, influencing the model’s responsiveness, computational requirements, and overall system design. Below, we explore the three primary modes of inference—batch, real-time, and hybrid—providing detailed descriptions, examples, and implications for deployment strategies.\n\n\n\n\n\n\nBatch Inference\n\n\n\n\n\nBatch inference involves generating predictions for a large set of data at scheduled intervals or in response to a specific request. This approach works well for scenarios where predictions do not need to be instantaneous and can be processed in bulk. Batch inference typically utilizes batch processing systems like Apache Spark, Hadoop, or cloud services like AWS Batch.\n\nExamples\n\nRetail Forecasting: A grocery retailer generates weekly demand forecasts for apples to ensure proper inventory management. Using historical sales data, the system runs batch inference every Sunday night, delivering predictions in time for Monday’s produce order.\nFraud Detection Reports: A bank processes transactional data overnight to flag potentially fraudulent activities. While immediate detection might be handled by real-time inference, deeper risk analysis is done in batches to provide a comprehensive view.\nCustomer Segmentation: A marketing team processes customer data monthly to identify new segments for targeted campaigns.\n\n\n\nImpact on Deployment Strategy\n\nInfrastructure: Batch inference systems typically require powerful computing resources but only for scheduled durations. This makes it cost-effective for use cases with predictable demand.\nLatency: Predictions are generated with a delay, so batch inference is unsuitable for time-sensitive applications.\nScaling: Scaling is easier because the system doesn’t need to maintain always-on infrastructure; it processes large volumes of data during specific windows.\n\n\n\n\n\n\n\n\n\n\n\nReal-Time Inference\n\n\n\n\n\nReal-time inference generates predictions as new data becomes available, providing immediate responses. This mode is essential for applications where decisions must be made within milliseconds or seconds. Real-time systems often leverage REST APIs, gRPC, or WebSocket-based endpoints to deliver low-latency predictions.\n\nExamples\n\nAutonomous Vehicles: Vehicles process sensor data in real time to detect obstacles, predict traffic patterns, and make driving decisions within milliseconds.\nE-Commerce Recommendations: An online shopping platform displays personalized product recommendations as users browse, enhancing the shopping experience and boosting sales.\nFraud Detection: A payment processor analyzes transactions in real time to block potentially fraudulent activities before they are completed.\n\n\n\nImpact on Deployment Strategy\n\nInfrastructure: Real-time inference requires always-on systems with low-latency processing capabilities. This often involves deploying models on scalable platforms like Kubernetes or cloud-native services such as AWS SageMaker.\nLatency and Reliability: The system must meet strict latency requirements while maintaining high availability. Failures can have immediate and significant business impact.\nScaling: Real-time systems need to scale dynamically to handle variable loads, such as during peak shopping hours or flash sales.\n\n\n\n\n\n\n\n\n\n\n\nHybrid Inference\n\n\n\n\n\nHybrid inference combines batch and real-time inference to meet diverse requirements within a single system. This approach allows organizations to optimize costs and performance by aligning inference strategies with specific use cases.\n\nExamples\n\nNews Recommendation System: A media platform precomputes general recommendations overnight using batch inference while delivering real-time personalized suggestions based on user activity.\nEnergy Management: A utility company predicts daily power demand using batch inference but adjusts its predictions in real time to account for sudden changes in weather or energy usage.\nDynamic Pricing: An airline uses batch inference to update base ticket prices daily while employing real-time inference to adjust prices dynamically based on seat availability and user demand.\n\n\n\nImpact on Deployment Strategy\n\nInfrastructure: Hybrid systems require flexible infrastructure capable of supporting both batch and real-time processing. This often involves integrating batch processing frameworks with real-time serving platforms.\nCost Management: By leveraging batch inference for non-urgent tasks and real-time inference for critical processes, hybrid systems can optimize resource usage and reduce operational costs.\nComplexity: Managing a hybrid system adds complexity, as teams must ensure smooth integration and data consistency between batch and real-time workflows.\n\n\n\n\n\nThe choice of inference mode is driven by the application’s business requirements, technical constraints, and cost considerations. Batch inference is suitable for predictable, non-urgent tasks, while real-time inference excels in time-sensitive scenarios. Hybrid inference offers the flexibility to address both needs but requires careful planning and infrastructure design. By understanding the trade-offs and aligning them with deployment goals, organizations can build systems that balance efficiency, responsiveness, and scalability.\n\n\nDeployment Environments\nThe deployment environment for machine learning models is a critical decision that influences performance, scalability, cost, and maintenance. Deployment environments can be broadly categorized into cloud-based, on-premises, and edge setups. The choice of environment depends on the application’s requirements, infrastructure constraints, and mode of inference (batch, real-time, or hybrid). Below, we explore each environment in detail.\n\n\n\n\n\n\nCloud-Based Deployment\n\n\n\n\n\nCloud-based deployment involves hosting machine learning models on platforms provided by cloud service providers such as AWS, Google Cloud Platform (GCP), or Microsoft Azure. These environments offer a wide range of managed services for storage, compute, and networking, reducing the operational burden on organizations. Cloud platforms support serverless deployments, containerization, and scalable architectures to meet diverse needs.\n\nUse Cases\n\nBatch Inference: Models deployed in cloud environments can leverage large-scale compute resources for scheduled tasks like generating daily sales forecasts or processing customer sentiment analysis.\nReal-Time Inference: Cloud environments are ideal for deploying APIs that deliver low-latency predictions, such as fraud detection in payment systems or personalized e-commerce recommendations.\nHybrid Inference: Combining batch processing with real-time APIs is seamless in the cloud, enabling use cases like dynamic pricing systems that precompute baseline prices and adjust them in real time.\n\n\n\nAdvantages\n\nScalability: Cloud platforms provide elastic scaling to handle variable workloads, whether processing massive datasets in batch mode or handling high traffic for real-time APIs.\nIntegration: Cloud services often integrate with data lakes, pipelines, and other tools, making it easier to manage end-to-end ML workflows.\nManaged Services: Features like automatic failover, logging, and monitoring simplify operations and improve reliability.\n\n\n\nConsiderations\n\nCost: While cloud solutions are flexible, costs can escalate with high data transfer or prolonged resource usage.\nLatency: For real-time applications requiring ultra-low latency, the physical location of the cloud data center relative to the end user is a critical factor.\n\n\n\n\n\n\n\n\n\n\n\nOn-Premises Deployment\n\n\n\n\n\nOn-premises deployment involves hosting machine learning models within an organization’s own data centers or servers. This setup gives organizations complete control over their infrastructure and is often used when regulatory, security, or cost concerns limit cloud adoption.\n\nUse Cases\n\nBatch Inference: On-premises setups are well-suited for organizations with robust internal infrastructure that periodically runs resource-intensive jobs, such as credit scoring or generating compliance reports.\nReal-Time Inference: Industries like banking or healthcare, where data privacy is paramount, often deploy real-time models on-premises to ensure sensitive information does not leave controlled environments.\nHybrid Inference: On-premises systems can combine batch and real-time processing, such as precomputing analytics reports while using real-time models for user-facing applications.\n\n\n\nAdvantages\n\nData Security: On-premises deployments offer complete control over data, reducing exposure to potential breaches or unauthorized access.\nRegulatory Compliance: Many industries, such as healthcare (HIPAA) and finance (PCI DSS), require data to be stored and processed within specific geographic or organizational boundaries, making on-premises deployment a necessity.\nCost Management: For organizations with existing infrastructure, on-premises deployment can reduce long-term operational costs.\n\n\n\nConsiderations\n\nScalability: Scaling on-premises systems requires significant investment in hardware and infrastructure, making it less flexible than cloud solutions.\nMaintenance: Organizations are responsible for hardware upkeep, system updates, and overall reliability, increasing operational complexity.\n\n\n\n\n\n\n\n\n\n\n\nEdge Deployment\n\n\n\n\n\nEdge deployment involves deploying machine learning models directly on devices close to where the data is generated. These devices include IoT sensors, mobile devices, or specialized hardware like NVIDIA Jetson or Raspberry Pi. Edge deployment minimizes latency and reduces the need for continuous internet connectivity.\n\nUse Cases\n\nReal-Time Inference: Edge environments are critical for time-sensitive applications such as autonomous vehicles, where models must process sensor data and make decisions instantaneously.\nBatch Inference: Though less common, edge devices can periodically compute predictions in bulk for local use, such as environmental monitoring stations summarizing daily sensor readings.\nHybrid Inference: Edge devices can preprocess data locally and send aggregated results to the cloud for deeper analysis or batch processing.\n\n\n\nAdvantages\n\nLow Latency: By processing data locally, edge deployments eliminate the delay introduced by sending data to a central server.\nReduced Bandwidth: Edge deployments reduce the amount of data transmitted over networks, lowering operational costs and improving efficiency in bandwidth-constrained environments.\nAutonomy: Edge devices can operate in environments with intermittent or no internet connectivity, such as remote oil rigs or disaster response zones.\n\n\n\nConsiderations\n\nResource Constraints: Edge devices have limited computational power, storage, and memory, requiring optimized models through techniques like quantization, pruning, or distillation.\nComplexity: Deploying and maintaining models across a distributed network of edge devices adds significant operational challenges.\n\n\n\n\n\nThe choice of inference mode significantly influences the selection of a deployment environment:\n\nBatch Inference:\n\nBest suited for cloud-based or on-premises environments where ample resources can be allocated during specific timeframes.\nEdge deployments for batch inference are rare but can be effective in localized systems.\n\nReal-Time Inference:\n\nCloud-based environments are preferred for applications needing dynamic scalability and global accessibility.\nOn-premises environments are necessary for scenarios with strict data privacy or compliance requirements.\nEdge deployments excel when ultra-low latency and autonomy are critical, such as in healthcare wearables or autonomous drones.\n\nHybrid Inference:\n\nCombines the strengths of different environments. For example, edge devices preprocess data for real-time use, while the cloud handles batch analytics for broader insights.\n\n\nSelecting a deployment environment involves balancing business needs, technical requirements, and cost considerations. Cloud platforms offer flexibility and scalability for most applications, while on-premises setups ensure control and compliance. Edge deployment stands out for latency-critical and bandwidth-sensitive scenarios. Understanding these environments and their alignment with inference modes empowers teams to make informed decisions, ensuring efficient and effective model deployments.",
    "crumbs": [
      "ModelOps",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Model Deployment</span>"
    ]
  },
  {
    "objectID": "08-modelops-deployment.html#tools-and-frameworks-for-model-deployment",
    "href": "08-modelops-deployment.html#tools-and-frameworks-for-model-deployment",
    "title": "8  Model Deployment",
    "section": "8.3 Tools and Frameworks for Model Deployment",
    "text": "8.3 Tools and Frameworks for Model Deployment\nThe model deployment landscape is vast, with numerous tools and frameworks available to address diverse deployment needs. This space is also constantly evolving, with new technologies and innovations emerging regularly. While you may never use the majority of the tools listed here, understanding their strengths and use cases will enable you to make informed decisions about which tools to adopt for a given deployment scenario. Below, we explore some of the most popular tools, discussing their features, examples of real-world use, and when they are preferred.\n\n\n\n\n\n\nDocker\n\n\n\n\n\n\nOverview\nDocker is a containerization platform that packages applications and their dependencies into isolated, portable containers. For machine learning models, Docker ensures consistent behavior across various environments, from development to production.\n\n\nFeatures\n\nEncapsulates models, dependencies, and runtime environments.\nEnables seamless portability across operating systems and infrastructures.\nSimplifies scaling and orchestration when combined with platforms like Kubernetes.\n\n\n\nExample\nAn insurance company deploys a fraud detection model using Docker. By containerizing the model and its dependencies, the company ensures that the model behaves the same in local testing as in the cloud production environment. This consistency prevents environment-specific bugs that could affect predictions.\n\n\nWhen Preferred\n\nIdeal for teams working in environments with diverse infrastructure, such as a mix of on-premises and cloud systems.\nPreferred when reproducibility and portability are key requirements.\nUseful for applications that may later need to integrate into a microservices architecture.\n\n\n\n\n\n\n\n\n\n\n\nKubernetes\n\n\n\n\n\n\nOverview\nKubernetes is an open-source orchestration system designed to automate the deployment, scaling, and management of containerized applications. It provides advanced capabilities for running machine learning models in distributed environments.\n\n\nFeatures\n\nOffers auto-scaling, load balancing, and fault tolerance.\nSupports rolling updates and rollbacks for seamless model version transitions.\nIntegrates with ML-specific tools like Kubeflow for managing end-to-end pipelines.\n\n\n\nExample\nA global e-commerce company deploys its recommendation system using Kubernetes. The system dynamically scales to handle increased traffic during holiday sales, ensuring low latency for real-time predictions, even as user demand spikes.\n\n\nWhen Preferred\n\nBest for organizations needing to scale machine learning models across large user bases or high-traffic applications.\nIdeal for managing multiple models simultaneously in production, particularly in microservices environments.\nPreferred when reliability and high availability are critical, as Kubernetes ensures that containerized applications recover automatically from failures.\n\n\n\n\n\n\n\n\n\n\n\nTensorFlow Serving\n\n\n\n\n\n\nOverview\nTensorFlow Serving is a flexible, high-performance serving system designed specifically for deploying TensorFlow models. It is optimized for production environments requiring low-latency predictions.\n\n\nFeatures\n\nProvides built-in support for gRPC and REST APIs for serving models.\nAllows dynamic loading and versioning of models without restarting the service.\nSupports TensorFlow-specific optimizations for inference performance.\n\n\n\nExample\nA healthcare startup deploys a TensorFlow-based medical imaging model using TensorFlow Serving. The system handles real-time X-ray image inputs and delivers diagnostic predictions to doctors within seconds, ensuring rapid decision-making in critical care situations.\n\n\nWhen Preferred\n\nIdeal for teams already using TensorFlow in their workflows and seeking seamless integration.\nBest for real-time inference applications where low latency is critical.\nSuitable for environments that require robust model version management and frequent updates.\n\n\n\n\n\n\n\n\n\n\n\nFastAPI\n\n\n\n\n\n\nOverview\nFastAPI is a modern Python web framework for building APIs. It is lightweight and easy to use, making it a popular choice for deploying machine learning models as REST endpoints.\n\n\nFeatures\n\nProvides high performance using asynchronous programming.\nAuto-generates API documentation via OpenAPI standards.\nSupports seamless integration with Python-based ML libraries like Scikit-learn, PyTorch, and TensorFlow.\n\n\n\nExample\nA fintech startup deploys a linear regression model using FastAPI to predict stock prices based on market indicators. The lightweight API serves predictions to a front-end dashboard used by financial analysts, with sub-second latency.\n\n\nWhen Preferred\n\nBest for rapid prototyping of machine learning APIs or lightweight deployments.\nSuitable for small to medium-scale applications where simplicity and ease of development are priorities.\nUseful for internal testing and experimentation before moving to larger-scale deployments.\n\n\n\n\n\n\n\n\n\n\n\nMLflow\n\n\n\n\n\n\nOverview\nMLflow is a comprehensive machine learning lifecycle platform that integrates model tracking, reproducibility, and deployment. Its model-serving capabilities simplify transitioning from experimentation to production.\n\n\nFeatures\n\nProvides direct deployment of models as REST APIs.\nSupports exporting models to various formats for compatibility with other tools.\nTracks and manages deployed model versions for streamlined monitoring and updates.\n\n\n\nExample\nA retail analytics company deploys a demand forecasting model using MLflow. The platform ensures that deployed models are linked to their training runs, providing traceability for model decisions and making it easy to redeploy improved versions.\n\n\nWhen Preferred\n\nIdeal for teams already using MLflow for experimentation and tracking.\nBest for managing multiple model versions and maintaining clear lineage.\nSuitable for small to medium-scale deployments that don’t require advanced orchestration.\n\n\n\n\n\n\n\n\n\n\n\nBentoML\n\n\n\n\n\n\nOverview\nBentoML is a specialized framework for packaging and deploying machine learning models as optimized APIs. It focuses on simplifying the process of creating production-grade endpoints.\n\n\nFeatures\n\nPackages models along with their dependencies into standalone bundles.\nOffers customizable REST or gRPC APIs for serving models.\nProvides tools for optimizing inference performance through pipeline support.\n\n\n\nExample\nA logistics company deploys a delivery route optimization model using BentoML. The system bundles the model with preprocessing logic, ensuring efficient and consistent predictions across the fleet’s onboard devices.\n\n\nWhen Preferred\n\nBest for applications with complex preprocessing or post-processing requirements.\nSuitable for teams seeking high-performance APIs for inference with minimal setup.\nIdeal for serving multiple models within a single application.\n\n\n\n\n\n\n\n\n\n\n\nAWS SageMaker\n\n\n\n\n\n\nOverview\nAWS SageMaker is a fully managed machine learning service that simplifies the deployment and scaling of models. It integrates deeply with other AWS services to provide a seamless workflow.\n\n\nFeatures\n\nSupports one-click deployment of models as scalable endpoints.\nMonitors endpoint performance and integrates with other AWS tools for analytics and security.\nOffers cost-effective options like multi-model endpoints.\n\n\n\nExample\nA media company deploys a content recommendation model on SageMaker. The model predicts user preferences in real time and scales automatically to serve millions of users globally during peak streaming hours.\n\n\nWhen Preferred\n\nIdeal for organizations heavily invested in the AWS ecosystem.\nBest for scaling ML models globally with minimal operational overhead.\nSuitable for use cases requiring integration with other AWS tools like Lambda or S3.\n\n\n\n\n\nThe right tool depends on several factors:\n\nInference Requirements: Tools like TensorFlow Serving excel in low-latency real-time inference, while BentoML handles complex pipelines effectively.\nScalability: Kubernetes is the go-to choice for large-scale, distributed deployments, whereas FastAPI is perfect for lightweight use cases.\nIntegration Needs: AWS SageMaker is ideal for teams already using AWS services, while Docker is better for hybrid environments.\nEcosystem Fit: MLflow works seamlessly for teams already using it for experiment tracking.\n\nBy understanding your deployment requirements and the strengths of these frameworks, you can select the right combination to ensure your models are deployed efficiently and effectively.",
    "crumbs": [
      "ModelOps",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Model Deployment</span>"
    ]
  },
  {
    "objectID": "08-modelops-deployment.html#sec-model-deploy-example",
    "href": "08-modelops-deployment.html#sec-model-deploy-example",
    "title": "8  Model Deployment",
    "section": "8.4 Hands-On Example: Deploying a Machine Learning Model",
    "text": "8.4 Hands-On Example: Deploying a Machine Learning Model\nIn this hands-on example, we’ll build on the apple demand forecasting model from previous chapters, demonstrating how to deploy it for real-time or batch inference using MLFlow, FastAPI, Streamlit and Docker. This example provides a practical, simplified view of how to bring a trained model into production-like environments.\nThe goal of this exercise is to simulate a complete deployment pipeline that includes:\n\nRetrieving the trained model from MLflow, ensuring versioning and reproducibility.\nSetting up a REST API to enable batch predictions on uploaded datasets.\nContainerizing the application using Docker for portability and scalability.\n\nWhile this example focuses on a relatively straightforward deployment approach, the principles and tools we’ll use—such as creating endpoints, handling model artifacts, and containerization—are foundational to real-world deployment strategies. In production, deployments often involve additional complexities, such as real-time inference, load balancing, and integration with orchestration tools like Kubernetes. However, starting with this hands-on example will help you grasp the basics and understand the core workflow of model deployment.\nBy the end of this example, you’ll:\n\nDeploy a FastAPI-based REST API for batch predictions.\nUnderstand how Docker enables scalable and reproducible deployments.\nGain insight into connecting deployment strategies to the considerations discussed earlier in this chapter.\n\nLet’s dive in and take the first step toward deploying the apple demand forecasting model!\n\n\n\n\n\n\nThis section is more technical than previous hands-on examples, as it involves setting up a FastAPI, integrating it with an MLflow-registered model, and containerizing the application with Docker. I encourage you to challenge yourself by actively following along with the implementation. However, if some of these steps feel overwhelming, don’t worry—at a minimum, carefully reading through this section will provide valuable insights into the complexities of deploying machine learning models. Even this simplified example demonstrates the many moving parts involved in transitioning a model from experimentation to a fully deployed system. Understanding these challenges is a crucial step toward mastering ModelOps and collaborating effectively with engineering teams in real-world deployments. 🚀\n\n\n\n\nPrerequisites\nBefore diving into the hands-on example, ensure that you have the following prerequisites in place:\n\n1. Required Tools and Libraries\nTo replicate this hands-on exercise on your end, you’ll need to Docker installed. You can either install Docker Desktop or Docker Engine. To verify you have Docker installed you can always run docker version in your terminal.\ndocker version\n\nClient: Docker Engine - Community\n Version:           27.5.1\n API version:       1.47\n Go version:        go1.23.5\n Git commit:        9f9e405801\n Built:             Tue Jan 21 23:46:20 2025\n OS/Arch:           darwin/amd64\n Context:           default\nYou’ll also need the following packages installed.1\nfastapi==0.115.7\nmlflow==2.12.2\nnumpy==1.26.4\npandas==2.1.4\npython-multipart==0.0.20\nscikit-learn==1.5.1\nstreamlit==1.37.1\nuvicorn==0.34.0\nxgboost==2.1.3\n\n\n\n\n\n\nWhile this example provides step-by-step instructions, having a basic understanding of FastAPI and Docker concepts will be helpful. Learn more at:\n\nFastAPI: fastapi.tiangolo.com\nDocker: docs.docker.com\n\n\n\n\n\n\n2. Access to the Versioned Models\nYou’ll also need to ensure you have completed the previous hands-on examples where the apple demand forecasting model was trained, logged and versioned to MLflow. If you haven’t, refer to Section 6.7 and Section 7.4.\n\n\n3. Dataset for Predictions\nFor these examples, we’ll use simulated test data to feed into our deployed model to make predictions. The following represents a single input that could be fed into our model to mimic a real-time prediction. You can use this test_data.csv file.\n\n\n\n\n\n\n\n\n\n\naverage_temperature\nrainfall\nweekend\nholiday\nprice_per_kg\npromo\nprevious_days_demand\n\n\n\n\n1000\n28.566576\n1.405188\n1\n0\n1.542647\n0\n1640.0\n\n\n\n\n\n\n\n\nAnd the following represents multiple inputs that could be fed into our model to mimic a batch prediction. You can use this test_batch_data.csv file.\n\n\n\n\n\n\n\n\n\n\naverage_temperature\nrainfall\nweekend\nholiday\nprice_per_kg\npromo\nprevious_days_demand\n\n\n\n\n0\n30.584727\n12.212080\n0\n0\n1.333262\n0\n989.0\n\n\n1\n15.465069\n7.372440\n1\n0\n1.956357\n0\n989.0\n\n\n2\n10.786525\n1.700924\n1\n0\n2.198421\n0\n1110.0\n\n\n3\n23.648154\n2.684491\n0\n0\n1.861633\n0\n1256.0\n\n\n4\n13.861391\n2.013523\n0\n0\n2.781717\n0\n906.0\n\n\n5\n14.674082\n2.281109\n0\n0\n2.455626\n0\n965.0\n\n\n6\n20.558692\n1.871252\n0\n0\n2.276917\n0\n879.0\n\n\n7\n25.138812\n4.342813\n0\n0\n0.730149\n0\n855.0\n\n\n8\n22.308853\n0.599279\n1\n0\n2.880621\n0\n960.0\n\n\n9\n26.102977\n1.971698\n1\n0\n1.058829\n1\n1135.0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFeel free to generate your own test data using this notebook.\n\n\n\n\n\n\nRetrieving the Trained Model from MLflow\nBefore deploying the model, we need to retrieve it from the MLflow Model Registry. In the previous chapter, we saw how we can version our trained apple demand forecasting model to MLflow.\n\n\n\n\n\n\nCurrent Models Registered\n\n\n\n\nFigure 8.1: I currently have 4 models versions. Depending on what you did in the previous chapter you may have more or less models versioned.\n\n\n\nNow, that these model’s are registered, we can load the latest version of this model programmatically and make predictions with it. The following code2 shows an example of loading the latest model and making a prediction using simulated test data:\n\n\n# Requirements\nimport mlflow\nfrom apple_data import generate_apple_sales_data_with_promo_adjustment\n\n\n# Set experiment name\nmlflow.set_experiment(\"Forecasting Apple Demand\")\n\n# Define the model name and version\nMODEL_NAME = \"apple_demand\"\nMODEL_VERSION = \"latest\"  # Can specify 1, 2, etc. or \"latest\"\n\n# Load the model from MLflow Model Registry\nmodel_uri = f\"models:/{MODEL_NAME}/{MODEL_VERSION}\"\nmodel = mlflow.pyfunc.load_model(model_uri)\n\n# Create test data for model input\ntest_data = generate_apple_sales_data_with_promo_adjustment(base_demand=1_000, n_rows=1_001)\ntest_data = test_data.drop(columns=['demand', 'date']).iloc[[-1]]\n\n# Generate predictions\nmodel.predict(test_data)\n\narray([970.05157731])\n\n\n\nNotice that you can load a specific model version (i.e. version 1, version 3) or simply retrieve the latest version. This is very convenient as it allows us to always deploying the latest approved model or a specific version of the model. Moreover, programmatically retrieving the logged/versioned model helps ensure consistency between models used during experimentation and deployment environments.\n\n\n\n\n\n\nIn addition to loading a specific model version or the “latest” version, MLflow allows you to retrieve models based on tags (e.g., deployment_status=production) or aliases (e.g., champion). This makes it easier to dynamically load models without hardcoding version numbers, ensuring that deployments always pull the most relevant and validated model. Tags help categorize models based on their lifecycle stage, while aliases provide a flexible way to reference key models like the current production or staging version. This approach enhances automation, reproducibility, and scalability in model deployment workflows.\n\n\n\nNow that we know how to retrieve a registered model, the next step is to deploy it as a REST API using FastAPI.\n\n\nDeploy a FastAPI-based REST API for batch predictions\nAs machine learning models move from experimentation to production, they must be accessible to the systems and users that rely on them. One of the most common ways to expose a machine learning model is through a REST API, which allows external applications to send input data and receive predictions. In this example, we use FastAPI to deploy our model but realize there are other options as well (i.e. Flask).\nFor a grocery chain retailer, having a deployed API means that various business systems such as inventory management, supply chain logistics, and automated ordering systems can dynamically request demand forecasts and adjust operations accordingly. Instead of manually running a demand forecasting model every day, store managers, warehouse systems, or enterprise resource planning (ERP) tools can programmatically request demand predictions based on real-time market conditions, weather data, and sales history.\nFor example:\n\nA warehouse system could call this API every morning to predict how many apples each store is expected to sell in the coming days. This allows the retailer to optimize deliveries and reduce waste.\nA pricing system could query the API and adjust apple prices dynamically based on predicted demand, running promotions when demand is low or adjusting supply when demand spikes.\nA dashboard used by regional managers might fetch daily demand forecasts via this API to monitor trends and make data-driven stocking decisions.\n\nRather than requiring manual calculations or data science expertise at each store, this API could allow automated, real-time access to apple demand forecasts across the retailer’s entire network.\n\n\n\n\n\n\nUnderstanding APIs\n\n\n\n\n\nAs a data scientist, you may not be responsible for deploying models at scale, but understanding how APIs work helps you bridge the gap between model development and practical business impact. This section walks you through building and testing a simple API locally, showing how predictions can be served dynamically.\nEven if you don’t plan to build production APIs, reading through this section will help you appreciate the complexities involved in model deployment. At a minimum, understanding API-based deployment will allow you to better collaborate with software engineers and DevOps teams, ensuring your models are integrated seamlessly into the company’s workflows.\n\n\n\nOur first task is to create a new Python script called fastapi_app.py3 and add the following code.\nNote the key components in this code includes:\n\nFastAPI initialization (app = FastAPI())\nLoading the model from MLflow (mlflow.pyfunc.load_model())\nDefine the expected input schema (InputData())\nReal-time & batch prediction capabilities (predict_single(), predict_batch())\n\nfrom fastapi import FastAPI, HTTPException, UploadFile, File\nimport mlflow.pyfunc\nimport pandas as pd\nfrom pydantic import BaseModel\nfrom typing import List\nimport io\n\n# Initialize FastAPI app\napp = FastAPI()\n\n# Set experiment name\nmlflow.set_experiment(\"Forecasting Apple Demand\")\n\n# Load the trained model from MLflow\nMODEL_URI = \"models:/apple_demand@champion\"  # Replace with your model name and alias\nmodel = mlflow.pyfunc.load_model(MODEL_URI)\n\n\n# Define the expected input schema for a single prediction\nclass InputData(BaseModel):\n    average_temperature: float\n    rainfall: float\n    weekend: int\n    holiday: int\n    price_per_kg: float\n    promo: int\n    previous_days_demand: float\n\n\n@app.post(\"/predict\")\ndef predict_single(input_data: List[InputData]):\n    \"\"\"Endpoint for real-time predictions with a single input.\"\"\"\n\n    # Convert input to DataFrame\n    df = pd.DataFrame([data.dict() for data in input_data])\n\n    try:\n        # Make predictions\n        predictions = model.predict(df)\n\n        return {\"predictions\": predictions.tolist()}\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=str(e))\n\n\n@app.post(\"/predict_batch\")\nasync def predict_batch(file: UploadFile = File(...)):\n    \"\"\"Endpoint for batch predictions using a CSV file.\"\"\"\n    try:\n        # Read the uploaded CSV file\n        contents = await file.read()\n        df = pd.read_csv(io.StringIO(contents.decode(\"utf-8\")))\n\n        # Validate required columns\n        required_features = [\"average_temperature\", \"rainfall\", \"weekend\", \"holiday\", \"price_per_kg\", \"promo\", \"previous_days_demand\"]\n        if not all(feature in df.columns for feature in required_features):\n            missing_cols = set(required_features) - set(df.columns)\n            raise HTTPException(status_code=400, detail=f\"Missing columns: {missing_cols}\")\n\n        # Make batch predictions\n        predictions = model.predict(df)\n        return {\"predictions\": predictions.tolist()}\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=str(e))\nOnce you’ve added this code to the fastapi_app.py file, we can test it locally. First, launch the API using the following:\nuvicorn fastapi_app:app --host 0.0.0.0 --port 5000 --reload\n\n\n\n\n\n\nWhat is Uvicorn and Why Are We Using It?\n\n\n\n\n\n\nUvicorn is an ASGI (Asynchronous Server Gateway Interface) server that runs FastAPI applications.\nUnlike traditional WSGI servers (e.g., Flask’s built-in server), Uvicorn is:\n\nAsynchronous: Handles multiple requests efficiently.\nLightweight: Optimized for performance.\nProduction-Ready: Used for scalable API deployments.\n\n\n\n\n\nWhen you run the command, the server will start:\nINFO:     Uvicorn running on http://0.0.0.0:5000 (Press CTRL+C to quit)\nOnce the server is running, you can test it a couple different ways. First, you could test using curl like the following. This would imitate a real-time request to the model for a prediction based on the inputs.\ncurl -X POST \"http://127.0.0.1:5000/predict\" \\\n     -H \"Content-Type: application/json\" \\\n     -d '[\n           {\n             \"average_temperature\": 28.5,\n             \"rainfall\": 1.4,\n             \"weekend\": 0,\n             \"holiday\": 0,\n             \"price_per_kg\": 1.54,\n             \"promo\": 0,\n             \"previous_days_demand\": 1313.0\n           }\n         ]'\nExpected response:\n{\"predictions\": [970.0515773108884]}\n\n\n\n\n\n\nBatch predictions\n\n\n\n\n\nLikewise, you could use curl to make a batch prediction and reference a .csv file that contains multiple inputs requiring predictions:\ncurl -X POST \"http://127.0.0.1:5000/predict_batch\" \\\n     -H \"Content-Type: multipart/form-data\" \\\n     -F \"file=@test_batch_data.csv\"\nExpected response:\n{\"predictions\": [970.8774897603781,951.4406298526695,918.2921839400934,938.5186636642713,922.5670241420959,1196.1975513217837,1198.097164109545,993.6193679149401,906.596099831946,1221.0938533472397]}\n\n\n\nAn alternative approach is to use FastAPI’s interactive user interface. If you go to http://127.0.0.1:5000/docs (assuming your server is running), you’ll come to the UI which shows details on the /predict and /predict_batch endpoints, along with other information.\n\n\n\n\n\n\nFastAPI UI\n\n\n\n\nFigure 8.2: The FastAPI UI\n\n\n\nThis interactive UI allows you to test the endpoints directly from the browser! For example, if I go to the /predict_batch endpoint and hit Try it out, I can choose this test_batch_data.csv that contains 10 inputs for our model and then hit Execute and I will get the 10 predictions for each observation.\n\n\n\n\n\n\nFastAPI UI\n\n\n\n\nFigure 8.3: The interactive UI allows you to test out the endpoints. For example, this shows an example of using the /predict_batch endpoint on 10 example inputs provided in a test_batch_data.csv file.\n\n\n\n\n\nAdding a Streamlit UI for Interactive Predictions\nWhen developing a new ML application, one of the biggest challenges is ensuring that stakeholders, business leaders, and end users can interact with and understand the model’s outputs. Often, at the early stages of ML development, there is no existing user interface, and asking non-technical users to interact with an API or raw model outputs can be unrealistic.\nThis is where Streamlit becomes an invaluable tool.\nStreamlit allows you to quickly prototype an interactive UI for your ML model without needing extensive frontend development skills. With just a few lines of Python, you can create a fully functional web-based interface that enables users to explore how the model works, test different inputs, and visualize results.\n\nHow Streamlit Enhances ML Prototyping and Deployment\n\n\n\n\n\n\nBusiness Users & Analysts: Easy, Accessible Model Predictions\n\n\n\n\n\nBusiness stakeholders such as product managers, marketing teams, or financial analysts often need to understand how a machine learning model behaves before making strategic decisions. However, they typically do not have the technical expertise to run Python scripts or query an API.\nWith Streamlit, you can provide a simple, interactive dashboard where business users can:\n\nUpload CSVs and get batch predictions without writing code.\nManually input values and see how predictions change.\nVisualize insights through tables and charts that explain model behavior.\n\nBy giving non-technical users an easy way to interact with your model, you foster better collaboration between data science teams and business stakeholders, ensuring alignment on how the model can be leveraged.\n\n\n\n\n\n\n\n\n\nData Scientists: Testing Model Behavior Before Production\n\n\n\n\n\nFor data scientists, understanding how a model behaves under different conditions is critical before moving it to production. Debugging models using raw code or CLI-based scripts can be cumbersome, and API-based testing is not always intuitive.\nA Streamlit interface allows data scientists to:\n\nVisually inspect model outputs for various test cases.\nDebug predictions by modifying input parameters dynamically.\nCompare different model versions before selecting one for deployment.\n\nBy using Streamlit, data scientists can identify edge cases, uncover biases, and validate performance more efficiently than through static reports or raw log outputs.\n\n\n\n\n\n\n\n\n\nInternal Tools: Rapid Experimentation Before Full Integration\n\n\n\n\n\nWhen deploying an ML model within an organization, integrating it into an existing web or mobile application can take time. Engineers and developers often need to align APIs, databases, and UI components before the model becomes accessible to end users.\nInstead of waiting for full integration, a Streamlit-based internal tool can:\n\nAct as a temporary UI for stakeholders to test the model.\nProvide early feedback on how the model performs in real-world use cases.\nHelp engineers understand API requirements before building a production-ready frontend.\n\nBy using Streamlit as a stepping stone, teams can validate the usefulness of an ML model before committing significant resources to integrating it into an enterprise application.\n\n\n\nStreamlit bridges the gap between data science, engineering, and business stakeholders by making ML models interactive and accessible. Whether you are prototyping a new application, debugging a model, or providing a temporary interface for internal use, Streamlit allows you to rapidly deploy a functional UI in minutes.\nIn the next section, we will walk through how to integrate Streamlit with FastAPI to create an interactive frontend for ML predictions.\n\n\nStreamlit App for Model Predictions\nFirst, we’ll create a new Python script called streamlit_app.py4. This script should be in the sameproject directory as the fastapi_app.py script you created in the last section.\n📂 project_directory/\n│── 📄 fastapi_app.py        # FastAPI backend for ML model inference\n│── 📄 streamlit_app.py      # Streamlit frontend for UI-based interaction\nThe streamlit_app.py script will contain the following code:\nimport streamlit as st\nimport pandas as pd\nimport requests\n\n# FastAPI backend URL. Used to send requests from Streamlit\n# to FastAPI for model predictions.\nFASTAPI_URL = \"http://127.0.0.1:5000\"\n\nst.title(\"Apple Demand Forecasting - ML Model UI\")\n\n#################################\n# === Single Input Prediction ===\n#################################\n# Users can manually enter feature values for each feature\nst.subheader(\"Single Input Prediction\")\naverage_temperature = st.number_input(\"Average Temperature (°C)\", value=28.5)\nrainfall = st.number_input(\"Rainfall (mm)\", value=1.4)\nweekend = st.selectbox(\"Is it a weekend?\", [0, 1])\nholiday = st.selectbox(\"Is it a holiday?\", [0, 1])\nprice_per_kg = st.number_input(\"Price per Kg ($)\", value=1.54)\npromo = st.selectbox(\"Promotion Available?\", [0, 1])\nprevious_days_demand = st.number_input(\"Previous Days Demand\", value=1313)\n\n# This button triggers a request to FastAPI's /predict endpoint.\nif st.button(\"Predict Demand\"):\n    input_data = [{\n        \"average_temperature\": average_temperature,\n        \"rainfall\": rainfall,\n        \"weekend\": weekend,\n        \"holiday\": holiday,\n        \"price_per_kg\": price_per_kg,\n        \"promo\": promo,\n        \"previous_days_demand\": previous_days_demand\n    }]\n\n    response = requests.post(f\"{FASTAPI_URL}/predict\", json=input_data)\n\n    # The response is displayed on the Streamlit UI.\n    if response.status_code == 200:\n        prediction = response.json()[\"predictions\"][0]\n        st.success(f\"Predicted Demand: {prediction:.2f}\")\n    else:\n        st.error(\"Error fetching prediction. Check FastAPI logs.\")\n\n###########################################\n# === Batch Prediction with File Upload ===\n###########################################\n# Users can upload a CSV file containing multiple rows of input data.\nst.subheader(\"Batch Prediction via CSV Upload\")\nuploaded_file = st.file_uploader(\"Upload CSV file\", type=[\"csv\"])\n\nif uploaded_file:\n    df = pd.read_csv(uploaded_file)\n    st.write(\"Uploaded Data Preview:\", df.head())\n\n    # The file is sent to the FastAPI /predict_batch endpoint.\n    if st.button(\"Get Batch Predictions\"):\n        files = {\"file\": uploaded_file.getvalue()}\n        response = requests.post(f\"{FASTAPI_URL}/predict_batch\", files=files)\n\n        #Predictions are added to the dataset and displayed on the UI.\n        if response.status_code == 200:\n            predictions = response.json()[\"predictions\"]\n            df[\"Predicted Demand\"] = predictions\n            st.subheader(\"Predictions:\")\n            st.write(df)\n        else:\n            st.error(\"Error processing batch prediction.\")\n\n\nRunning FastAPI and Streamlit Together\nSince FastAPI serves as the backend for model inference and Streamlit acts as the frontend UI, both applications need to run simultaneously and communicate with each other. There are several ways to achieve this depending on whether you’re in a development or production environment.\n\nRunning them separately in different terminal windows (best for local development).\nRunning both from a single Python script using multiprocessing (useful for quick testing).\nContainerizing them with Docker Compose (best for deployment).\n\nWe’ll demo the first two approaches and then the next section will discuss the third.\n\n\n\n\n\n\nOption 1: Running Separately (Recommended for Development)\n\n\n\n\n\nThe simplest way to run FastAPI and Streamlit is to start them in separate terminal windows.\nStep 1: Start the FastAPI Backend\nNavigate to the directory where your fastapi_app.py file is located and run:\nuvicorn fastapi_app:app --host 0.0.0.0 --port 5000 --reload\nStep 2: Start the Streamlit Frontend\nOpen another terminal window, navigate to the directory where streamlit_app.py is located, and run:\nstreamlit run streamlit_app.py\nThis starts the Streamlit UI on http://127.0.0.1:8501 and will send API requests to FastAPI to retrieve predictions.\n\n\n\nStreamlit UI\n\n\n\n\n\n\n\n\n\n\n\nOption 2: Running FastAPI and Streamlit from a Single Script\n\n\n\n\n\nIf you want to start both applications from one script, you can use Python’s multiprocessing module to run them in parallel. You’ll need to create a new script titled fastapi_streamlit.py5 that is in the same directory as your other app scripts.\n📂 project_directory/\n│── 📄 fastapi_app.py        # FastAPI backend for ML model inference\n│── 📄 streamlit_app.py      # Streamlit frontend for UI-based interaction\n│── 📄 fastapi_streamlit.py  # Run both FastAPI and Streamlit concurrently\nThe fastapi_streamlit.py should have the following code.\nimport multiprocessing\nimport os\nimport signal\nimport sys\n\nimport uvicorn\n\n\ndef run_fastapi():\n    \"\"\"Start the FastAPI app\"\"\"\n    uvicorn.run(\"fastapi_app:app\", host=\"0.0.0.0\", port=5000, reload=False)\n\n\ndef run_streamlit():\n    \"\"\"Start the Streamlit app\"\"\"\n    os.system(\"streamlit run streamlit_app.py\")\n\n\ndef shutdown_handler(signum, frame):\n    \"\"\"Gracefully terminate child processes\"\"\"\n    print(\"\\nShutting down FastAPI and Streamlit...\")\n\n    p1.terminate()\n    p2.terminate()\n\n    p1.join()\n    p2.join()\n\n    sys.exit(0)  # Exit the script cleanly\n\n\nif __name__ == \"__main__\":\n    # Run FastAPI and Streamlit in parallel processes\n    multiprocessing.set_start_method(\"spawn\")\n\n    p1 = multiprocessing.Process(target=run_fastapi, daemon=True)  # Set daemon mode\n    p2 = multiprocessing.Process(target=run_streamlit, daemon=True)\n\n    p1.start()\n    p2.start()\n\n    # Capture termination signals\n    signal.signal(signal.SIGINT, shutdown_handler)  # Handle Ctrl+C\n    signal.signal(\n        signal.SIGTERM, shutdown_handler\n    )  # Handle termination (e.g., Docker stop)\n\n    try:\n        p1.join()\n        p2.join()\n    except KeyboardInterrupt:\n        shutdown_handler(None, None)  # Gracefully shut down on manual interrupt\nIn your terminal window, navigate to the directory where fastapi_streamlit.py is located, and run:\npython fastapi_streamlit.py\nThis will start both applications automatically so that as you provide inputs to the Streamlit frontend UI, it will automatically send the inputs to the FastAPI backend.\n\n\n\n\n\n\nContainerizing the Application\nContainerization is a critical practice in modern software deployment that ensures portability, reproducibility, and scalability. By packaging an application with all its dependencies into a Docker container, we eliminate issues related to environment inconsistencies, making it easy to deploy on any system, cloud platform, or cluster.\nThe primary benefits of containerizing a solution includes:\n\nPortability – Containers run consistently across different environments (local, cloud, on-premises).\nReproducibility – Ensures that dependencies, libraries, and configurations remain consistent.\nScalability – Containers can be efficiently orchestrated using tools like Kubernetes.\nIsolation – Each container runs independently, preventing dependency conflicts.\nEfficient Resource Utilization – Containers are lightweight compared to traditional virtual machines.\n\nFor this project, we will containerize both the FastAPI backend and the Streamlit frontend to ensure a smooth and efficient deployment.\n\nProject Directory Structure\nTo fully support FastAPI, Streamlit, and MLflow, our project will be structured as follows:\n📂 model-deploy/\n│── 📄 fastapi_app.py         # FastAPI backend\n│── 📄 streamlit_app.py       # Streamlit frontend\n│── 📄 fastapi_streamlit.py   # Script to run both apps together\n│── 📄 requirements.txt       # Python dependencies\n│── 📄 Dockerfile             # Defines how to build the container\n│── 📄 .dockerignore          # Excludes unnecessary files from the Docker build\n│── 📄 docker-compose.yml     # Adds MLflow environment variable and volume containing local path\n\n\n\n\n\n\nYou can find this directory and all the files discussed here: https://github.com/bradleyboehmke/uc-bana-7075/tree/main/ModelOps/model-deploy.\n\n\n\n\n\nDockerfile\nThe Dockerfile defines how our container is built, specifying the Python version, copying necessary files, installing dependencies, and setting the startup command.\n# Use official Python image\nFROM python:3.12\n\n# Set the working directory in the container\nWORKDIR /app\n\n# Copy all application files to the container\nCOPY . /app\n\n# Install dependencies\nRUN pip install --no-cache-dir -r requirements.txt\n\n# Expose necessary ports for FastAPI (5000) and Streamlit (8501)\nEXPOSE 5000 8501\n\n# Start both FastAPI and Streamlit using the Python script\nCMD [\"python\", \"fastapi_streamlit.py\"]\n\n\n.dockerignore File\nThis prevents unnecessary files (like __pycache__ and .git) from being copied into the container, reducing build size.\n__pycache__/\n*.pyc\n*.pyo\n*.log\n.git/\n\n\nUsing Docker Compose to Manage Containers\nInstead of running the container manually, we use Docker Compose to define and manage the service. The docker-compose.yml file makes it easier to configure the application and allows us to mount local directories for data persistence.\nservices:\n  model-deploy:\n    image: model-deploy-app  # Set a custom, shorter image name\n    build: .\n    ports:\n      - \"5000:5000\"\n      - \"8501:8501\"\n    environment:\n      - MLFLOW_TRACKING_URI=file:///app/mlflow_registry/mlruns\n    volumes:\n      - /Users/b294776/Desktop/workspace/training/UC/uc-bana-7075/ModelOps/mlruns:/app/mlflow_registry/mlruns\nKey Features of docker-compose.yml includes:\n\nVolume Mounting (volumes): We mount the local MLflow experiment directory to the container so that the FastAPI app inside the container can access models stored on the host machine.\nEnvironment Variables (environment): We set MLFLOW_TRACKING_URI, allowing the containerized application to locate MLflow experiments.\nPort Mapping (ports): The container exposes FastAPI (5000) and Streamlit (8501) so they can be accessed from the host machine.\n\n\n\n\n\n\n\nSince we are hosting MLflow locally, we need to explicitly reference our local MLflow experiment path in docker-compose.yml. However, in a real-world scenario, organizations typically host MLflow models in a central storage location (e.g., AWS S3, Azure Blob Storage, or an MLflow server). In such a setup, instead of using a local volume, we would pass the cloud storage path to MLFLOW_TRACKING_URI, like:\nenvironment:\n  - MLFLOW_TRACKING_URI=s3://my-mlflow-bucket/mlruns\nThis makes the system cloud-compatible and scalable, allowing multiple services to retrieve models from a shared registry.\n\n\n\n\n\nBuilding and Running the Docker Container\nNow that we have everything set up, we’re ready to build and run our Docker image. Navigate to the model-deploy directory:\ncd /path/to/model-deploy\nand run the following to build the Docker image:\ndocker-compose build --no-cache\nNow that your Docker image is built you can start the container with:\ndocker-compose up\nNow:\n\nFastAPI should be available at http://127.0.0.1:5000/docs\nStreamlit UI should be accessible at http://127.0.0.1:8501\n\nTo stop the container, run:\ndocker-compose down\n\n\nScaling with Kubernetes\nOnce the application is containerized, the next step toward a production-ready deployment is scalability. In real-world environments, machine learning models often need to handle varying workloads, ranging from a few requests per second in development to thousands per second in production. Kubernetes, an industry-standard container orchestration platform, provides a robust and flexible way to manage and scale containerized applications.\nOne of the key benefits of Kubernetes is its ability to manage multiple replicas of services such as FastAPI to handle higher request volumes. In a production setting, rather than running a single instance of FastAPI, Kubernetes can deploy multiple replicas of the FastAPI service, ensuring that requests are distributed efficiently across different pods. This improves availability and ensures the system can handle spikes in traffic without degrading performance.\nIn addition to horizontal scaling, Kubernetes also provides load balancing through its Ingress Controller or built-in LoadBalancer service. When multiple replicas of the FastAPI service are running, a Kubernetes Ingress Controller can act as a gateway that efficiently distributes incoming requests to different FastAPI pods. This ensures no single instance becomes overwhelmed, improving both response time and system reliability.\nKubernetes also allows seamless model versioning by dynamically pulling new model artifacts from a centralized model registry. This allows FastAPI pods running in Kubernetes to dynamically load the latest version of a model without requiring a full redeployment of the application.\nAnother significant advantage of using Kubernetes is its auto-scaling capabilities. Kubernetes can automatically scale up the number of running FastAPI instances when CPU or memory usage surpasses a certain threshold. Conversely, during periods of low activity, Kubernetes can scale down instances to reduce infrastructure costs, making the system both cost-effective and efficient.\nFinally, in deployments that require high availability and fault tolerance, Kubernetes provides built-in self-healing mechanisms. If a FastAPI or Streamlit pod crashes unexpectedly, Kubernetes will automatically restart the service to maintain uptime. This feature is particularly valuable in production environments where unexpected failures can impact business operations.\nIn summary, Kubernetes offers a powerful way to manage and scale ML model deployments, ensuring that applications are highly available, performant, and cost-effective. By incorporating Kubernetes into this workflow, organizations can transition from local, manually managed deployments to scalable, production-grade infrastructure that dynamically adapts to changing workloads.\n\n\n\nFinal Thoughts\nBy containerizing the FastAPI backend, Streamlit frontend, and MLflow model registry, we have created a fully functional machine learning deployment pipeline that is portable, scalable, and reproducible. The use of Docker ensures that both services can run in any environment, eliminating compatibility issues and making it easier to share and deploy models.\nThroughout this example, we have demonstrated how FastAPI serves as an API layer for model inference, while Streamlit provides a user-friendly interface for business users and data scientists to interact with the model. Additionally, MLflow serves as a lightweight experiment tracking and model registry solution, enabling seamless model management.\nFor development and testing, running FastAPI and Streamlit together using Docker Compose provides an efficient way to simulate a production-like setup on a local machine. This allows for quick iteration and debugging while maintaining separation between services. However, as machine learning applications grow and need to support high traffic, Kubernetes becomes the next logical step. It allows organizations to dynamically scale services, manage load balancing, and ensure high availability with minimal manual intervention.\nOverall, this approach provides a realistic, scalable solution for machine learning model deployment, bringing together some of the best tools in the ModelOps ecosystem. By leveraging containerization, API-driven model serving, and interactive UI design, this setup can be extended to enterprise-level deployments with minimal modifications. Whether the goal is to deploy models in a local setting for internal use or scale up to handle thousands of requests per second in production, the tools and techniques demonstrated here provide a strong foundation for operationalizing machine learning models effectively.",
    "crumbs": [
      "ModelOps",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Model Deployment</span>"
    ]
  },
  {
    "objectID": "08-modelops-deployment.html#strategies-for-updating-models-in-production",
    "href": "08-modelops-deployment.html#strategies-for-updating-models-in-production",
    "title": "8  Model Deployment",
    "section": "8.5 Strategies for Updating Models in Production",
    "text": "8.5 Strategies for Updating Models in Production\nThus far, we’ve discussed the process of deploying a machine learning model into production. However, deployment is not a one-and-done task. Once a model is in production, you will often need to make updates and redeploy new versions of the model. These updates might be necessary due to retraining on fresh data, improvements in model architecture, changes in business requirements, or performance degradation caused by data drift.\nEffectively managing these updates while ensuring a smooth transition is critical to maintaining reliability and minimizing risk. There are several widely used strategies to introduce new models into production while balancing performance, user experience, and operational stability:\n\n\n\n\n\n\nCanary Deployment\n\n\n\n\n\nDescription: This approach involves releasing the new model to a small subset of users or traffic while the majority continues using the current production model. The performance of the new model is closely monitored, and based on the results, the deployment can either be scaled up or rolled back.\nWhen to Use: Canary deployments are ideal for environments where testing in production with minimal risk is a priority. For example, an e-commerce platform could test a new recommendation model with 5% of users to verify its effectiveness without disrupting the overall user experience.\nBenefits:\n\nAllows real-world testing with minimal impact.\nProvides the flexibility to revert quickly if issues arise.\n\nChallenges:\n\nRequires robust monitoring and the ability to manage traffic routing.\n\n\n\n\n\n\n\n\n\n\nBlue-Green Deployment\n\n\n\n\n\nDescription: In a blue-green deployment, both the old (blue) and new (green) models are run in parallel. The system routes traffic to the new model only after it has been fully validated. This strategy ensures zero downtime, as the old model remains available until the new one is deemed stable.\nWhen to Use: This strategy is well-suited for high-stakes applications where downtime is unacceptable, such as financial fraud detection systems or real-time healthcare monitoring.\nBenefits:\n\nEliminates downtime during updates.\nSimplifies rollback processes since the old model is still live.\n\nChallenges:\n\nResource-intensive, as it requires maintaining two fully operational systems simultaneously.\nCan introduce complexity in managing environments.\n\n\n\n\n\n\n\n\n\n\nShadow Deployment\n\n\n\n\n\nDescription: In this strategy, the new model operates alongside the current production model but does not impact users. Instead, the new model receives a copy of the production data for inference. This approach is used to evaluate the new model’s performance against the current model in a real-world setting without influencing the end-user experience.\nWhen to Use: Shadow deployments are particularly useful for testing how a new model would perform under production conditions without any risk to users. For example, a logistics company could shadow-deploy a new route optimization model to analyze its predictions compared to the current model.\nBenefits:\n\nProvides a risk-free way to validate the new model under live conditions.\nEnables performance comparisons using production data.\n\nChallenges:\n\nRequires infrastructure to duplicate traffic and collect results.\nCan increase operational costs due to redundant processing.\n\n\n\n\nWhen updating models in production, it’s essential to balance the risks and benefits of each strategy. Monitoring the new model’s performance under real-world conditions is critical to identifying any issues early and ensuring the model meets business and user requirements. Gradually scaling the deployment also helps stabilize operations, especially for systems handling critical tasks.\n\n\n\n\n\n\nA Note on Model Evaluation\n\n\n\nOnce a model is in production, evaluating the performance of new models compared to existing ones becomes a vital part of the lifecycle. Common approaches to evaluate new models include A/B testing, where users are randomly assigned to the old or new model to compare outcomes, and multi-armed bandits, which dynamically allocate traffic to the best-performing model. These methods are often used in conjunction with deployment strategies like canary or shadow deployments to assess the new model’s impact.\nWhile the topic of model evaluation is beyond the scope of this chapter, resources such as the Google Machine Learning Guide and these articles on A/B testing and Multi-armed bandits provide valuable insights for those interested in learning more.",
    "crumbs": [
      "ModelOps",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Model Deployment</span>"
    ]
  },
  {
    "objectID": "08-modelops-deployment.html#summary",
    "href": "08-modelops-deployment.html#summary",
    "title": "8  Model Deployment",
    "section": "8.6 Summary",
    "text": "8.6 Summary\nIn this chapter, we explored the critical aspects of model deployment, building on previous discussions of model tracking and versioning. We began by outlining key considerations for deploying machine learning models, covering factors such as inference type, deployment environments, and collaboration with engineering teams. From there, we delved into deployment strategies, comparing batch and real-time inference while also examining different production update strategies like Canary, Blue-Green, and Shadow Deployments.\nTo bring these concepts to life, we walked through a hands-on example, demonstrating how to deploy a trained apple demand forecasting model using FastAPI, Streamlit and Docker. This included retrieving a versioned model from MLflow, developing an API to serve predictions, creating a front-end UI to interact with FastAPI and view the predictions, and containerizing the application for a reliable and scalable deployment pipeline.\nWhile deployment ensures a model is accessible in production, the work does not stop there. Once deployed, models must be monitored continuously to detect performance degradation, data drift, and unexpected failures. In the next chapter, we will focus on model monitoring, covering best practices, tools, and strategies to ensure that models continue to deliver accurate and reliable predictions in real-world conditions.",
    "crumbs": [
      "ModelOps",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Model Deployment</span>"
    ]
  },
  {
    "objectID": "08-modelops-deployment.html#exercise",
    "href": "08-modelops-deployment.html#exercise",
    "title": "8  Model Deployment",
    "section": "8.7 Exercise",
    "text": "8.7 Exercise\nIn this exercise, you will build upon the California housing price prediction task from previous exercises6 and take the next step: deploying your trained model as an API and integrating a user-friendly Streamlit app as a front-end interface. This will simulate a real-world scenario where users can interact with the model through an application.\n\n\n\n\n\n\nPart 1: Conceptual Design\n\n\n\n\n\nBefore jumping into implementation, think about how this model would be used in a real-world setting. Answer the following questions:\n\nInference Type:\n\nWould batch inference or real-time inference be more appropriate for a housing price prediction model?\nWho are the potential users of this model (e.g., real estate analysts, homebuyers, realtors), and how might they interact with it?\n\nDeployment Strategy:\n\nIf you needed to update the model in production, which strategy (Canary, Blue-Green, or Shadow deployment) would you choose and why?\nHow would you ensure that the deployed model is reliable and scalable?\n\nSystem Integration:\n\nHow could this model integrate into a real estate application or property valuation tool?\nWhat external systems (e.g., databases, business intelligence dashboards) might need access to the model’s predictions?\n\n\n\n\n\n\n\n\n\n\n\nPart 2: Hands-On Experimentation\n\n\n\n\n\nNow, you will deploy your trained California housing price model as a FastAPI-based REST API, create a Streamlit front-end UI to interact with FastAPI, and containerize it with Docker.\n\nRetrieve Your Trained Model\n\nLoad your previously trained California housing price model from MLflow.\nEnsure that you are retrieving the correct version from the MLflow model registry.\n\nBuild a FastAPI Application\n\nCreate a FastAPI app that exposes an endpoint (/predict) to receive requests and return predicted house prices.\nAllow the API to accept both a single input (for real-time inference) and a CSV file (for batch inference).\n\nCreate a Streamlit UI for Model Interaction\n\nBuild a Streamlit app that serves as a user-friendly front end to interact with the model.\nThe app should:\n\nAllow users to input features manually for real-time predictions.\nEnable uploading a CSV file for batch predictions.\nDisplay the model’s predictions in a clear and structured format.\n\nThe Streamlit app should send requests to the FastAPI backend and display the returned predictions.\n\nContainerize the API with Docker\n\nWrite a Dockerfile to package the FastAPI and Streamlit application.\nBuild and run the Docker container locally to ensure the API is functioning correctly.\n\nTest the End-to-End System\n\nRun the FastAPI server and the Streamlit app simultaneously.\nTest making predictions through both the Streamlit UI and direct API calls (via curl or requests).\nTry making a prediction for a single home and for multiple homes using a CSV file.\n\n\n\n\n\n\n\n\n\n\n\nPart 3: Reflection on Deployment Considerations\n\n\n\n\n\nNow that you’ve deployed your model, reflect on the process:\n\nChallenges & Optimizations\n\nWhat challenges did you face while deploying the model?\nHow could you optimize this deployment for scalability and performance?\n\nDesign Principles in Deployment\n\nReview the ML system design principles discussed in Section 1.3.\nHow does your deployment incorporate principles like modularity, scalability, reproducibility, or adaptability/flexibility?\nWhat design trade-offs did you encounter, and how would you improve your deployment using these principles?",
    "crumbs": [
      "ModelOps",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Model Deployment</span>"
    ]
  },
  {
    "objectID": "08-modelops-deployment.html#footnotes",
    "href": "08-modelops-deployment.html#footnotes",
    "title": "8  Model Deployment",
    "section": "",
    "text": "See the modelops-requirements.txt file.↩︎\nSee this notebook: https://github.com/bradleyboehmke/uc-bana-7075/blob/main/ModelOps/model-retrieval.ipynb↩︎\nSee this python script: https://github.com/bradleyboehmke/uc-bana-7075/blob/main/ModelOps/fastapi_app.py↩︎\nSee this python script: https://github.com/bradleyboehmke/uc-bana-7075/blob/main/ModelOps/streamlit_app.py↩︎\nSee this python script: https://github.com/bradleyboehmke/uc-bana-7075/blob/main/ModelOps/fastapi_streamlit.py↩︎\nSee Exercise 6.7 and Exercise 7.6↩︎",
    "crumbs": [
      "ModelOps",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Model Deployment</span>"
    ]
  },
  {
    "objectID": "09-modelops-monitoring.html",
    "href": "09-modelops-monitoring.html",
    "title": "9  Model Monitoring",
    "section": "",
    "text": "9.1 Why is Model Monitoring Important?\nDeploying a machine learning model is not the final step in an ML workflow, it’s just the beginning. Once a model is in production, its performance can degrade over time due to changes in data patterns, evolving user behavior, or shifts in external factors that were not present in the training data. Without a robust monitoring system in place, organizations risk relying on outdated or inaccurate predictions, which can lead to poor business decisions and financial losses.\nModel monitoring provides a structured way to continuously track and evaluate model performance, ensuring reliability and accountability in production environments. It helps detect issues such as data drift (when the input data distribution changes), concept drift (when the relationship between inputs and outputs evolves), and operational failures (such as increased response times or system crashes). By implementing real-time monitoring, data teams can identify problems early, trigger alerts, and take corrective action — whether by retraining the model, adjusting its parameters, or even rolling back to a previous version.\nThis chapter will explore the different types of model monitoring, the key components of an effective monitoring system, and popular tools used to track model performance. We’ll also walk through a hands-on example, where we implement a basic monitoring system for the apple demand forecasting model introduced in previous chapters. By the end, you’ll understand how to build scalable, automated monitoring pipelines that keep models performant and aligned with business objectives.\nMachine learning models do not exist in a static environment—once deployed, they are exposed to new and evolving data that may differ from what they were trained on. Without continuous monitoring, model performance can degrade, leading to inaccurate predictions and potentially costly business decisions. Model monitoring is a critical component of an operational ML system, ensuring that models remain reliable, fair, and performant in real-world applications.",
    "crumbs": [
      "ModelOps",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Model Monitoring</span>"
    ]
  },
  {
    "objectID": "09-modelops-monitoring.html#why-is-model-monitoring-important",
    "href": "09-modelops-monitoring.html#why-is-model-monitoring-important",
    "title": "9  Model Monitoring",
    "section": "",
    "text": "Key Reasons for Model Monitoring\n\n\n\n\n\n\nEnsuring Performance Consistency\n\n\n\n\n\nOver time, models may experience a decline in accuracy or other evaluation metrics due to shifts in data distributions or changes in real-world conditions. Monitoring helps track performance trends and detect issues early.\n\n\n\n\n\n\n\n\n\nDetecting Data Drift and Concept Drift\n\n\n\n\n\nModels rely on patterns in historical data to make predictions. If these patterns shift (data drift) or the relationship between input features and predictions changes (concept drift), the model may no longer be valid. Monitoring helps catch these shifts before they cause significant problems.\n\n\n\n\n\n\n\n\n\nMaintaining Business Value\n\n\n\n\n\nA poorly monitored model can lead to incorrect recommendations, financial losses, or compliance risks, depending on the application. By continuously tracking performance, organizations can proactively intervene when necessary.\n\n\n\n\n\n\n\n\n\nEnsuring Operational Stability\n\n\n\n\n\nBeyond accuracy, models must also function efficiently in production environments. Monitoring helps track API response times, infrastructure performance, and overall system health.\n\n\n\nTo address these challenges, model monitoring systems track various aspects of model performance, including predictive accuracy, data consistency, and operational efficiency.\n\n\nTypes of Model Monitoring\nEffective model monitoring involves tracking multiple dimensions of model performance, data integrity, and system stability. The key types of monitoring include:\n\n\n\n\n\n\nPerformance Monitoring\n\n\n\n\n\nPerformance monitoring tracks a model’s predictive accuracy over time to ensure that it continues to produce reliable outputs. Common metrics include:\n\nRegression models: RMSE (Root Mean Squared Error), MAE (Mean Absolute Error), R²\nClassification models: Accuracy, Precision, Recall, F1-score, AUC-ROC\nForecasting models: MAPE (Mean Absolute Percentage Error), MSE (Mean Squared Error)\n\nWhen a model’s performance declines beyond an acceptable threshold, teams can investigate the cause and take corrective action, such as retraining the model with fresh data or adjusting its hyperparameters.\n\n\n\n\n\n\nModel Decay\n\n\n\n\nFigure 9.1: Performance monitoring tracks a model’s predictive accuracy over time. The decrease of the performance metric can be used to trigger model retraining, which leads to model recovery. source\n\n\n\nExample: A demand forecasting model for a grocery retailer consistently achieves an RMSE of 50 units per week. However, after a few months, the RMSE increases to 120 units, indicating that the model’s predictions are becoming less reliable. Monitoring helps flag this change and allows the team to retrain the model with updated data.\n\n\n\n\n\n\n\n\n\nData Drift Monitoring\n\n\n\n\n\nData drift occurs when the statistical properties of input features change over time. This can lead to unexpected model behavior and degraded performance. Monitoring data drift involves tracking feature distributions and identifying deviations from the training data.\nKey Indicators of Data Drift:\n\nChanges in mean, variance, or distribution of input features.\nIncreased outliers in newly ingested data.\nShift in feature correlations compared to the training dataset.\n\nExample:\nImagine a retail chain that uses machine learning to predict how many products of a particular type they need to stock in each of their stores. They trained their model using historical sales data from the past few years.\nUntil now, most of their sales have been in physical stores, and their model has become quite good at forecasting demand for in-store products. However, as the retailer ran a marketing campaign to promote their new mobile app, there’s been a significant shift towards online sales, especially for some product categories.\nThe training data didn’t have enough online sales information, so the model didn’t perform as well for this segment. But it didn’t matter much because online sales were a small part of their business. With the surge in online shopping, the quality of the model’s forecasts has significantly dropped, affecting their ability to manage inventory effectively.\nThis shift in sales channels, from predominantly in-store to largely online, is an example of data drift.\n\n\n\n\n\n\nData Drift\n\n\n\n\nFigure 9.2: An example of data drift is a change in sales distribution by channel. source\n\n\n\n\n\n\n\n\n\nRead more about data drift here: https://www.evidentlyai.com/ml-in-production/data-drift\n\n\n\n\n\n\n\n\n\n\n\n\nConcept Drift Monitoring\n\n\n\n\n\nConcept drift happens when the relationship between input features and predictions changes over time. Unlike data drift (which concerns changes in input data distribution), concept drift affects how a model interprets data. While data drift describes changes in the data distribution, concept drift relates to changes in the relationships between input and target variables. Basically, concept drift means that whatever your model is predicting – it is changing.\nCommon Causes of Concept Drift:\n\nChanges in user behavior (e.g., customer preferences shift).\nMarket changes affecting feature importance.\nSeasonality or external factors introducing new trends.\n\nExample:\nA recommendation system for an e-commerce website suggests products based on past user behavior. However, as new shopping trends emerge (e.g., a sudden rise in eco-friendly products), user preferences change. Concept drift monitoring helps detect these shifts and prompts model adjustments.\nAnother instance could be the onset of COVID-19, which transformed how people shopped and disrupted logistical patterns. In these cases, all previously created models became almost obsolete.\n\n\n\n\n\n\nConcept Drift\n\n\n\n\nFigure 9.3: Whereas data drift refers to the shifts in input feature distributions, concept drift refers to shifts in the relationships between model inputs and outputs. source\n\n\n\n\n\n\n\n\n\nRead more about concept drift here: https://www.evidentlyai.com/ml-in-production/data-drift\n\n\n\n\n\n\n\n\n\n\n\n\nOperational Monitoring\n\n\n\n\n\nOperational monitoring focuses on ensuring the reliability and efficiency of model-serving infrastructure. It tracks key deployment metrics, including:\n\nAPI Latency: Response time of the model’s predictions.\nInfrastructure Load: Resource consumption (CPU, memory, GPU usage).\nError Logs: Detecting system failures, API timeouts, or unusual error rates.\n\nExample: A fraud detection model deployed as an API for real-time transactions experiences an increase in response times from 100ms to 2 seconds. This delay could impact the customer experience and lead to transaction failures. Operational monitoring alerts engineers to the issue so they can optimize the model-serving pipeline.\n\n\n\nModel monitoring is a crucial part of maintaining ML models in production, ensuring they remain accurate, robust, and scalable. Whether tracking predictive performance, detecting data drift, or maintaining operational stability, effective monitoring allows teams to intervene before performance issues impact business decisions. In the next section, we will explore the key components of a robust model monitoring system, providing insights into what should be tracked and why.",
    "crumbs": [
      "ModelOps",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Model Monitoring</span>"
    ]
  },
  {
    "objectID": "09-modelops-monitoring.html#key-components-of-model-monitoring",
    "href": "09-modelops-monitoring.html#key-components-of-model-monitoring",
    "title": "9  Model Monitoring",
    "section": "9.2 Key Components of Model Monitoring",
    "text": "9.2 Key Components of Model Monitoring\nEnsuring the reliability and accuracy of machine learning models in production requires a robust monitoring system. A well-designed model monitoring framework consists of multiple key components that provide insights into performance, data integrity, and operational stability. In this section, we break down the essential components of model monitoring and how they align with the four primary types of monitoring: performance monitoring, data drift monitoring, concept drift monitoring, and operational monitoring.\n\n\n\n\n\n\nData Logging & Storage\n\n\n\n\n\nOne of the foundational elements of model monitoring is comprehensive data logging. Every input fed into the model and every output generated should be logged and stored to enable retrospective analysis, debugging, and compliance auditing.\nWhat Needs to Be Logged?\n\nInput Features – The actual data used for making predictions.\nModel Predictions – The output generated by the model.\nGround Truth Labels – The actual observed outcomes (when available).\nMetadata – Additional details such as timestamps, user IDs, or session information.\nInfrastructure Logs – CPU/memory usage, response times, request logs.\n\nWhy It Matters?\n\nEnables troubleshooting when unexpected behavior occurs.\nSupports comparative analysis between different model versions.\nFacilitates model retraining by capturing historical data distributions.\nAids in regulatory compliance by ensuring transparency.\n\nExample:\nImagine a fraud detection model deployed at a financial institution. Logging transaction details (e.g., amount, location, device used) alongside fraud predictions allows auditors to investigate flagged transactions and detect inconsistencies in the model’s decision-making.\n\n\n\n\n\n\n\n\n\nModel Performance Metrics\n\n\n\n\n\nTracking model performance over time ensures that predictions remain accurate and aligned with business goals. A model that performed well during training may degrade in production due to changing data distributions, adversarial behavior, or unanticipated scenarios.\nKey Metrics to Track\n\nClassification Models: Accuracy, Precision, Recall, F1-score, AUC-ROC.\nRegression Models: RMSE, MAE, R², MAPE.\nForecasting Models: Mean Squared Error (MSE), Symmetric Mean Absolute Percentage Error (SMAPE).\nOperational Metrics: Prediction latency, inference throughput.\n\nWhy It Matters?\n\nDetects gradual performance degradation over time.\nHelps diagnose if the model is suffering from overfitting or underfitting.\nAllows teams to compare different models before making updates.\nHelps assess whether a model meets business KPI objectives.\n\nExample:\nA customer support chatbot tracks its accuracy by monitoring whether users rephrase or repeat their questions after receiving responses. A decline in accuracy over time could indicate drift in language patterns, requiring the chatbot’s model to be retrained with updated conversations.\n\n\n\n\n\n\n\n\n\nData Drift Detection\n\n\n\n\n\nData drift occurs when the distribution of input features changes over time, making the model less reliable. This often happens due to seasonal trends, user behavior shifts, or external factors like economic fluctuations.\nWhat to Monitor?\n\nFeature Statistics – Mean, variance, correlation between features.\nCategorical Changes – Shift in frequency of categorical variables.\nNew Feature Values – The emergence of previously unseen data points.\n\nWhy It Matters?\n\nPrevents models from making predictions based on outdated assumptions.\nHelps ensure models are trained on data distributions similar to production data.\nFlags changes in data pipelines that may introduce unexpected biases.\n\nExample:\nA credit risk model was trained with past banking data assuming most applicants were full-time employees. Over time, the number of gig economy workers applying for loans increases significantly, leading to data drift. If not detected, the model may underperform or systematically reject new valid applicants.\n\n\n\n\n\n\n\n\n\nConcept Drift Detection\n\n\n\n\n\nConcept drift refers to changes in the relationship between inputs and outputs. Even if the input data distribution remains stable, the way features correlate with predictions may shift, leading to unreliable models.\nTypes of Concept Drift\n\nSudden Drift: A major shift in feature importance occurs abruptly.\nIncremental Drift: The relationship between input and output changes gradually.\nRecurring Drift: Seasonal effects cause relationships to fluctuate over time.\n\nWhy It Matters?\n\nEnsures models do not rely on outdated assumptions.\nIdentifies scenarios where the meaning of labels changes.\nHelps teams decide when to retrain models based on changing trends.\n\nExample:\nA product recommendation model trained pre-pandemic suggested travel-related products based on user browsing patterns. However, during the pandemic, consumer behavior changed drastically, and prior patterns no longer correlated with purchase behavior. The model’s relevance degraded due to concept drift.\n\n\n\n\n\n\n\n\n\nInfrastructure and API Monitoring\n\n\n\n\n\nBeyond model predictions, monitoring the technical health of deployed models is equally important. Even the most accurate models can fail to provide value if they suffer from downtime, latency issues, or resource constraints.\nKey Infrastructure Metrics\n\nAPI Latency – Time taken for the model to return a prediction.\nRequest Volume – Number of prediction requests per second.\nSystem Load – CPU and memory consumption during inference.\nFailure Rate – Frequency of errors or timeouts in serving predictions.\n\nWhy It Matters?\n\nPrevents service disruptions by identifying infrastructure bottlenecks.\nEnsures scalability of model inference under high loads.\nFlags API outages before they impact users.\n\nExample:\nAn e-commerce company deploys a dynamic pricing model that adjusts product prices in real time. If the model’s API slows down significantly on Black Friday due to high traffic, it could lead to delayed price updates and revenue loss. Monitoring API latency ensures infrastructure auto-scaling is triggered to handle increased demand.\n\n\n\n\n\n\n\n\n\nAutomated Alerts & Retraining Triggers\n\n\n\n\n\nOnce an issue is detected—whether it’s a drop in accuracy, data drift, or increased latency—it’s crucial to have an automated mechanism to trigger alerts and model updates.\nCommon Alerting Triggers\n\nPerformance Threshold Breach: When accuracy falls below a pre-defined limit.\nSignificant Data Drift: A major shift in feature distributions.\nInference Latency Spikes: If model response time exceeds expectations.\n\nRetraining Triggers\n\nScheduled Retraining: Periodic model updates (e.g., weekly, monthly).\nAdaptive Retraining: Triggered only when performance degradation is detected.\nEvent-Driven Retraining: Initiated based on major business events (e.g., new product launches).\n\nWhy It Matters?\n\nEnsures models remain adaptive to new data patterns.\nReduces manual intervention in model maintenance.\nProvides a structured way to validate and replace models safely.\n\nExample:\nA financial forecasting model detects a sudden spike in stock market volatility. A retraining trigger is activated, updating the model with the latest market data to prevent outdated predictions.\n\n\n\nA comprehensive model monitoring framework tracks data quality, model performance, drift, and operational stability to ensure models remain reliable in production. Without proper monitoring, businesses risk deploying models that degrade silently, leading to poor decisions and lost revenue.\n\n\n\n\n\n\nCollaboration in Model Monitoring\n\n\n\n\n\nWhile understanding model monitoring is crucial for ML practitioners, not all components need to be built from scratch. Many organizations already have observability tools and monitoring infrastructure in place for API health, system performance, and automated alerting. Data scientists and ML engineers often work collaboratively with DevOps, IT, and software engineering teams to integrate ML-specific monitoring into existing platforms.\nThe key takeaway? As a data scientist or ML engineer, you should understand what needs to be monitored and how to interpret issues, but implementation may involve leveraging existing tools and working closely with platform engineers.\n\n\n\nIn the next section, we will explore the tools and frameworks available to implement these monitoring components efficiently.",
    "crumbs": [
      "ModelOps",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Model Monitoring</span>"
    ]
  },
  {
    "objectID": "09-modelops-monitoring.html#tools-for-model-monitoring",
    "href": "09-modelops-monitoring.html#tools-for-model-monitoring",
    "title": "9  Model Monitoring",
    "section": "9.3 Tools for Model Monitoring",
    "text": "9.3 Tools for Model Monitoring\nSelecting the right tools for monitoring machine learning models depends on the specific monitoring needs, infrastructure, and scalability requirements of your organization. There is a growing ecosystem of open-source and cloud-based tools designed to track model performance, detect drift, and ensure reliability in production environments. Additionally, traditional Application Performance Monitoring (APM) tools play a critical role in operational monitoring to ensure API uptime and infrastructure stability.\nBelow, we explore some of the key tools across different categories.\n\n\n\n\n\n\nA Rapidly Evolving Landscape\n\n\n\n\n\nModel monitoring is a rapidly growing area within MLOps, with new tools and frameworks constantly emerging. Keeping up with all available tools can be overwhelming, but that shouldn’t be the primary focus. Instead of trying to learn every tool, data scientists and ML engineers should focus on understanding the core principles of model monitoring—tracking model performance, detecting drift, ensuring operational stability, and automating alerts. Once these fundamentals are clear, selecting the right tool becomes much easier, as the choice will be driven by the specific needs of the model and deployment environment.\n\n\n\n\nOpen-Source Monitoring Tools\nOpen-source tools provide flexible, customizable solutions for monitoring models without vendor lock-in. They are particularly useful and popular for detecting drift, tracking model performance over time, and ensuring model explainability.\n\n\n\n\n\n\nEvidently AI\n\n\n\n\n\nEvidently AI is an open-source tool designed for monitoring data and concept drift, as well as tracking model performance over time. It also provides a set of prebuilt reports that visualize key monitoring metrics.\n\nKey Features:\n\nPrebuilt dashboards for monitoring feature drift and prediction distributions.\nStatistical tests to flag significant data changes over time.\nIntegrates with Jupyter Notebooks, Airflow, and other pipelines.\n\nWhen to Use: If you need lightweight, flexible monitoring integrated into existing ML workflows.\nAdvantages:\n\nSupports both batch and real-time monitoring.\nEasy-to-use dashboard for quick insights.\nWorks well with Jupyter notebooks for exploratory analysis.\n\nDisadvantages:\n\nRequires manual setup and integration into ML pipelines.\nMay not scale well for large enterprise use cases without additional infrastructure.\n\n🔗 Evidently AI Documentation\n\n\n\n\n\n\n\n\n\n\nWhyLabs\n\n\n\n\n\nWhyLabs is a scalable ML monitoring solution that provides anomaly detection for models in production. It integrates with tools like Evidently AI for enhanced drift detection.\n\nKey Features:\n\nAI-powered drift detection and explainability insights.\nAutomated alerts when model performance deteriorates.\nPrivacy-friendly data logging without sending raw data.\n\nWhen to Use: If you need a scalable, cloud-native monitoring tool that integrates well with production systems.\nAdvantages:\n\nUses AI-driven anomaly detection to proactively flag potential issues.\nScales well for large datasets and high-throughput models.\nProvides automated root cause analysis to explain model failures.\n\nDisadvantages:\n\nThe open-source version (WhyLogs) requires additional engineering effort for full automation.\nThe cloud-based version (WhyLabs) involves additional costs for enterprise-grade monitoring.\n\n🔗 WhyLabs Documentation\n\n\n\n\n\n\n\n\n\n\nFiddler AI\n\n\n\n\n\nFiddler AI is designed for explainability, bias detection, and monitoring ML models in production. It allows teams to understand model decisions, identify biases, and track drift over time.\n\nKey Features:\n\nAdvanced feature attribution and interpretability methods.\nBias detection to ensure fairness in model predictions.\nReal-time monitoring and debugging capabilities.\n\nWhen to Use: If your organization requires model transparency and bias detection as part of compliance.\nAdvantages:\n\nProvides interpretable explanations for ML predictions.\nStrong emphasis on ethical AI and bias detection.\nSupports continuous monitoring and alerts for model degradation.\n\nDisadvantages:\n\nPrimarily targeted at organizations concerned with model interpretability and fairness rather than general performance monitoring.\nMore complex setup compared to simpler monitoring tools.\n\n🔗 Fiddler AI Documentation\n\n\n\n\n\n\n\n\n\n\nArize AI\n\n\n\n\n\nArize AI is an ML observability platform that offers real-time performance tracking, drift detection, and bias identification. It supports both structured and unstructured data, making it useful for diverse ML applications.\n\nKey Features:\n\nDrift detection for input data and predictions.\nPerformance tracking across multiple versions of a model.\nHeatmaps and visualization tools for debugging model failures.\n\nWhen to Use: If you need real-time performance monitoring and AI observability across multiple ML models.\nAdvantages:\n\nProvides a comprehensive monitoring dashboard with intuitive visualizations.\nSupports real-time model monitoring for immediate issue detection.\nStrong integration with popular ML frameworks like TensorFlow and PyTorch.\n\nDisadvantages:\n\nRequires ingestion of model logs into Arize’s system, adding an additional dependency.\nMay not be as customizable as self-hosted solutions like Evidently AI.\n\n🔗 Arize AI Documentation\n\n\n\n\n\n\nCloud-Based Monitoring Solutions\nFor organizations using cloud-based ML platforms, built-in monitoring tools provide seamless integration with cloud storage, deployment pipelines, and model registries.\n\n\n\n\n\n\nAWS SageMaker Model Monitor\n\n\n\n\n\nSageMaker Model Monitor allows users to track and detect drift, bias, and model degradation in AWS-based ML deployments. It integrates with SageMaker endpoints and automatically logs key metrics.\n\nKey Features:\n\nDetects data drift, bias, and performance degradation.\nAutomated logging and alerts via AWS CloudWatch.\nNative integration with S3, Lambda, and SageMaker Pipelines.\n\nWhen to Use: If your models are deployed in AWS SageMaker and require fully managed monitoring.\nAdvantages:\n\nFully integrated into the AWS ecosystem, making deployment seamless for AWS users.\nProvides automated alerts based on pre-configured thresholds.\nSupports integration with CloudWatch for centralized logging.\n\nDisadvantages:\n\nLimited flexibility if the model is not deployed on AWS.\nCost can increase significantly with high-frequency monitoring.\n\n🔗 AWS SageMaker Model Monitor\n\n\n\n\n\n\n\n\n\n\nGoogle Vertex AI Model Monitoring\n\n\n\n\n\nGoogle’s Vertex AI Model Monitoring provides automated drift detection, performance tracking, and alerting for models deployed on Google Cloud.\n\nKey Features:\n\nMonitors feature drift and prediction distributions.\nTriggers alerts when data distributions shift.\nIntegrates with BigQuery, Cloud Logging, and AI Notebooks.\n\nWhen to Use: If your models are deployed in Google Cloud Vertex AI.\nAdvantages:\n\nOffers built-in drift detection with statistical monitoring tools.\nStrong integration with BigQuery and Google’s data ecosystem.\nCan be easily configured with AutoML and custom ML models.\n\nDisadvantages:\n\nLess flexibility for non-GCP deployments.\nMight not support as many model frameworks compared to other solutions.\n\n🔗 Google Vertex AI Model Monitoring\n\n\n\n\n\n\n\n\n\n\nAzure ML Monitoring\n\n\n\n\n\nAzure ML Monitoring is a cloud-native monitoring service that helps teams track model performance and data drift for models deployed within Azure Machine Learning.\n\nKey Features:\n\nTracks model accuracy, feature drift, and prediction consistency.\nConnects with Azure Event Grid for automated alerts.\nVisual dashboards in Azure ML Studio.\n\nWhen to Use: If you use Azure ML and need native model monitoring.\nAdvantages:\n\nProvides integration with Azure’s suite of tools, such as Power BI and Data Factory.\nSupports real-time model performance tracking and alerting.\nCan automate model retraining based on monitoring triggers.\n\nDisadvantages:\n\nBest suited for teams already using Azure’s ML infrastructure.\nCan become costly for large-scale monitoring needs.\n\n🔗 Azure ML Monitoring\n\n\n\n\n\n\nLogging & APM Tools (For Operational Monitoring)\nOperational monitoring focuses on infrastructure, API uptime, latency, and system performance. While these tools do not track ML-specific metrics, they are essential for ensuring the stability and reliability of ML services.\n\n\n\n\n\n\nPrometheus & Grafana\n\n\n\n\n\nPrometheus is an open-source monitoring system that collects real-time metrics, while Grafana is used for visualization. Together, they provide powerful infrastructure monitoring capabilities.\n\nKey Features:\n\nPrometheus collects time-series metrics from deployed services.\nGrafana provides visual dashboards and alerts.\nCan monitor CPU, memory, and response times of ML APIs.\n\nWhen to Use: If you need customized, self-hosted monitoring for ML deployments.\nAdvantages:\n\nWidely used for monitoring API uptime, latency, and resource usage.\nHighly customizable and works with Kubernetes-based deployments.\nOpen-source with strong community support.\n\nDisadvantages:\n\nRequires engineering expertise to set up and maintain.\nLacks built-in ML-specific monitoring capabilities.\n\n🔗 Prometheus | Grafana\n\n\n\n\n\n\n\n\n\n\nDatadog & New Relic\n\n\n\n\n\nDatadog and New Relic are cloud-based APM (Application Performance Monitoring) solutions that track API performance, latency, and system health.\n\nKey Features:\n\nAutomated anomaly detection for infrastructure metrics.\nDistributed tracing to track API response times.\nIntegrates with AWS, GCP, and Kubernetes.\n\nWhen to Use: If you need enterprise-grade monitoring for cloud-based ML applications.\nAdvantages:\n\nEasy to set up and integrate with cloud services.\nProvides real-time dashboards and automated alerts.\nSupports distributed tracing to diagnose model serving issues.\n\nDisadvantages:\n\nMore focused on infrastructure monitoring than ML-specific issues like drift detection.\nCan be expensive for high-volume logging and monitoring.\n\n🔗 Datadog | New Relic\n\n\n\n\nSelecting the right monitoring tool depends on your model deployment environment, monitoring needs, and infrastructure. In many organizations, a combination of ML monitoring tools (e.g., Evidently AI, SageMaker Model Monitor) and APM tools (e.g., Prometheus, Datadog) is used to provide comprehensive observability.\n\n\n\n\n\n\n\n\nTool Category\nBest For\nExample Tools\n\n\n\n\nOpen-Source Model Monitoring\nCustomizable, lightweight ML monitoring\nEvidently AI, WhyLabs, Fiddler AI, Arize AI\n\n\nCloud-Native Model Monitoring\nFully managed monitoring for cloud ML platforms\nAWS SageMaker Model Monitor, Google Vertex AI Model Monitoring, Azure ML Monitoring\n\n\nOperational Monitoring\nInfrastructure, API latency, and uptime tracking\nPrometheus, Grafana, Datadog, New Relic\n\n\n\nIn the next section, we will implement a hands-on example to help demonstrate how to set up model monitoring in practice.",
    "crumbs": [
      "ModelOps",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Model Monitoring</span>"
    ]
  },
  {
    "objectID": "09-modelops-monitoring.html#hands-on-example-implementing-model-monitoring",
    "href": "09-modelops-monitoring.html#hands-on-example-implementing-model-monitoring",
    "title": "9  Model Monitoring",
    "section": "9.4 Hands-On Example: Implementing Model Monitoring",
    "text": "9.4 Hands-On Example: Implementing Model Monitoring\nIn the previous chapter, we deployed a machine learning model as an API using FastAPI. However, deploying a model is only part of the journey, ensuring it continues to perform well over time is equally critical. In this hands-on example, we will extend our deployed model by incorporating monitoring capabilities, allowing us to track performance, detect drift, and ensure operational stability.\nThis exercise will introduce you to practical model monitoring techniques, demonstrating how to:\n\nLog incoming data and predictions to track model performance in production.\nDetect data drift using Evidently, which helps determine if incoming data distributions are changing over time.\nMonitor API performance (latency, request counts, and errors) using Prometheus and visualize it in Grafana.\nAutomate monitoring and alerts to proactively identify issues before they impact business decisions.\n\n\nWhy is This Important?\nIn real-world applications, an ML model that performs well during training may degrade over time due to shifting data patterns (data drift), changes in the relationship between inputs and outputs (concept drift), or due to changes in API performance (i.e. latency). Without proper monitoring, these changes can go unnoticed, leading to poor predictions, financial losses, or operational disruptions.\nFor instance, in our apple demand forecasting model, what if consumer behavior changes due to a sudden price increase, or a competitor introduces a promotional campaign, or maybe a hot new apple martini recipe is trending on social media and all of a sudden demand has exceeded any amounts we’ve seen previously? If our model does not adapt to these changes, inventory predictions may become inaccurate, leading to overstocking or shortages. Monitoring allows us to detect such changes early and trigger necessary actions, such as model retraining or adjusting forecasting strategies.\nThis section will demonstrate how to incorporate fundamental monitoring so that by the end of this chapter, you will have a well-monitored ML model that logs incoming data, detects drift, tracks API performance, and provides real-time insights through dashboards and alerts. This will help ensure your deployed model remains reliable and accurate over time.\n\n\nPrerequisites\nBefore proceeding, make sure you have the following:\n\nWe’ll be building onto the previous hands-on examples where the apple demand forecasting model was trained, logged and versioned to MLflow and then predictions were served with a FastAPI. If you want to recreate this section then be sure have successfully reproduced Section 6.7, Section 7.4, and Section 8.4.\nYou’ll also need the following packages installed.1\n\nevidently==0.6.1\nWith these prerequisites met, let’s move on to setting up the monitoring infrastructure!\n\n\nSetting Up the Monitoring Infrastructure\nThe first step is to implement a logging mechanism to capture all incoming prediction requests and their corresponding outputs. This will allow us to:\n\nTrack model behavior over time.\nDetect potential data drift and concept drift.\nIdentify issues in the model’s performance before they impact business decisions.\n\nThis is the first step toward building a fully automated monitoring system.\n\n\n\n\n\n\nIn a real-world enterprise system, logged data would typically be stored in a centralized logging database (i.e. PostgreSQL, MySQL, NoSQL) or a cloud-based storage system (i.e. BigQuery, AWS S3). However, for this hands-on example, we will log predictions locally to a CSV file.\n\n\n\nTo implement logging, we will modify our FastAPI application to:\n\nLog incoming requests (input features) and corresponding predictions.\nStore logs in a CSV file (prediction_logs.csv).\nInclude timestamps and status messages for error tracking.\n\nThe primary code that we will add includes:\n# Define log file path\nLOG_FILE_PATH = \"prediction_logs.csv\"\n\n# Ensure log file exists with headers\nif not os.path.exists(LOG_FILE_PATH):\n    pd.DataFrame(columns=[\n        \"timestamp\", \"request_type\", \"input_data\", \"predictions\", \"status\"\n    ]).to_csv(LOG_FILE_PATH, index=False)\n\n# Primary function to log inputs & predictions\ndef log_request(request_type, input_data, predictions, status):\n    \"\"\"Logs the request details to a CSV file.\"\"\"\n    log_entry = pd.DataFrame([{\n        \"timestamp\": datetime.datetime.now().isoformat(),\n        \"request_type\": request_type,\n        \"input_data\": json.dumps(input_data),\n        \"predictions\": json.dumps(predictions),\n        \"status\": status\n    }])\n    log_entry.to_csv(LOG_FILE_PATH, mode='a', header=False, index=False)\nWe can then add a call to the log_request() function inside the function definitions for predict_single() and predict_batch(). You can see the full revised FastAPI code below or also here.\n\n\n\n\n\n\nRevised FastAPI code\n\n\n\n\n\nfrom fastapi import FastAPI, HTTPException, UploadFile, File\nimport mlflow.pyfunc\nimport pandas as pd\nfrom pydantic import BaseModel\nfrom typing import List\nimport io\nimport datetime\nimport json\nimport os\n\n# Initialize FastAPI app\napp = FastAPI()\n\n# Set experiment name\nmlflow.set_experiment(\"Forecasting Apple Demand\")\n\n# Load the trained model from MLflow\nMODEL_URI = \"models:/apple_demand@champion\"  # Replace with your model name and alias\nmodel = mlflow.pyfunc.load_model(MODEL_URI)\n\n# Define the expected input schema for a single prediction\nclass InputData(BaseModel):\n    average_temperature: float\n    rainfall: float\n    weekend: int\n    holiday: int\n    price_per_kg: float\n    promo: int\n    previous_days_demand: float\n\n# Define log file path\nLOG_FILE_PATH = \"prediction_logs.csv\"\n\n# Ensure log file exists with headers\nif not os.path.exists(LOG_FILE_PATH):\n    pd.DataFrame(columns=[\n        \"timestamp\", \"request_type\", \"input_data\", \"predictions\", \"status\"\n    ]).to_csv(LOG_FILE_PATH, index=False)\n\ndef log_request(request_type, input_data, predictions, status):\n    \"\"\"Logs the request details to a CSV file.\"\"\"\n    log_entry = pd.DataFrame([{\n        \"timestamp\": datetime.datetime.now().isoformat(),\n        \"request_type\": request_type,\n        \"input_data\": json.dumps(input_data),\n        \"predictions\": json.dumps(predictions),\n        \"status\": status\n    }])\n    log_entry.to_csv(LOG_FILE_PATH, mode='a', header=False, index=False)\n\n@app.post(\"/predict\")\ndef predict_single(input_data: List[InputData]):\n    \"\"\"Endpoint for real-time predictions with a single input.\"\"\"\n    try:\n        # Convert input to DataFrame\n        df = pd.DataFrame([data.dict() for data in input_data])\n\n        # Make predictions\n        predictions = model.predict(df)\n\n        # Log the request\n        log_request(\"single\", df.to_dict(orient=\"records\"), predictions.tolist(), \"success\")\n\n        return {\"predictions\": predictions.tolist()}\n    except Exception as e:\n        log_request(\"single\", df.to_dict(orient=\"records\"), None, f\"error: {str(e)}\")\n        raise HTTPException(status_code=500, detail=str(e))\n\n@app.post(\"/predict_batch\")\nasync def predict_batch(file: UploadFile = File(...)):\n    \"\"\"Endpoint for batch predictions using a CSV file.\"\"\"\n    try:\n        # Read the uploaded CSV file\n        contents = await file.read()\n        df = pd.read_csv(io.StringIO(contents.decode(\"utf-8\")))\n\n        # Validate required columns\n        required_features = [\"average_temperature\", \"rainfall\", \"weekend\", \"holiday\", \"price_per_kg\", \"promo\", \"previous_days_demand\"]\n        if not all(feature in df.columns for feature in required_features):\n            missing_cols = set(required_features) - set(df.columns)\n            raise HTTPException(status_code=400, detail=f\"Missing columns: {missing_cols}\")\n\n        # Make batch predictions\n        predictions = model.predict(df)\n\n        # Log the request\n        log_request(\"batch\", df.to_dict(orient=\"records\"), predictions.tolist(), \"success\")\n\n        return {\"predictions\": predictions.tolist()}\n    except Exception as e:\n        log_request(\"batch\", df.to_dict(orient=\"records\"), None, f\"error: {str(e)}\")\n        raise HTTPException(status_code=500, detail=str(e))\n\n\n\nOnce the FastAPI code is modified, we can can test it by running the FastAPI app (either directly or by running with Streamlit as discussed in Section 8.4.4.3). Go ahead and make some predictions and you’ll notice a prediction_logs.csv is created in your directory that will resemble the following, which includes the timestamp of the prediction, the type of request (single vs. batch), the input data fed into the model, the prediction the model made, and even the error message if an issue occurred.\nExample of Logged Data:\n\n\n\n\n\n\n\n\n\n\nTimestamp\nRequest Type\nInput Data\nPredictions\nStatus\n\n\n\n\n2025-02-01T14:12:00Z\nSingle\n{“temp”: 30, “rainfall”: 2.1, …, “promo”: 1}\n1250.4\nSuccess\n\n\n2025-02-01T14:15:12Z\nBatch\n[{“temp”: 28, “rainfall”: 1.8, …}, {“temp”: 27, “rainfall”: 2.5, …}]\n[1185.2, 1200.8]\nSuccess\n\n\n2025-02-01T14:20:30Z\nSingle\n{“temp”: 35, “rainfall”: 3.0, “promo”: 0}\nNone\nError: Missing feature\n\n\n\nNow that we are storing historical inputs and predictions, we can move forward to drift detection — analyzing whether our model is still making accurate predictions or if data patterns have changed significantly.\n\n\nMonitoring Model Performance with Evidently AI\nAs machine learning models operate in real-world environments, they face evolving data distributions, shifting relationships between features and target variables, and potential degradation in predictive performance. Evidently AI is an open-source tool designed to help teams monitor, diagnose, and address these changes through drift detection and performance monitoring.\n\nExamples of Implementing Evidently\nThis section provides an overview of how to use Evidently AI to track feature drift, concept drift, and model performance drift, ensuring our apple demand forecasting model remains accurate and reliable.2 Below, we demonstrate how to generate Evidently AI reports to assess different types of drift using artificially generated datasets.\n\n\n\n\n\n\nDetecting Feature Drift\n\n\n\n\n\nFeature drift occurs when the distribution of input features changes significantly from the training data, potentially making the model’s learned patterns obsolete. This could be due to seasonal trends, economic shifts, or data collection changes.\nThe code below provides an example of using Evidently for feature drift analysis. Using the apple_data.py module, we generate:\n\nA baseline dataset representing normal, expected conditions. This would typically be the original dataset your current model in production was trained on.\nA drifted dataset, where key features such as temperature, rainfall, and pricing have shifted.\n\n\n\nfrom apple_data import generate_apple_sales_data_with_promo_adjustment\n\n# Generate baseline dataset (no drift)\nbaseline_df = generate_apple_sales_data_with_promo_adjustment(\n    n_rows=5000\n)\n\n# Generate drifted dataset with controlled drift factors\nfeature_drift_config = {\n    \"average_temperature\": 1.2,  # 20% increase\n    \"rainfall\": 0.9,             # 10% decrease\n    \"price_per_kg\": 1.09,        # 9% increase\n    \"promo\": 1.5                 # 50% more promotions\n}\n\nconcept_drift_config = {\n    \"price_sensitivity\": 0.8,  # 20% less sensitive to price changes\n    \"promo_effect\": 0.7,       # Promotions become 30% less effective\n    \"weekend_effect\": 1.1,     # Weekend demand slightly increases\n    \"feature_importance\": True\n}\n\ndrifted_df = generate_apple_sales_data_with_promo_adjustment(\n    n_rows=5000,\n    feature_drift_factors=feature_drift_config,\n    concept_drift_factors=concept_drift_config\n)\n\n\nWe can then use Evidently AI’s DataDriftPreset to analyze the distribution changes across features and then save the results to a data_drift_report.html file:\n\n\nfrom evidently.report import Report\nfrom evidently.metric_preset import DataDriftPreset\n\n# Define the drift detection report\ndata_drift_report = Report(metrics=[DataDriftPreset(drift_share=0.3)])\n\n# Run comparison\ndata_drift_report.run(reference_data=baseline_df, current_data=drifted_df)\n\n# Save the report\ndata_drift_report.save_html(\"data_drift_report.html\")\n\n\nThis will create a Feature Drift Report (data_drift_report.html) that provides a side-by-side comparison of the feature distributions in the baseline dataset (reference data) and the drifted dataset (current data).\n\n\n\n\n\n\nFeature Drift Report\n\n\n\n\nFigure 9.4: Snapshot of the feature drift report.\n\n\n\nThe key components of this report include:\n\nFeature Distribution Comparisons: Visual histograms and statistical tests (e.g., Kolmogorov-Smirnov, Jensen-Shannon) to highlight significant shifts in individual feature distributions.\nDrift Detection Summary: A table listing all monitored features, their calculated drift scores, and whether the drift is deemed significant.\nOverall Data Drift Score: A single metric summarizing how much the dataset has changed, indicating whether the current dataset is still representative of the training data.\n\n\n\n\n\n\n\nBy default, Evidently will use 50% of the feature columns as the cutoff to determine if there is enough overall drift to want concern; however, you can set that as we did in the code with drift_share=0.3. This is a cutoff that you and your team needs to determine what amount of drift warrants concern. If this threshold is breached, it suggests that the model may be making predictions on a data distribution it was not trained on, increasing the risk of inaccurate forecasts.\n\n\n\n\n\n\n\n\n\n\n\n\nDetecting Concept Drift (Target Variable Drift)\n\n\n\n\n\nConcept drift occurs when the relationship between input features and the target variable (e.g., demand) changes. Even if the feature distributions remain stable, the way they impact predictions may shift.\nTo detect whether the target variable has changed, we can use Evidently AI’s TargetDriftPreset() to analyze drift in the target variable (y). This will evaluate both changes in its distribution and shifts in its relationship with feature variables.\nFirst, it compares the statistical distribution of the target variable in the baseline dataset (training data) to the current dataset (recent predictions), using statistical tests such as the Kolmogorov-Smirnov test or Jensen-Shannon divergence. If the target’s distribution has significantly changed, this indicates target drift, meaning the model’s assumptions about the outcome variable may no longer hold.\nAdditionally, TargetDriftPreset() assesses the correlation between the target and input features — if the strength or direction of relationships between features and the target shifts significantly, this suggests concept drift. For instance, if price_per_kg was previously a strong predictor of demand but has become less relevant in the new data, it may indicate a fundamental change in consumer behavior, requiring model retraining or adaptation.\nThe following code implements TargetDriftPreset() and then saves the results to a concept_drift_report.html file:\n\n\nfrom evidently.metric_preset import TargetDriftPreset\nfrom evidently import ColumnMapping\n\n\n# Define the target variable and date variable\ncolumn_mapping = ColumnMapping()\ncolumn_mapping.target = 'demand'\ncolumn_mapping.datetime = 'date'\n\n# Create an Evidently AI report for concept drift detection\nconcept_drift_report = Report(metrics=[TargetDriftPreset()])\n\n# Run the report specifying the target variable\nconcept_drift_report.run(\n    reference_data=baseline_df,\n    current_data=drifted_df,\n    column_mapping=column_mapping  # Explicitly map the target variable\n)\n\n# Save and view the report\nconcept_drift_report.save_html(\"concept_drift_report.html\")\n\n\nThis will create a Feature Drift Report (concept_drift_report.html) that includes:\n\nTarget Variable Distribution Analysis: Visual and statistical comparisons of how the target variable (apple demand) behaves in the baseline dataset vs. the drifted dataset.\nCorrelation Shift Analysis: If configured, the report can highlight whether the relationship between features and the target variable has changed.\nConcept Drift Detection: A statistical test that determines whether the demand predictions based on old patterns are still valid in the current dataset.\n\n\n\n\n\n\n\nConcept Drift Report\n\n\n\n\nFigure 9.5: Snapshot of the concept drift report.\n\n\n\n\n\n\n\n\n\n\n\n\nDetecting Model Performance Drift\n\n\n\n\n\nEven if input features and target values remain stable, a model can degrade due to changes in underlying data relationships, outdated assumptions, or external factors. Tracking model performance over time helps detect these issues.\nEvidently AI provides the RegressionPreset() and ClassificationPreset() metrics to track and evaluate model performance drift over time. These presets help monitor whether a model’s predictions remain accurate and reliable as new data flows in.\n\nThe RegressionPreset() is designed for continuous target variables (e.g., sales forecasts) and evaluates metrics like RMSE, MAE, R², and residual analysis to detect shifts in prediction errors. If RMSE increases significantly compared to the reference dataset, it may indicate that the model is underperforming due to data drift or concept drift.\nSimilarly, ClassificationPreset() is tailored for classification tasks and tracks key metrics such as accuracy, precision, recall, F1-score, and ROC-AUC. It flags performance degradation if there’s a drop in classification confidence or an increase in misclassification rates.\n\nThe following code implements RegressionPreset() and then saves the results to a performance_report.html file:\n\n\nfrom evidently.metric_preset import RegressionPreset\nimport mlflow\n\n\n# Load current model\nmlflow.set_experiment(\"Forecasting Apple Demand\")\nMODEL_URI = \"models:/apple_demand@champion\"\nmodel = mlflow.pyfunc.load_model(MODEL_URI)\n\n# Score baseline & drift data with model\nbaseline_df['predictions'] = model.predict(drifted_df)\ndrifted_df['predictions'] = model.predict(drifted_df)\n\n# Add the prediction variable to our column mapping to compare to actuals\ncolumn_mapping.prediction = 'predictions'\n\n# Create a model performance monitoring report\nperformance_report = Report(metrics=[RegressionPreset()])\nperformance_report.run(\n    reference_data=baseline_df,\n    current_data=drifted_df,\n    column_mapping=column_mapping  # Explicitly map the target variable\n)\n\n# Save report\nperformance_report.save_html(\"performance_report.html\")\n\n\nThe Model Performance Drift Report provides:\n\nPerformance Metrics Comparison: Side-by-side evaluation of model accuracy, highlighting whether predictive performance has worsened on new data.\nResidual Analysis: Visual plots showing whether model errors have increased significantly in specific regions of the data.\nFeature Importance Changes (if enabled): A comparison of how feature importance scores have shifted, indicating whether the model is relying on different patterns than before.\n\n\n\n\n\n\n\nPerformance Drift Report\n\n\n\n\nFigure 9.6: Snapshot of the model performance drift report.\n\n\n\n\n\n\n\n\n\nBy using these presets, teams can proactively identify when a model’s predictions start deviating, allowing them to trigger alerts, diagnose potential drift, and determine whether retraining is necessary to maintain high model accuracy in production.\n\n\n\n\n\n\nEvidently AI offers a robust framework for detecting and visualizing drift in machine learning models. While the examples provided here demonstrate the basics of monitoring feature drift, target drift, and model performance drift, Evidently includes many additional capabilities, such as bias detection, data integrity checks, and customizable dashboards for ongoing model monitoring. These advanced features can provide deeper insights into why a model’s performance is changing over time. In the next section, we will take these concepts further by integrating Evidently AI into our production pipeline, demonstrating how to automate drift detection and implement real-time model monitoring. Along the way, we will also introduce additional functionalities that Evidently provides, reinforcing its role in maintaining reliable and high-performing ML systems in production.\n\n\nImplementing Evidently into Our Pipeline\nTBD\n\n\nVisualizing Model Monitoring in Streamlit\nTBD\n\n\nAutomating the Monitoring Pipeline\nTBD\n\n\n\nSetting Up Operational Monitoring with Prometheus and Grafana\n\nA. Introduction to Prometheus and Grafana\n\nWhy These Tools?\n\nPrometheus: Captures API request latency, response times, and error rates.\nGrafana: Visualizes the collected data with dashboards.\n\n\n\n\nB. Configuring Prometheus to Track API Performance\n\nImplementation:\n\nExpose FastAPI metrics using Prometheus FastAPI Instrumentator.\nConfigure Prometheus to scrape metrics from the API.\nTrack response time, request count, and error rates.\n\n\n\n\nC. Setting Up a Grafana Dashboard\n\nImplementation:\n\nConnect Prometheus as a data source in Grafana.\nBuild a dashboard to visualize API performance.\nConfigure alerts for high latency or errors.\n\n\n\n\n\nAutomating Monitoring & Alerts\n\nA. Scheduling Drift Checks\n\nImplementation:\n\nUse a cron job or scheduler to run drift checks periodically.\nStore results and generate alerts if drift is detected.\n\n\n\n\nB. Setting Up Alerting with Prometheus & Grafana\n\nImplementation:\n\nDefine alert rules in Prometheus for API performance issues.\nSend notifications via email, Slack, or webhooks when issues arise.\n\n\n\n\n\nReflection & Next Steps\n\nWhat We Achieved:\n\nImplemented logging and drift detection.\nMonitored API health and set up dashboards.\nConfigured alerts for early issue detection.\n\nChallenges & Considerations:\n\nHandling large-scale monitoring data efficiently.\nDetermining the right drift detection thresholds.\n\nWhat’s Next?:\n\nFuture chapters will explore model retraining strategies and automation.",
    "crumbs": [
      "ModelOps",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Model Monitoring</span>"
    ]
  },
  {
    "objectID": "09-modelops-monitoring.html#summary",
    "href": "09-modelops-monitoring.html#summary",
    "title": "9  Model Monitoring",
    "section": "9.5 Summary",
    "text": "9.5 Summary\n\nImportance of Continuous Monitoring: Ensuring long-term reliability of ML models.\nTypes of Monitoring: Performance, data drift, concept drift, operational.\nKey Components: Logging, metrics, drift detection, alerting, retraining.\nTools: Open-source, cloud-native, and APM solutions.\nNext Steps: The following chapters will discuss how to integrate monitoring with automated ML workflows.",
    "crumbs": [
      "ModelOps",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Model Monitoring</span>"
    ]
  },
  {
    "objectID": "09-modelops-monitoring.html#exercise",
    "href": "09-modelops-monitoring.html#exercise",
    "title": "9  Model Monitoring",
    "section": "9.6 Exercise",
    "text": "9.6 Exercise\n\nConceptual Design:\n\nIdentify key performance metrics and drift detection methods for monitoring a real-world ML system.\n\nHands-On Task:\n\nUsing Evidently AI, monitor a sample dataset for data drift.\nSimulate incoming requests and track performance over time.\nSet up an alerting mechanism for degraded model performance.\n\nReflection on Monitoring Challenges:\n\nWhat challenges might arise in deploying a real-world monitoring system?\nHow do design principles from Chapter 1 apply to model monitoring?",
    "crumbs": [
      "ModelOps",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Model Monitoring</span>"
    ]
  },
  {
    "objectID": "09-modelops-monitoring.html#footnotes",
    "href": "09-modelops-monitoring.html#footnotes",
    "title": "9  Model Monitoring",
    "section": "",
    "text": "See the modelops-monitoring-requirements.txt file.↩︎\nYou can also refer to this notebook: https://github.com/bradleyboehmke/uc-bana-7075/blob/main/ModelOps/model-drift-monitoring.ipynb↩︎",
    "crumbs": [
      "ModelOps",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Model Monitoring</span>"
    ]
  },
  {
    "objectID": "10-devops-role.html",
    "href": "10-devops-role.html",
    "title": "10  The Role of DevOps",
    "section": "",
    "text": "10.1 Why DevOps Matters for ML Systems\nDevOps is a software development methodology that emphasizes the integration of development (Dev) and operations (Ops) teams to improve the efficiency, speed, and reliability of software delivery. It emerged in response to the traditional siloed approach, where developers focused solely on writing code while operations teams were responsible for deployment, monitoring, and maintenance. This separation often led to bottlenecks, slow deployment cycles, and inefficient incident resolution.\nThe goal of DevOps is to streamline the software development lifecycle through automation, collaboration, and continuous feedback loops. It leverages practices such as continuous integration/continuous deployment (CI/CD), infrastructure as code (IaC), automated testing, and monitoring to ensure rapid and reliable software releases.\nIn the previous chapters, we explored how to build data pipelines, track and version datasets and models, and deploy and monitor models in simple scenarios. However, the role of DevOps is to simplify, standardize, automate, and scale these processes across an entire organization, ensuring robustness and efficiency at every stage.\nWhile DevOps has been widely adopted in traditional software engineering, its application to ML systems is still evolving. ML workflows introduce additional complexities beyond traditional software development, as they involve code, data, and models, each requiring careful versioning, validation, and deployment strategies.",
    "crumbs": [
      "DevOps",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>The Role of DevOps</span>"
    ]
  },
  {
    "objectID": "10-devops-role.html#why-devops-matters-for-ml-systems",
    "href": "10-devops-role.html#why-devops-matters-for-ml-systems",
    "title": "10  The Role of DevOps",
    "section": "",
    "text": "Automating Workflows\n\n\n\n\n\nMany ML workflows involve manual steps in data preprocessing, model training, and deployment, leading to inefficiencies and errors. DevOps principles help automate these steps, reducing human intervention and increasing reproducibility.\n\n\n\n\n\n\n\n\n\nEnhancing Reliability and Stability\n\n\n\n\n\nDeploying ML models in production requires more than just wrapping a model in an API. It involves integrating the model into existing infrastructure, implementing automated monitoring to track performance, ensuring uptime, and managing rollback mechanisms and scalable infrastructure.\n\n\n\n\n\n\n\n\n\nAccelerating Experimentation and Deployment\n\n\n\n\n\nThe ability to quickly iterate on models, test changes, and deploy updates is crucial for ML teams. CI/CD pipelines designed for ML enable teams to push models into production efficiently without compromising stability.\n\n\n\n\n\n\n\n\n\nBridging the Gap Between ML and Production Systems\n\n\n\n\n\nMany ML projects struggle to transition from proof-of-concept to production due to operational challenges. DevOps provides structured and standardized deployment processes, ensuring that models are not only trained but also continuously monitored and updated as needed.",
    "crumbs": [
      "DevOps",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>The Role of DevOps</span>"
    ]
  },
  {
    "objectID": "10-devops-role.html#the-value-of-devops-in-ml-systems",
    "href": "10-devops-role.html#the-value-of-devops-in-ml-systems",
    "title": "10  The Role of DevOps",
    "section": "10.2 The Value of DevOps in ML Systems",
    "text": "10.2 The Value of DevOps in ML Systems\nDevOps plays a crucial role in ensuring that ML systems are not just successfully developed but also efficiently deployed, maintained, and updated in production environments. By leveraging automation, scalability, and streamlined workflows, DevOps principles help data science teams focus on innovation while ensuring model reliability and performance in real-world applications. These principles directly support key ML system design principles such as reproducibility, automation, scalability, and maintainability, which were discussed in Section 1.3.\n\n\n\n\n\n\nAutomating Code & Model Updates\n\n\n\n\n\nAutomation is a core tenet of effective ML system design. One of the most significant challenges in ML workflows is keeping models up to date without causing disruptions. DevOps enables seamless automation of code and model updates through CI/CD pipelines, allowing teams to continuously integrate new data, retrain models, and deploy updated versions with minimal manual intervention. This ensures that models remain relevant and perform optimally as data evolves while maintaining reproducibility and consistency across environments.\n\n\n\n\n\n\n\n\n\nImproving Reliability & Stability\n\n\n\n\n\nEnsuring model reliability aligns with the principle of maintainability in ML system design. ML models in production need to be robust and resilient to changing conditions. DevOps practices such as automated rollback mechanisms, failover strategies, and proactive monitoring help mitigate risks associated with model degradation and system failures. By implementing scalable and flexible model-serving architectures, organizations can ensure high availability and consistent performance, even under fluctuating workloads, supporting the principle of scalability and ensuring system longevity.\n\n\n\n\n\n\n\n\n\nAccelerating Model Deployment & Iteration\n\n\n\n\n\nSpeed and agility in ML development tie directly to the principle of automation and scalability. DevOps facilitates rapid experimentation by streamlining the deployment process. Automated testing and validation frameworks ensure that models meet performance criteria before being pushed to production, reducing the risk of deploying underperforming models. Additionally, DevOps enables consistency across environments, allowing models to be deployed efficiently across cloud, edge, or on-premise infrastructures, ensuring the system remains scalable and adaptable to various operational needs.\n\n\n\nIntegrating DevOps into ML workflows enhances the efficiency, scalability, and reliability of ML systems. By automating workflows, improving reliability, and standardizing deployment processes, organizations can effectively operationalize ML models and derive real business value from their ML investments.",
    "crumbs": [
      "DevOps",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>The Role of DevOps</span>"
    ]
  },
  {
    "objectID": "10-devops-role.html#key-concepts-of-devops-for-ml",
    "href": "10-devops-role.html#key-concepts-of-devops-for-ml",
    "title": "10  The Role of DevOps",
    "section": "10.3 Key Concepts of DevOps for ML",
    "text": "10.3 Key Concepts of DevOps for ML\nUnderstanding how DevOps fits into ML systems requires understanding key concepts that support automation, scalability, and collaboration across teams. These concepts help ensure that ML systems are efficiently trained, tested, deployed, and maintained in production environments.\nTo measure the effectiveness of DevOps in ML systems, organizations rely on four key software delivery metrics1:\n\n\n\n\n\n\n\n\nMetric\nDevOps Definition\nRelation to ML Systems\n\n\n\n\nDeployment Frequency\nHow often does your organization deploy code to production or release it to end-users?\nIn ML systems, the frequency of deployment often depends on:1. Model retraining requirements, which can range from less frequent retraining for batch processes to constant “always on” retraining for online systems. Two aspects are crucial for model retraining (a) New data availability. Preferrably we want to retrain data as soon as new data is available to retrain on. (b) Model decay. Typically we want to retrain a model as soon as we identify a decay in the model performance. 2. The level of automation of the deployment process, which might range between manual deployment and fully automated CI/CD pipeline.\n\n\nLead Time for Changes\nHow long does it take to go from code committed to code successfully running in production?\nThe Lead Time for Changes in an ML system depends on:(1) Duration of the explorative phase in Data Science in order to finalize the ML model for deployment/serving.(2) Duration of the ML model training.(3) The number and duration of manual steps during the deployment process.\n\n\nChange Failure Rate\nWhat percentage of changes to production or released to users result in degraded service (e.g., lead to service impairment or service outage) and subsequently require remediation (e.g., require a hotfix, rollback, fix forward, patch)?\nIn ML systems, Change Failure Rate are often driven by three components of the system: (1) Infrastructure failure: Infrastructure failures contribute to a high change failure rate if new deployments or updates cause system instability, unexpected resource constraints, or networking issues.(2) Model performance: If an ML model deployed in production exhibits performance degradation (e.g., increased error rates, drift, or bias introduction), it may require immediate rollback or remediation.(3) Data pipeline failure: Data pipeline failures can introduce corrupted, missing, or incorrect data, leading to failed model training or degraded predictions in production.\n\n\nMean Time to Recovery (MTTR)\nHow long does it generally take to restore service when a service incident or a defect that impacts users occurs (e.g., unplanned outage or service impairment)?\nIn an ML system Model MTTR depends on the number and duration of manually performed debugging and deployment steps involved in the data pipeline and the model retraining, versioning, deployment, and monitoring pipelines.\n\n\n\nThese metrics serve as benchmarks for improving DevOps practices and ensuring that ML systems are continuously delivering value with high reliability and efficiency. And these metrics are what drive the following key DevOps concepts:\n\n\n\n\n\n\nCI/CD Pipelines for ML Models\n\n\n\n\n\nCI/CD pipelines in ML automate the training, testing, and deployment of models, ensuring reproducibility and consistency across different environments. Unlike traditional software CI/CD, MLOps-specific CI/CD includes additional steps such as data validation, feature engineering, model retraining, and evaluation before deployment.\n\nThese pipelines help streamline workflows across various ML system processes, including:\n\nData Ingestion & Processing: Automating data extraction, transformation, and validation before feeding into model training.\nModel Training & Evaluation: Triggering training jobs when new data is available, followed by validation tests to check for performance regressions or drift.\nModel Deployment & Serving: Ensuring smooth transitions from development to production with robust version control and rollback mechanisms.\nContinuous Monitoring & Feedback Loops: Monitoring performance metrics and triggering model retraining when needed.\n\nImpact on Metrics: By implementing CI/CD, ML teams can increase Deployment Frequency while reducing Lead Time for Changes and Change Failure Rate, leading to a more efficient transition from model development to production.\nCommon Tools: Kubeflow Pipelines, MLflow, TFX, GitHub Actions, GitLab CI/CD, Jenkins\n\n\n\n\n\n\n\n\n\n\nAutomated Testing & Validation\n\n\n\n\n\nAutomated testing and validation are crucial in ensuring the reliability and accuracy of ML models throughout their lifecycle. These processes help detect issues early, prevent performance degradation, and streamline deployment. \n\nWhere it fits in ML systems:\n\nData Validation & Preprocessing: Ensuring that incoming data is consistent with expected formats and distributions.\nFeature Engineering: Verifying transformations and engineered features maintain integrity across training and inference environments.\nModel Training & Evaluation: Running automated checks to compare model versions and detect regression in performance.\nDeployment & Monitoring: Implementing continuous validation to detect drift, bias, or concept changes in production.\n\nTypes of automated testing:\n\nUnit tests for data preprocessing and feature engineering.\nModel validation tests to detect performance degradation and drift.\n\nImpact on Metrics: Lowers Change Failure Rate by catching errors before production deployment.\nCommon Tools: pytest, Great Expectations, Deepchecks, TensorFlow Model Analysis\n\n\n\n\n\n\n\n\n\n\nCompute Resource Management\n\n\n\n\n\nCompute resource management is essential for optimizing the efficiency and scalability of ML workflows. ML models often require significant computational power for training and inference, and ensuring these resources are managed effectively is critical for cost efficiency and performance.\n\nWhere it fits in ML systems:\n\nModel Training: Allocating appropriate GPU, TPU, or cloud VM instances to optimize training speed without over-provisioning.\nModel Inference: Ensuring inference workloads scale dynamically based on demand, particularly in real-time or batch-processing environments.\nResource Optimization: Using Kubernetes and serverless architectures to allocate resources only when needed, reducing idle compute costs.\n\nImpact on Metrics:\n\nReduces Mean Time to Recovery (MTTR) by ensuring fast resource allocation and failure recovery.\nImproves Deployment Frequency by enabling automated provisioning and scaling for training and deployment workflows.\n\nCommon Tools:\n\nKubernetes – Orchestration for containerized workloads.\nRay – Distributed computing for ML workloads.\nAWS SageMaker – Managed ML model training and deployment.\nVertex AI – Google Cloud’s ML platform for scalable training and deployment.\nApache Spark – Distributed computing framework for big data processing and ML.\n\n\n\n\n\n\n\n\n\n\n\nStorage Solutions for ML\n\n\n\n\n\nStorage solutions in ML are crucial for managing the vast amounts of data and model artifacts efficiently. They ensure that data remains accessible, cost-effective, and scalable across different ML system components.\n\nWhere it fits in ML systems:\n\nData Ingestion & Processing: Storing raw and processed datasets in accessible and scalable formats.\nModel Training: Providing fast access to training datasets while ensuring version control.\nModel Deployment & Serving: Storing model artifacts and ensuring efficient retrieval for inference.\nReproducibility & Experimentation: Enabling dataset and model versioning to track changes over time.\n\nImpact on Metrics:\n\nEnhances Deployment Frequency by providing quick access to reliable data and models.\nReduces Mean Time to Recovery (MTTR) by ensuring efficient storage retrieval and minimizing downtime in case of failures.\n\nCommon Tools:\n\nDVC – Data versioning and storage management.\nPachyderm – Data lineage tracking and version control.\nMinIO – High-performance object storage for ML workloads.\nAmazon S3 – Scalable cloud object storage.\nGoogle BigQuery – Managed data warehouse for ML analytics.\n\n\n\n\n\n\n\n\n\n\n\nNetworking & Security Considerations\n\n\n\n\n\nNetworking and security considerations are critical to ensuring the reliability, compliance, and safety of ML workflows. ML models often operate in environments that require secure data handling, model integrity, and controlled access to prevent unauthorized use or attacks.\n\nWhere it fits in ML systems:\n\nModel Deployment & Serving: Ensuring APIs for model inference are protected from unauthorized access and adversarial attacks.\nData Privacy & Compliance: Encrypting sensitive data and enforcing access control to comply with GDPR, HIPAA, and other regulations.\nInfrastructure Security: Securing cloud and on-premise environments where ML models and data are stored and processed.\nMonitoring & Threat Detection: Implementing logging, anomaly detection, and automated alerts to mitigate potential security threats.\n\nImpact on Metrics:\n\nLowers Change Failure Rate by reducing vulnerabilities that could lead to breaches or unauthorized access.\nReduces Mean Time to Recovery (MTTR) by enabling rapid detection and remediation of security incidents.\n\nCommon Tools:\n\nIstio – Service mesh for securing and managing ML microservices.\nHashiCorp Vault – Secrets management for securing API keys and credentials.\nAWS IAM – Identity and access management for cloud-based ML systems.\nAzure Key Vault – Secure storage of cryptographic keys and secrets.\nGoogle Cloud Security Command Center – Centralized security management for cloud-hosted ML workflows.\n\n\n\n\n\n\n\n\n\n\n\nCross-Team Collaboration\n\n\n\n\n\nCollaboration is a fundamental aspect of MLOps, ensuring that data scientists, ML engineers, and operations teams work efficiently to deliver and maintain high-quality ML models in production. By fostering strong communication and shared workflows, teams can prevent bottlenecks and improve deployment reliability.\n\nWhere it fits in ML systems:\n\nModel Development & Experimentation: Enabling knowledge sharing between data scientists and engineers to ensure scalable and production-ready models.\nCI/CD & Deployment: Creating standardized workflows for continuous integration and deployment across multiple environments.\nMonitoring & Maintenance: Establishing cross-functional feedback loops to ensure model performance and system health over time.\nGovernance & Compliance: Ensuring that all teams align on ethical AI, regulatory requirements, and operational best practices.\n\nImpact on Metrics:\n\nReduces Lead Time for Changes by improving coordination and efficiency across teams.\nEnhances Deployment Frequency by standardizing collaboration workflows and preventing bottlenecks.\n\nImpact on Metrics: Reduces Lead Time for Changes by improving coordination and efficiency across teams.\nCommon Tools:\n\nSlack – Real-time team communication and collaboration.\nJira – Project management for tracking ML experiments and deployments.\nConfluence – Documentation and knowledge-sharing platform.\nGitHub – Version control for managing code, models, and data.\nGitHub Projects – Task and workflow management for ML teams.\nAzure DevOps – CI/CD and version control integration for scalable MLOps workflows.\n\n\n\n\n\n\n\n\nGit and GitHub are especially crucial in MLOps, as they enable versioning of ML code, datasets, and models, ensuring reproducibility and collaboration. The next chapter will provide a deeper dive into Git and GitHub, covering best practices for managing ML projects effectively.",
    "crumbs": [
      "DevOps",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>The Role of DevOps</span>"
    ]
  },
  {
    "objectID": "10-devops-role.html#challenges-in-devops-for-ml",
    "href": "10-devops-role.html#challenges-in-devops-for-ml",
    "title": "10  The Role of DevOps",
    "section": "10.4 Challenges in DevOps for ML",
    "text": "10.4 Challenges in DevOps for ML\nWhile DevOps practices have greatly improved software development and deployment, applying these principles to ML systems presents unique challenges. These challenges arise due to the dynamic nature of ML workflows, dependencies on data, and the interdisciplinary collaboration required to maintain production-ready ML systems. Below are some key challenges organizations face when implementing DevOps in ML.\n\n\n\n\n\n\nComplexity in Automating ML Pipelines\n\n\n\n\n\n\nImportance: Automation in ML pipelines is crucial for ensuring reproducibility, scalability, and efficiency. A well-automated ML pipeline enables seamless transitions between data ingestion, preprocessing, model training, validation, and deployment. It reduces human intervention, minimizes errors, and accelerates time-to-production.\nChallenge: Unlike traditional software, ML workflows involve complex dependencies between code, data, and models. Managing these dependencies while ensuring automation across different ML frameworks and infrastructure environments can be difficult. Additionally, handling data drift and model degradation over time adds another layer of complexity.\nRecommendation: Organizations should invest in robust pipeline orchestration tools such as Kubeflow or Apache Airflow to manage dependencies and automate end-to-end ML workflows. Implementing automated data validation and model monitoring solutions will help detect drift and trigger retraining when necessary.\n\n\n\n\n\n\n\n\n\n\nInfrastructure Cost & Resource Allocation\n\n\n\n\n\n\nImportance: ML workloads require substantial computational resources, often relying on GPUs and TPUs for training and inference. Managing infrastructure efficiently ensures that organizations can scale their ML initiatives while maintaining cost-effectiveness.\nChallenge: Balancing cost and performance when deploying at scale is challenging. Over-provisioning leads to wasted resources and increased costs, while under-provisioning can degrade model performance and slow down inference or training jobs.\nRecommendation: Organizations should leverage cloud-based solutions with auto-scaling capabilities, such as AWS SageMaker and Google Vertex AI. Using serverless computing and spot instances can further optimize costs while ensuring workload efficiency.\n\n\n\n\n\n\n\n\n\n\nEnsuring Reproducibility in Model Deployment\n\n\n\n\n\n\nImportance: Reproducibility is a cornerstone of reliable ML systems. It ensures that models can be trained, tested, and deployed consistently across different environments, reducing the risk of unexpected performance discrepancies.\nChallenge: Versioning datasets, models, and configurations effectively is difficult due to the dynamic nature of ML workflows. Changes in data distribution, feature engineering, and hyperparameter tuning can result in different model outputs, making it hard to replicate results.\nRecommendation: Adopting model and data versioning tools such as DVC and MLflow helps maintain a trackable history of datasets, models, and experiments. Implementing standardized experiment tracking ensures transparency and consistency across teams.\n\n\n\n\n\n\n\n\n\n\nSecurity & Compliance\n\n\n\n\n\n\nImportance: ML systems often process sensitive data, making security and compliance critical to maintaining trust and meeting regulatory requirements. Secure access to models and data prevents unauthorized usage and potential adversarial attacks.\nChallenge: Ensuring compliance with industry regulations like GDPR and HIPAA while maintaining strong access controls and encryption mechanisms is a significant challenge. ML models can also be vulnerable to data poisoning and adversarial attacks.\nRecommendation: Organizations should implement role-based access controls (RBAC) using tools like AWS IAM or Azure Key Vault. Encrypting data in transit and at rest and adopting secure API management solutions like Istio can enhance security.\n\n\n\n\n\n\n\n\n\n\nInterdisciplinary Communication Barriers\n\n\n\n\n\n\nImportance: Successful MLOps relies on seamless collaboration between data scientists, ML engineers, software developers, and IT operations. Effective communication ensures that models move efficiently from research to production.\nChallenge: Misalignment between DevOps and data science teams can lead to inefficiencies. Data scientists may prioritize experimentation, whereas DevOps teams focus on scalability, security, and stability. This difference in priorities often results in delays and inconsistencies in ML deployment.\nRecommendation: Organizations should establish clear workflows and shared responsibilities by implementing collaboration platforms such as GitHub and Azure DevOps. Encouraging cross-functional meetings and using tools like Confluence for documentation can foster better alignment.\n\n\n\n\n\n\n\n\n\n\nStandardizing DevOps Practices Across an Enterprise\n\n\n\n\n\n\nImportance: A standardized approach to MLOps ensures consistency, scalability, and efficiency across different teams and projects. Establishing uniform DevOps practices prevents fragmentation and reduces redundant efforts.\nChallenge: Many organizations struggle to create unified DevOps frameworks for ML, leading to inconsistent workflows and infrastructure sprawl. Without standardization, different teams may use different tools and methodologies, making scaling and governance difficult.\nRecommendation: Organizations should define enterprise-wide MLOps best practices and enforce them using Infrastructure as Code (IaC) tools like Terraform or Pulumi. Establishing centralized ML platforms and CI/CD pipelines ensures governance while maintaining flexibility for innovation.\n\n\n\n\nBy addressing these challenges with structured DevOps strategies, organizations can build scalable, secure, and efficient ML workflows. Investing in automation, collaboration, and standardization will ultimately drive the success of ML initiatives in production environments.",
    "crumbs": [
      "DevOps",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>The Role of DevOps</span>"
    ]
  },
  {
    "objectID": "10-devops-role.html#summary",
    "href": "10-devops-role.html#summary",
    "title": "10  The Role of DevOps",
    "section": "10.5 Summary",
    "text": "10.5 Summary\nThis chapter explored how DevOps principles enhance ML workflows by integrating automation, scalability, and collaboration into model development and deployment. By applying CI/CD, infrastructure as code, and monitoring, organizations can improve ML system reliability, streamline model updates, and ensure reproducibility.\nKey takeaways include:\n\nAutomation reduces errors and accelerates deployment cycles.\nScalability ensures optimal resource utilization and cost efficiency.\nCollaboration bridges the gap between data scientists, ML engineers, and DevOps teams.\n\nBy implementing these principles, ML teams can increase deployment frequency, reduce downtime, and improve maintainability.\nThe next chapter introduces Git and GitHub, essential tools for version control in MLOps as it provides:\n\nTracking ML code, datasets, and models for reproducibility.\nCollaborative workflows for managing team-based ML projects.\nGitHub Actions for CI/CD, automating testing and deployment.\n\nMastering Git and GitHub will help teams integrate DevOps best practices into their ML workflows for scalable and production-ready systems.",
    "crumbs": [
      "DevOps",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>The Role of DevOps</span>"
    ]
  },
  {
    "objectID": "10-devops-role.html#exercise",
    "href": "10-devops-role.html#exercise",
    "title": "10  The Role of DevOps",
    "section": "10.6 Exercise",
    "text": "10.6 Exercise\nRead the paper Hidden Technical Debt in Machine Learning Systems and analyze how DevOps principles align with the key discussion points made in the paper. Consider the following questions:\n\nHow does the concept of technical debt in ML relate to the need for automation in DevOps?\nWhat aspects of DevOps help mitigate system entropy and hidden dependencies as described in thepaper?\nHow can DevOps practices address reproducibility challenges and data dependencies in ML workflows?\nWhat role does continuous monitoring play in managing feedback loops and ensuring system stability?",
    "crumbs": [
      "DevOps",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>The Role of DevOps</span>"
    ]
  },
  {
    "objectID": "10-devops-role.html#footnotes",
    "href": "10-devops-role.html#footnotes",
    "title": "10  The Role of DevOps",
    "section": "",
    "text": "As outlined in Google’s 2019 State of DevOps Report: https://services.google.com/fh/files/misc/state-of-devops-2019.pdf↩︎",
    "crumbs": [
      "DevOps",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>The Role of DevOps</span>"
    ]
  },
  {
    "objectID": "11-devops-git.html",
    "href": "11-devops-git.html",
    "title": "11  Introduction to Git and GitHub",
    "section": "",
    "text": "11.1 Introduction to Git and GitHub\nVersion control is an essential part of modern software development, enabling teams to collaborate efficiently, track changes, and manage codebases systematically. Git, a distributed version control system, has become the industry standard for tracking modifications and maintaining project history. GitHub, a cloud-based platform built around Git, enhances collaboration by providing a central repository for sharing, reviewing, and integrating code changes.\nThis chapter introduces Git and GitHub as foundational tools in the DevOps journey. Understanding version control and collaboration through these tools is essential for managing code effectively and enabling seamless teamwork. Whether working independently or within a team, proficiency in Git and GitHub empowers developers to maintain project integrity, experiment with new features, and contribute to open-source projects.\nBy the end of this chapter, you will:\nThrough hands-on exercises and step-by-step guides, this chapter will equip you with the fundamental skills to manage source code efficiently and collaborate on projects with confidence.",
    "crumbs": [
      "DevOps",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Introduction to Git and GitHub</span>"
    ]
  },
  {
    "objectID": "11-devops-git.html#introduction-to-git-and-github",
    "href": "11-devops-git.html#introduction-to-git-and-github",
    "title": "11  Introduction to Git and GitHub",
    "section": "",
    "text": "What is Version Control?\nVersion control is a system that records changes to a file or set of files over time, allowing developers to track modifications, revert to previous versions, and collaborate seamlessly. It is essential for managing code in any software development process, preventing loss of work, and ensuring a structured workflow.\n\n\n\n\n\n\n%%{init: {'gitGraph': {'mainBranchName': 'Main codebase'}} }%%\n\ngitGraph\n   commit id: \"Version 1\"\n   commit id: \"Version 2\"\n   branch \"Your code\"\n   commit id: \"add new feature\"\n   checkout \"Main codebase\"\n   commit id: \"Version 3\"\n   branch \"Someone else's code\"\n   checkout \"Main codebase\"\n   merge \"Your code\" id: \"Version 4\"\n   checkout \"Someone else's code\"\n   commit id: \"another new feature\"\n   checkout \"Main codebase\"\n   merge \"Someone else's code\" id: \"Version 5\"\n\n\n\n\nFigure 11.1: A version control system allows you and your teammates to work collaboratively, safely, and simultaneously on a single project. Version control helps you track all the code changes made in your project.\n\n\n\n\n\nWithout version control, teams often encounter challenges such as overwritten files, difficulty tracking changes, and conflicts when multiple contributors work on the same codebase. For instance, in machine learning (ML) projects, version control is crucial for tracking changes to datasets, model configurations, and source code, enabling reproducibility and iterative improvements.\n\n\nWhat is Git?\nGit is a distributed version control system (DVCS) designed to handle everything from small to very large projects efficiently. Unlike centralized version control systems, where a single server stores all versions of a project, Git enables every user to have a complete local copy of the repository. This makes Git robust in handling offline work, merging changes, and maintaining a reliable history of modifications.\nFor ML systems, Git helps in maintaining different experiment branches, managing multiple versions of code, and integrating model versioning workflows. Developers and data scientists use Git to collaborate on research code, ensuring that experimental changes do not disrupt stable pipelines.\n\n\nWhat is GitHub?\nGitHub is a cloud-based platform that provides remote repository hosting and additional features for version control collaboration. It enhances Git’s capabilities by offering tools for pull requests, issue tracking, and code review, making it a central hub for software development.\nWhile GitHub is one of the most popular Git hosting services, alternatives like GitLab and Bitbucket provide similar functionality with varying degrees of customization and integration options. In the context of DevOps and ML workflows, GitHub plays a key role in continuous integration/continuous deployment (CI/CD) pipelines, enabling automated testing, deployment, and monitoring of ML models in production environments. By using GitHub, ML engineers can streamline collaboration, ensure code quality, and integrate seamlessly with MLOps platforms.\n\n\n\n\n\narchitecture-beta\n    service github(cloud)[Github]\n    service git(disk)[Git on local computer]\n\n    git:T &lt;--&gt; B:github\n\n\n This illustrates the simple relationship between a local Git repository on a developer’s computer and a remote GitHub repository hosted in the cloud. Git and Github work in tandem allow you to push and pull content between the two locations. \n\n\n\n\n\nUsing Git and GitHub Together\nAlthough Git and GitHub are separate tools, they are most commonly used together in modern software development. Git serves as the local version control system that tracks changes and manages branches, while GitHub acts as the remote hosting service that facilitates collaboration among multiple contributors. Developers use Git commands to manage their local repositories and push their changes to GitHub for storage, sharing, and team collaboration.\n\n\n\n\n\n\nFigure 11.2: Git vs. Github\n\n\n\nFor ML teams, this combination is particularly powerful. By using Git locally to track changes in data processing scripts, model training code, and experiment configurations, teams can ensure that their work is versioned and reproducible. GitHub then provides a centralized location where team members can review each other’s code, integrate improvements, and leverage automated workflows for model deployment and testing. The synergy between Git and GitHub makes them indispensable tools for both traditional software development and MLOps practices.",
    "crumbs": [
      "DevOps",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Introduction to Git and GitHub</span>"
    ]
  },
  {
    "objectID": "11-devops-git.html#setting-up-git-and-github",
    "href": "11-devops-git.html#setting-up-git-and-github",
    "title": "11  Introduction to Git and GitHub",
    "section": "11.2 Setting Up Git and GitHub",
    "text": "11.2 Setting Up Git and GitHub\nGit and GitHub are essential tools for managing and collaborating on code projects. This section provides a step-by-step guide to installing Git, creating a GitHub account, and configuring Git for first-time use.\n\nInstalling Git\nTo begin using Git, you must first install it on your local machine. You can download Git for all operating systems from the official website: https://git-scm.com/downloads. This website provides multiple installation options for each operating system, allowing you to choose the one that best fits your needs. \n\n\n\n\n\n\nFigure 11.3: You can download Git for all operating systems from the official website: https://git-scm.com/downloads. This website provides multiple installation options for each operating system, allowing you to choose the one that best fits your needs.\n\n\n\nThe following are the most common approaches used.\n\nWindows\n\nDownload the Git installer from https://git-scm.com/downloads.\nRun the installer and follow the setup instructions, selecting default options unless specific configurations are needed.\nOpen the Command Prompt or Git Bash and verify the installation by running:\ngit --version\n\n\n\nmacOS\n\nOpen the Terminal application.\nInstall Git using Homebrew (recommended):\nbrew install git\nVerify the installation:\ngit --version\n\n\n\nLinux\n\nOpen the terminal and use the package manager for your distribution:\n\nDebian/Ubuntu:\nsudo apt update\nsudo apt install git\nFedora:\nsudo dnf install git\nArch Linux:\nsudo pacman -S git\n\nConfirm the installation:\ngit --version\n\n\n\n\nCreating a GitHub Account\nTo use GitHub for hosting and collaborating on repositories, you need an account.\n\nGo to https://github.com. \nClick Sign Up and enter your email, password, and username.\nFollow the prompts to verify your email and complete the registration process.\nOnce logged in, explore key GitHub features. Take some time to browse around and look at other user profiles and GitHub repositories to see how they are organized. A great way to start is by checking out the following repositories:\n\n\npandas: pandas\nFastAPI: https://github.com/tiangolo/fastapi\nPydantic: https://github.com/pydantic/pydantic\nPython Data Visualization: https://github.com/talkpython/python-data-visualization\n\n\n\n\n\n\nIn these repositories, observe how the code is structured, review the README file, and explore the issues, pull requests, and GitHub Actions tabs.  Don’t worry about understanding these as we will be covering them shortly; just get a feel for how a Github repo is structured.\n\n\n\n\n\n\nConfiguring Git for First Use\nBefore using Git, configure it with your personal information to ensure that commits are properly attributed to you. Configuring Git is essential because it associates your work with your identity, ensuring that every commit you make is correctly attributed to you in Git logs and GitHub repositories.\n\n\n\n\n\n\nGit has many other settings that can be customized to fit your workflow. You can explore the full list of available configuration options in the official Git documentation.\n\n\n\n\nOpen a terminal or command prompt.\nSet your name:\ngit config --global user.name \"Your Name\"\nSet your email:\ngit config --global user.email \"you@example.com\"\nVerify your configuration:\ngit config --list\n\nThe --global flag ensures that these settings apply to all Git repositories on your system. Without this flag, the configuration would only apply to the current repository, meaning you would need to set these details again for every new project. By setting them globally, you ensure a consistent identity across all your projects.\n\n\n\n\n\n\nFigure 11.4: Configuring Git with your personal information to ensure that commits are properly attributed to you.\n\n\n\nWith Git installed and configured, and a GitHub account created, you’re now ready to start using Git for version control and collaboration. Git and GitHub are extremely powerful and sophisticated tools with a wide range of functionalities. However, for typical day-to-day use on projects, the Git and GitHub workflow can be boiled down to just a handful of essential functionalities. The video that follows provides an introduction to this basic workflow, and the sections that follow will walk you through this workflow step-by-step.",
    "crumbs": [
      "DevOps",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Introduction to Git and GitHub</span>"
    ]
  },
  {
    "objectID": "11-devops-git.html#git-basics-tracking-and-managing-changes",
    "href": "11-devops-git.html#git-basics-tracking-and-managing-changes",
    "title": "11  Introduction to Git and GitHub",
    "section": "11.3 Git Basics: Tracking and Managing Changes",
    "text": "11.3 Git Basics: Tracking and Managing Changes\nGit provides powerful tools for tracking and managing changes in your projects. This section covers fundamental Git operations, including creating a repository, staging and committing changes, and viewing repository history.\n\nCreating a Local Git Repository\nA Git repository is essentially a directory (or folder) that has been set up to track changes using Git. When you initialize a Git repository, Git begins monitoring changes to files within that directory, allowing you to record, revert, and collaborate efficiently. You can create a new local repository from scratch or clone an existing one from a remote source to start tracking changes immediately.\n\nInitializing a Repository\nTo start tracking a project with Git, navigate to the project directory in your terminal and initialize a repository:\ncd your-project-folder\ngit init\nThis creates a hidden .git directory, where Git stores all version control information.\n\n\n\n\n\n\n.git directory\n\n\n\n\n\nAt this time, you don’t need to worry about the contents of the .git directory, as it is managed by Git automatically. However, if you want to explore its contents, you can make hidden files visible:\n\nOn Windows, open File Explorer, go to the View tab, and check Hidden items.\nOn macOS or Linux, open the terminal and use:\nls -la\nOr you can also use `Cmd + Shift + .`\n\n\n\n\n\n\n\n\n\n\nBe cautious not to modify any files inside the .git directory, as doing so may corrupt the repository.\n\n\n\n\n\nCloning a Repository\nOften, projects you work on are not brand new but rather existing projects where you are a new collaborator. Most of the time, these projects are already hosted on GitHub, and your objective is to make a copy of the repository on your local machine so you can start contributing to the source code. If you want to work on an existing project, you can clone a remote repository:\ngit clone &lt;repository-url&gt;\nThis creates a local copy of the remote repository on your machine, allowing you to track and contribute changes.\n\n\n\n\n\n\nTo find the Git repository URL on GitHub, navigate to the main page of the repository you are interested in. Under the repository name, you will see a green “Code” button. Click on this button to reveal a dropdown menu that displays the repository URL. You can choose between HTTPS, SSH, or GitHub CLI options. Copy the URL provided to use it for cloning the repository to your local machine or for other Git operations.\nFor example, if you were to clone the UC BANA 7075 Github repo shown below you would use:\ngit clone https://github.com/bradleyboehmke/uc-bana-7075.git\n\n\n\nGit Repository URL\n\n\n\n\n\n\n\n\nStaging and Committing Changes\nNow that you have a local repository set up for your project, you can start making changes to project documentation, code files, or other assets and save these changes systematically. This ensures that you have a record of modifications, making it easier to track progress, revert changes if necessary, and collaborate with others.  Git uses a two-step process to save changes:\n\nStep 1 is called staging and\nStep 2 is called committing.\n\n\nAdding Files to Staging\nStaging in Git is the process of preparing changes for a commit. When you modify files in your working directory, Git does not automatically track them for the next commit. Instead, you must explicitly add them to the staging area using the git add command. This allows you to carefully select which changes you want to include in your next commit, rather than committing all changes at once.\nThink of the staging area as a middle step between your working directory (where changes are made) and your repository (where commits are stored). This separation gives you greater control over your commits, allowing you to structure them in a meaningful way.\nTo stage a specific file you can use:\ngit add filename\nTo stage all modified files:\ngit add .\n\n\n\n\n\n\nBe care when using git add . as this will stage all files that have changed. Often, we want to be deliberate about which files we stage so files don’t accidently get staged and committed.\n\n\n\n\n\nCommitting Changes\nOnce files are staged, you can commit them with a descriptive message:\ngit commit -m \"Commit message describing changes\"\nCommits serve as snapshots of your project, capturing the exact state of your files at a given point in time. Each commit represents a recorded change, allowing you to track modifications, revert to previous versions if needed, and collaborate with others more effectively. Commits also create a historical timeline of your project, making it easier to understand the evolution of the codebase and identify when specific changes were introduced. By using meaningful commit messages, you can document the purpose of each change, improving project maintainability and readability.\n\n\n\n\n\n\n%%{init: {'gitGraph': {'mainBranchName': 'Main codebase'}} }%%\n\ngitGraph\n   commit id: \"Change 1\"\n   commit id: \"Change 2\"\n   commit id: \"Change 3\"\n\n\n\n\nFigure 11.5: Commits serve as snapshots of your project, capturing the exact state of your files at a given point in time. Each commit represents a recorded change, allowing you to track modifications and revert to previous versions if needed.\n\n\n\n\n\n\n\n\nViewing Repository Status & History\n\nChecking Current Work Status\nAt any point while modifying files in the repository, you can check which files have changed, which are staged, and which are unstaged by running the following command:\ngit status\nThis command provides a summary of the repository’s current state.\n\n\nChecking Commit History\nYou can also view a log of all past commits with:\ngit log\nThis displays commit messages, authors, timestamps, and unique commit hashes. For example, if I look at the recent commits for the log of the repo for this class it looks like:\n\n\n\n\n\n\nFigure 11.6: Recent commits in the log for the UC BANA 7075 repository.\n\n\n\n\n\nUnderstanding the SHA Hash for Commits\nEach commit is assigned a unique SHA hash, which acts as an identifier, ensuring that every change in the repository has a distinct reference. A SHA (Secure Hash Algorithm) hash in Git is a 40-character hexadecimal string that uniquely represents a commit. This hash is generated based on the commit’s content, metadata, and parent commit(s), making it nearly impossible to duplicate. The SHA hash is used to reference specific commits, allowing developers to revert to, compare, or identify previous changes efficiently.\n\n\n\n\n\n\n%%{init: {'gitGraph': {'mainBranchName': 'Main codebase'}} }%%\n\ngitGraph\n   commit\n   commit\n   commit\n\n\n\n\nFigure 11.7: Example of what commit SHA hashes look like. Although the actual SHA hash is longer, you typically just see the first 7+ digits of the hash.\n\n\n\n\n\nUnderstanding SHA hashes is crucial for navigating a project’s history and managing different versions effectively. Each SHA hash serves as a permanent reference point, enabling developers to track specific changes, revert to stable versions, and collaborate efficiently. When working in a team, referencing SHA hashes in discussions and bug fixes ensures clarity and precision, reducing ambiguity when identifying code changes. Additionally, SHA hashes play a fundamental role in advanced Git operations such as rebasing and resolving merge conflicts.\n\n\n\n\n\n\nAlthough understanding SHA hashes is important, for now, just realize that each commit has a SHA hash identifier that allows you to reference specific commits throughout a project’s lifecycle.\n\n\n\nYou can reference specific commits using their SHA hash in various Git commands, such as checking out a previous commit. This will allow you to revert all project files back to the state that they were in based on the commit hash provided.\ngit checkout &lt;commit-hash&gt;",
    "crumbs": [
      "DevOps",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Introduction to Git and GitHub</span>"
    ]
  },
  {
    "objectID": "11-devops-git.html#synchronizing-with-github",
    "href": "11-devops-git.html#synchronizing-with-github",
    "title": "11  Introduction to Git and GitHub",
    "section": "11.4 Synchronizing with GitHub",
    "text": "11.4 Synchronizing with GitHub\nOnce you have a local Git repository, you often need to synchronize it with a remote repository hosted on GitHub. This allows you to share your work, collaborate with others, and ensure your local repository stays up to date with any changes made remotely. This section covers how to connect a local repository to GitHub, pull updates from GitHub, and handle merge conflicts when they arise.\n\nCreating a New Repository on GitHub\nIf you do not already have a local repository, you can start your project repo on GitHub by creating a new repository and cloning it locally to start working with. This video provides an example:\n\nThe steps to do this include:\n\nNavigate to GitHub and log in to your account.\nClick the + icon in the upper-right corner and select New repository.\nEnter a repository name, choose public or private visibility, and click Create repository.\nCopy the repository URL provided by GitHub.\nOpen a terminal and navigate to the directory where you want to clone the repository.\nUse the following command to clone the repository to your local machine:\ngit clone https://github.com/your-username/your-repository.git\n\nYour repository is now set up locally, and you can start working with it. This means you have a dedicated directory on your computer where you can create, modify, and track files under version control. Any changes you make can be committed and later synchronized with GitHub, enabling seamless collaboration and backup.\n\n\nPushing a New Local Repository to GitHub\nSometimes, you may start a project on your local machine without creating a GitHub repository first. In such cases, you can push your local repository to GitHub by adding a remote repository. If you have an existing local repository and want to push it to GitHub, follow these steps:\n\nOpen a terminal and navigate to your local repository:\ncd your-project-folder\nAdd the GitHub repository as a remote:\ngit remote add origin https://github.com/your-username/your-repository.git\nVerify that the remote was added correctly:\ngit remote -v\nPush the local repository to GitHub:\ngit push -u origin main\nThis command uploads your local commits to the remote repository and sets the origin remote as the default for future pushes.\n\n\n\nPushing & Pulling Changes from GitHub\nOnce you have a local repository connected to a remote GitHub repository, you will need to push and pull changes between the two to keep them in sync over time and as the project progresses. When you make changes to the project locally and commit them, you can push these changes to GitHub using:\ngit push origin main\nThis updates the remote repository with your latest committed changes, making them available for others to see and collaborate on.\nSimilarly, other contributors may make updates and push them to GitHub. To ensure your local repository remains up to date, you need to pull these changes from GitHub.\ngit pull origin main\nThis command updates your local repo with the latest changes from GitHub.",
    "crumbs": [
      "DevOps",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Introduction to Git and GitHub</span>"
    ]
  },
  {
    "objectID": "11-devops-git.html#collaboration-with-branching-and-pull-requests",
    "href": "11-devops-git.html#collaboration-with-branching-and-pull-requests",
    "title": "11  Introduction to Git and GitHub",
    "section": "11.5 Collaboration with Branching and Pull Requests",
    "text": "11.5 Collaboration with Branching and Pull Requests\nGit and GitHub provide powerful tools for collaboration, and one of the most important features is branching. Branching allows developers to work on different tasks or features without affecting the main codebase. This section introduces the concept of branches, pull requests, and best practices for effective collaboration.\n\nWhy Use Branches?\nWhen working on a software project, it’s essential to develop new features, fix bugs, and experiment without disrupting the main working version of the code. Branches provide a way to create separate workspaces for these tasks. Instead of working directly on the main branch, which represents the stable version of the project, developers create new branches to isolate their changes.\nA branch in Git is like a separate workspace where you can work on new features, bug fixes, or experiments without affecting the main version of your project. Think of it as a parallel timeline where you can make changes without disrupting the main history. Once your work is complete, you can merge your branch back into the main branch.\n\n\n\n\n\n\n%%{init: {'gitGraph': {'mainBranchName': 'Main codebase'}} }%%\n\ngitGraph\n   commit id: \"Version 1\"\n   commit id: \"Version 2\"\n   branch \"Branch 1\"\n   commit id: \"little feature\"\n   checkout \"Main codebase\"\n   commit id: \"Version 3\"\n   branch \"Branch 2\"\n   checkout \"Main codebase\"\n   merge \"Branch 1\" id: \"Version 4\"\n   checkout \"Branch 2\"\n   commit id: \"big feature\"\n   checkout \"Main codebase\"\n   merge \"Branch 2\" id: \"Version 5\"\n\n\n\n\nFigure 11.8: This diagram visualizes a repository with two isolated lines of development, one for a little feature, and one for a larger feature. By developing them in branches, it’s not only possible to work on both of them in parallel, but it also keeps the main branch free from questionable code. Once the new feature code is complete, we can merge the branches back into the main branch.\n\n\n\n\n\nUsing branches has several advantages:\n\nAllows multiple team members to work on different features simultaneously.\nPrevents incomplete or experimental code from affecting the main codebase.\nMakes it easier to review and test changes before merging them.\n\nThe following sections will provide a nice introduction to branching but to learn more about good branching practices and detailed explanations of branching strategies, refer to A Guide to Branching in Git.\n\n\nCreating and Switching Branches\nTo create a new branch, use the following command:\ngit branch new-feature\nThis command creates a new branch called new-feature, but it does not switch to it automatically. To switch to the newly created branch, use:\ngit checkout new-feature\nor (recommended)\ngit switch new-feature\nNow, any changes you make will be recorded in the new-feature branch instead of main.  \n\n\n\n\n\n\n%%{init: {'gitGraph': {'mainBranchName': 'main'}} }%%\n\ngitGraph\n   commit id: \"Version 1\"\n   commit id: \"Version 2\"\n   branch \"new-feature\"\n   commit id: \"little feature\"\n\n\n\n\nFigure 11.9: Illustration of creating a new branch named new-feature to allow you to work on code for the new feature without impacting the current code in the main branch.\n\n\n\n\n\nOnce work on a branch is complete, the changes need to be merged back into the main branch. There are a couple of ways to merge branches. One way is to merge the branches locally using Git commands. Another way is to use a pull request on GitHub to propose the changes, allow others to review and approve them, and then perform the merge. The latter approach is more common in collaborative projects, as it ensures code quality and enables team discussion before integration.  However, the following sections will discuss both approaches.\n\n\nMerging Branches\nMerging branches locally allows you to integrate changes from one branch into another without relying on GitHub. This approach is useful when working offline, testing changes before pushing them, or handling merges in a controlled environment before sharing updates with the team. To merge the branches locally, first, switch back to main:\ngit checkout main\n(or use git switch main) Then merge the feature branch:\ngit merge new-feature\nIf there are no conflicts, Git will integrate the changes. If conflicts exist, Git will prompt you to resolve them manually before completing the merge.\n\n\n\n\n\n\n%%{init: {'gitGraph': {'mainBranchName': 'main'}} }%%\n\ngitGraph\n   commit id: \"Version 1\"\n   commit id: \"Version 2\"\n   branch \"new-feature\"\n   commit id: \"little feature\"\n   checkout \"main\"\n   merge \"new-feature\"\n\n\n\n\nFigure 11.10: Illustration of merging the new-feature branch into the main branch.\n\n\n\n\n\n\n\n\n\n\n\nFor more details on merging strategies and resolving merge conflicts, check out Merging in Git and How to Resolve Merge Conflicts.\n\n\n\n\n\nPull Requests on GitHub\nA Pull Request (PR) is a way to propose changes from one branch to another on GitHub. PRs allow for discussion, review, and approval before merging changes. They are especially useful in collaborative projects where multiple developers are working on different features simultaneously. By using pull requests, teams can review changes before they are merged, ensuring code quality and reducing the risk of introducing bugs.\nWhile merging locally is useful for small, independent changes, pull requests should be used when working in a team setting to facilitate discussions, maintain a clear project history, and ensure that changes align with project goals. PRs also integrate well with automated testing and continuous integration workflows, making them a preferred method for managing contributions in larger projects.\n\nOpening a Pull Request\n\nPush your branch to GitHub:\ngit push origin new-feature\nGo to your repository on GitHub.\nClick the Pull Requests tab and then New Pull Request.\nSelect the branch you want to merge into main and provide a clear description of your changes.\nRequest a review from teammates to get feedback on your code.\n\n\n\nMerging a Pull Request\nOnce the pull request is approved:\n\nClick the Merge Pull Request button on GitHub.\nDelete the branch if it is no longer needed.\nUpdate your local repository:\ngit pull origin main\n\n\n\n\nBest Practices for Collaboration\nCollaboration in Git and GitHub is most effective when following best practices. This includes writing clear commit messages, keeping branches small and focused, and regularly syncing with the main branch. Additionally, requesting code reviews helps ensure code quality and facilitates better teamwork.\n\nWrite meaningful commit messages – Each commit should clearly describe what was changed and why. A good commit message follows a standard format and is concise yet descriptive. For example:\nfeat: Add model monitoring with logging\n\nImplemented model performance monitoring with logging capabilities. Added a logging framework to track prediction accuracy, response times, and data drift over time.\nFollowing a clear commit message format helps other developers understand the purpose of changes and makes version history easier to navigate. To learn more about writing effective commit messages, refer to How to Write a Git Commit Message.\nKeep branches small and focused – Large branches can become difficult to review and merge. Aim for focused, single-purpose branches.\nRegularly sync with main – Periodically pull updates from main to keep your branch up to date and reduce merge conflicts.\nRequest code reviews – Encourage collaboration and ensure code quality by having peers review changes before merging. A good code review process helps catch bugs early, enforces coding standards, and facilitates knowledge sharing among team members. When reviewing code, consider readability, maintainability, and adherence to project guidelines. To learn more about effective code reviews, refer to How to Conduct a Code Review.\n\nBy following these best practices, teams can collaborate effectively, maintain clean code, and streamline the development process.\n\n\n\n\n\n\nFor a more detailed discussion on best practices for pull requests, see the following references:\n\nGitHub’s Guide on Pull Requests\nBest Practices for Code Reviews and Pull Requests",
    "crumbs": [
      "DevOps",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Introduction to Git and GitHub</span>"
    ]
  },
  {
    "objectID": "11-devops-git.html#introduction-to-cicd-with-github-actions",
    "href": "11-devops-git.html#introduction-to-cicd-with-github-actions",
    "title": "11  Introduction to Git and GitHub",
    "section": "11.6 Introduction to CI/CD with GitHub Actions",
    "text": "11.6 Introduction to CI/CD with GitHub Actions\nCI/CD stands for Continuous Integration (CI) and Continuous Deployment (CD). It is a fundamental practice in modern software development and DevOps that helps automate the process of integrating and deploying code changes.\n\nContinuous Integration (CI) ensures that every code change is automatically tested and validated before being merged into the main branch. This helps catch bugs early and maintain software quality.\nContinuous Deployment (CD) takes CI a step further by automatically deploying validated changes to production or staging environments, reducing manual intervention and enabling faster release cycles.\n\nFor machine learning (ML) systems, CI/CD is particularly important as it helps automate model training, testing, and deployment, ensuring reproducibility and consistency across different environments. Unlike traditional software CI/CD, MLOps-specific CI/CD includes additional steps such as data validation, feature engineering, model retraining, and evaluation before deployment.\nThese pipelines help streamline workflows across various ML system processes, including:\n\nData Ingestion & Processing: Automating data extraction, transformation, and validation before feeding into model training.\nModel Training & Evaluation: Triggering training jobs when new data is available, followed by validation tests to check for performance regressions or drift.\nModel Deployment & Serving: Ensuring smooth transitions from development to production with robust version control and rollback mechanisms.\nContinuous Monitoring & Feedback Loops: Monitoring performance metrics and triggering model retraining when needed.\n\n\nIntroduction to GitHub Actions\nGitHub Actions is a powerful automation tool that enables developers to create workflows directly within a GitHub repository. It allows users to automate tasks such as testing, building, and deploying applications based on Git events (e.g., push, pull request, or scheduled triggers).\nGitHub Actions is particularly useful in CI/CD pipelines because it provides:\n\nAutomated Testing – Run unit tests, integration tests, and code quality checks automatically.\nContinuous Deployment – Deploy applications or ML models to cloud environments or production servers.\nCustom Workflows – Define and trigger sequences of automated steps using YAML configuration files.\n\nGitHub Actions workflows are stored inside the .github/workflows directory within a repository. This directory contains YAML configuration files that define various automation tasks. Each workflow file specifies when it should run, what environment it should use, and the sequence of actions to execute. For example, the following illustrates an ML project (ml-project) git repo that contains subdirectories for data ingestion, data cleaning, data validation, model experimentation, etc.; along with the .github/workflows directory that contains an example ML CI Pipeline yaml workflow file.\nml-project/\n│── .gitignore\n│\n│── .github/\n│   ├── workflows/\n│   │   ├── ml_ci_pipeline.yml\n│\n│── data_ingestion/\n│   ├── fetch_data.py\n│   ├── ingest_pipeline.py\n│\n│── data_cleaning/\n│   ├── clean_data.py\n│   ├── preprocess.py\n│\n│── data_validation/\n│   ├── validate_schema.py\n│   ├── check_duplicates.py\n│\n│── model_experimentation/\n│   ├── train.py\n│   ├── evaluate.py\n│\n│── model_deployment/\n│   ├── deploy.py\n│   ├── inference.py\n│\n│── model_monitoring/\n│   ├── monitor_performance.py\n│   ├── drift_detection.py\n│\n│── tests/\n│   ├── test_data_ingestion.py\n│   ├── test_model_training.py\n│   ├── test_model_inference.py\n│\n│── requirements.txt\n│── README.md\n\n\n\n\n\n\nFor example, here is the GitHub Actions workflow that I use to automatically build and publish this book on a daily basis - publish-book.yml.\n\n\n\nAnd the following GitHub Actions workflow file provides and example of what the ml_ci_pipeline.yml file may look like. This example workflow automates the process of training and evaluating a machine learning model every time new code is pushed to the main branch in the repository:\nname: ML CI Pipeline\n\non:\n  push:\n    branches:\n      - main\n\njobs:\n  train-and-test:\n    runs-on: ubuntu-latest\n    steps:\n      - name: Checkout repository\n        uses: actions/checkout@v3\n\n      - name: Set up Python\n        uses: actions/setup-python@v3\n        with:\n          python-version: '3.8'\n\n      - name: Install dependencies\n        run: |\n          pip install -r requirements.txt\n\n      - name: Train model\n        run: |\n          python train.py\n\n      - name: Evaluate model\n        run: |\n          python evaluate.py\nThis workflow does the following:\n\nTriggers on a push to the main branch.\nRuns on an Ubuntu-based virtual machine.\nChecks out the repository code.\nSets up Python and installs dependencies.\nRuns a training script (train.py) to train an ML model.\nEvaluates the trained model using a validation script (evaluate.py).\n\nBy integrating CI/CD into ML workflows, this process ensures that model training and evaluation are automated, helping maintain performance consistency and reproducibility.\nThis workflow does the following:\n\nTriggers on a push to the main branch.\nRuns on an Ubuntu-based virtual machine.\nChecks out the repository code.\nSets up Python and installs dependencies.\nRuns tests using pytest to validate changes.\n\n\n\nNext Steps in Learning CI/CD\nTo deepen your understanding of CI/CD and GitHub Actions, explore these resources:\n\nGitHub Actions Documentation\nCI/CD Best Practices\nBuilding CI/CD Pipelines for ML Systems\n\nBy implementing CI/CD workflows with GitHub Actions, you can enhance automation, improve code quality, and accelerate deployment in software and ML projects.",
    "crumbs": [
      "DevOps",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Introduction to Git and GitHub</span>"
    ]
  },
  {
    "objectID": "11-devops-git.html#summary",
    "href": "11-devops-git.html#summary",
    "title": "11  Introduction to Git and GitHub",
    "section": "11.7 Summary",
    "text": "11.7 Summary\nIn this chapter, we explored the fundamental concepts of Git and GitHub, essential tools for version control and collaboration in software development and MLOps. By leveraging Git’s capabilities, teams can efficiently track changes, collaborate on code, and maintain project history, while GitHub enhances these functionalities with cloud-based repository hosting, pull requests, and CI/CD automation.\n\nKey Takeaways\n\nGit and Version Control: Git provides a distributed version control system that allows developers to track changes, revert to previous versions, and collaborate without losing work.\nSetting Up Git and GitHub: We covered installing Git, configuring user settings, and creating repositories on GitHub to start managing code effectively.\nTracking and Managing Changes: Fundamental Git operations such as adding files, committing changes, and viewing repository history help maintain a structured development process.\nBranching and Collaboration: Branching enables isolated development, and pull requests facilitate team collaboration by allowing reviews and discussions before merging changes.\nSynchronizing with GitHub: We explored how to push and pull changes between local and remote repositories to keep projects up to date and prevent conflicts.\nCI/CD with GitHub Actions: Continuous Integration and Deployment (CI/CD) automates testing, validation, and deployment, streamlining ML workflows and DevOps processes.\n\n\n\nWhy This Matters for ML and DevOps\nVersion control and CI/CD are critical components of an efficient ML development pipeline. In ML projects, Git helps manage datasets, experiment tracking, and model versioning, while GitHub Actions facilitates automation, ensuring reproducibility and consistency across different environments. By integrating Git and GitHub into ML workflows, teams can collaborate more effectively, improve code quality, and deploy models with confidence.\n\n\nNext Steps\nTo deepen your understanding of Git, GitHub, and CI/CD, consider:\n\nPracticing with real-world projects to get hands-on experience.\nExploring advanced Git features such as rebasing, stash, and cherry-picking.\nLearning more about GitHub Actions to build robust CI/CD pipelines.\n\nBy mastering Git and GitHub, you will be well-equipped to manage code efficiently, collaborate seamlessly, and automate critical aspects of your ML and DevOps workflows.",
    "crumbs": [
      "DevOps",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Introduction to Git and GitHub</span>"
    ]
  },
  {
    "objectID": "11-devops-git.html#exercise",
    "href": "11-devops-git.html#exercise",
    "title": "11  Introduction to Git and GitHub",
    "section": "11.8 Exercise",
    "text": "11.8 Exercise\nYou just joined a data science team at a company, and they use Git and GitHub for collaboration. Your manager has asked you to set up your GitHub account, clone the team’s repository, and make your first contribution. To demonstrate this ability, execute the following tasks:\n\n\n\n\n\n\n1. Set Up Git and GitHub\n\n\n\n\n\n\nInstall Git on your machine.\nCreate a GitHub account if you haven’t already.\nConfigure Git with your name and email.\n\n\n\n\n\n\n\n\n\n\n2. Work with a Git Repository\n\n\n\n\n\n\nCreate a new repository on GitHub.\nClone the repository to your local machine.\nAdd a new file (e.g., hello_git.txt), write a short message inside, and commit the changes.\nPush your changes to GitHub.\n\n\n\n\n\n\n\n\n\n\n3. Branching and Pull Requests\n\n\n\n\n\n\nCreate a new branch called feature-update.\nModify an existing file or add a new file.\nCommit and push the changes to the feature-update branch.\nOpen a pull request on GitHub to merge your changes into main.\nMerge the pull request once approved.\n\n\n\n\n\n\n\n\n\n\n4. Exploring GitHub Actions (Bonus Task)\n\n\n\n\n\n\nAdd a GitHub Actions workflow file that runs a simple Python test on every push.\nObserve the automated workflow execution.\n\n\n\n\n\n\n\n\n\n\n5. Reflection Questions\n\n\n\n\n\n\nWhy is version control essential for collaborative coding?\nHow does Git help manage different versions of a project?\nWhat are the benefits of using GitHub for collaboration?\nHow does CI/CD improve software and model deployment?",
    "crumbs": [
      "DevOps",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Introduction to Git and GitHub</span>"
    ]
  },
  {
    "objectID": "12-human-side-of-ml.html",
    "href": "12-human-side-of-ml.html",
    "title": "12  The Human Side of ML Systems",
    "section": "",
    "text": "12.1 The Role of Humans in ML Systems\nMachine learning systems are often discussed in terms of algorithms, data pipelines, and infrastructure. However, behind every ML system are human decisions—decisions about what data to collect, how to frame a problem, which features to include, and how to evaluate success. The impact of these decisions extends far beyond technical performance; they influence trust, adoption, and the ethical implications of ML-driven systems.\nUnlike traditional software, machine learning models learn from data, which is inherently shaped by human biases, errors, and systemic patterns. As a result, deploying ML in real-world settings introduces risks that are not purely technical but are deeply connected to human behavior, organizational dynamics, and societal values.\nThis chapter explores the human elements of ML systems, from collaboration between teams and organizational challenges to bias, fairness, and accountability.\nBy understanding these aspects, ML practitioners can move beyond simply building high-performing models to developing responsible, interpretable, and trustworthy AI systems that work in harmony with human decision-making. Throughout this chapter, we’ll examine key challenges in collaboration, trust, interpretability, and ethics in ML systems and discuss best practices for building responsible AI.\nMachine learning is not just about algorithms—it is fundamentally shaped by human decisions at every stage, from problem definition to deployment. As we discussed in Chapter 2 - Before We Build, successful ML projects require strong collaboration with stakeholders to ensure that models solve the right problems, use appropriate data, and integrate effectively into business operations. Without human-centered planning, even technically sophisticated models can fail to deliver meaningful or ethical outcomes.\nThis section builds on those earlier discussions by examining how human judgment influences ML systems, the importance of cross-functional collaboration, and the role of human oversight in critical decision-making.\nThe Before We Build chapter emphasized the importance of engaging stakeholders early in the ML lifecycle but its important to understand that human decisions, collaboration, and oversight continue to shape ML systems throughout their entire lifecycle.\nML is not just about building accurate models — it’s about ensuring that those models are aligned with business goals, ethically sound, and adaptable to real-world challenges. Without strong collaboration and human oversight, even the most advanced ML models can fail in deployment.",
    "crumbs": [
      "Human Elements",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>The Human Side of ML Systems</span>"
    ]
  },
  {
    "objectID": "12-human-side-of-ml.html#the-role-of-humans-in-ml-systems",
    "href": "12-human-side-of-ml.html#the-role-of-humans-in-ml-systems",
    "title": "12  The Human Side of ML Systems",
    "section": "",
    "text": "Beyond the Algorithms: How Human Decisions Shape ML\n\n\n\n\n\nAs covered in Before We Build, framing the problem correctly is one of the most crucial steps in ML development. Decisions made at this stage, such as defining objectives, selecting data sources, and determining success criteria, will shape the entire ML pipeline. But even beyond problem framing, human judgment impacts ML systems in many ways:\n\nProblem Definition and Stakeholder Needs: In Before We Build, we emphasized working with domain experts to define the right problem. If an ML model optimizes for the wrong goal, it can have unintended consequences. For example, a loan approval model that prioritizes profitability might systematically exclude lower-income applicants rather than ensuring fair access to credit.\nData Collection and Labeling: The quality of ML models depends on the data they are trained on. Human decisions around what data to collect, how to clean it, and how to label it introduce potential biases. If training data is not representative of real-world scenarios, the model will struggle in production.\nFeature Selection and Model Design: In Before We Build, we discussed how involving stakeholders early helps ensure the model aligns with business needs. Data scientists also need to make intentional choices about which features to use and how to weigh different variables. For example, using ZIP codes in a model may unintentionally reinforce racial disparities in lending.\nEvaluation Metrics and Success Criteria: Choosing the right metrics is critical. If accuracy is the only consideration, the model might work well on average but fail for underrepresented groups. Instead, ML teams should balance multiple evaluation metrics—such as fairness, interpretability, and robustness—to ensure the model is truly effective.\n\nThese decisions highlight that ML is not just a technical challenge; it is a socio-technical system that requires careful design and collaboration.\n\n\n\n\n\n\n\n\n\nCollaboration Between Teams\n\n\n\n\n\nML projects involve more than just data scientists—they require strong coordination across teams to ensure success. In Before We Build, we discussed the importance of stakeholder engagement early in the process. Here, we expand on that idea by highlighting the different roles involved in ML deployment and why collaboration is critical:\n\nData Scientists: Develop and optimize models, ensuring they generalize well to new data.\nSoftware Engineers: Build and maintain the infrastructure to deploy models efficiently in production.\nBusiness Leaders & Product Managers: Define success metrics, assess risks, and ensure that ML aligns with business goals.\nDomain Experts: Provide essential knowledge about the problem space. For example, in healthcare, doctors validate whether an AI-powered diagnosis tool is medically sound.\n\nWithout strong collaboration, misalignment can occur. Data scientists may optimize for technical performance without considering deployment constraints, engineers may struggle to integrate ML models into production, and business leaders may not trust or understand ML-driven decisions.\nTo bridge these gaps, ML teams should:\n\nInvolve key stakeholders from the start to align expectations.\nEstablish clear documentation and shared workflows.\nRegularly communicate findings and concerns across teams.\n\n\n\n\n\n\n\n\n\n\nHuman-in-the-Loop Systems\n\n\n\n\n\nIn Before We Build, we discussed the need for stakeholder feedback before building ML models. However, in many cases, human oversight is also needed after deployment to ensure models remain effective and fair. Human-in-the-loop (HITL) systems combine automated predictions with human decision-making to improve accuracy and reliability.\nCommon examples of HITL systems include:\n\nActive Learning: Rather than labeling all training data upfront, models can request human labels for uncertain cases. This improves efficiency and ensures high-quality data. For example, a medical diagnosis AI might ask doctors to review edge cases where it has low confidence.\nReviewing Automated Decisions: In high-risk applications, models should support, not replace, human decision-makers. A loan approval model, for example, may flag high-risk applications, but a human underwriter makes the final decision.\nOverride Mechanisms: When an ML model produces unexpected results, human intervention should be possible. Fraud detection systems often wrongly flag legitimate transactions, requiring manual review to prevent customer frustration.\n\nBalancing automation with human oversight ensures that ML models remain trustworthy and adaptable. Instead of viewing ML as a fully autonomous system, organizations should design workflows where humans and models complement each other.",
    "crumbs": [
      "Human Elements",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>The Human Side of ML Systems</span>"
    ]
  },
  {
    "objectID": "12-human-side-of-ml.html#organizational-challenges-in-ml-adoption",
    "href": "12-human-side-of-ml.html#organizational-challenges-in-ml-adoption",
    "title": "12  The Human Side of ML Systems",
    "section": "12.2 Organizational Challenges in ML Adoption",
    "text": "12.2 Organizational Challenges in ML Adoption\nAdopting machine learning within an organization is not just a technical challenge, it’s also a cultural and operational one. While ML has the potential to drive innovation and efficiency, many organizations struggle to integrate it effectively. Success depends on fostering cross-functional collaboration, overcoming barriers to ML adoption, and scaling ML capabilities with the right strategies and infrastructure.\n\nCross-Functional Collaboration\nSuccessful ML adoption requires alignment between data science, engineering, business, and product teams. Each group brings unique expertise to the table, and without proper collaboration, ML initiatives can fail to translate into real business impact.\n\nProduct Managers: Define business objectives and ensure that ML initiatives align with user needs. They help set priorities, manage expectations, and connect data scientists with domain experts to ensure models solve the right problems.\nSoftware, ML Engineers & Data Scientists: Develop, deploy, and maintain ML models in production. Data scientists tend to focus more on training and optimizing models, while engineers ensure models are scalable, efficient, and integrated into real-world systems. Together, they implement best practices for model performance, monitoring, and retraining.\nBusiness & Domain Experts: Provide real-world context and assess the feasibility of ML applications. Their insights help refine problem definitions, validate assumptions, and interpret model outputs correctly.\n\nWhen these teams work in silos, ML projects risk failing due to misalignment between technical execution and business objectives. Strong cross-functional collaboration ensures that ML models are not just technically robust but also practical, scalable, and impactful.\n\n\n\n\n\n\nExamples of Misalignment\n\n\n\n\n\n\nMisaligned Optimization Goals: A recommendation system team optimizes for engagement by showing users the most-clicked content. However, the business team is concerned that this approach leads to lower customer satisfaction and retention. The data science team, unaware of this long-term impact, continues optimizing for short-term clicks, leading to unintended negative effects on the business.\nLack of Engineering Support for Deployment: A data science team develops a real-time fraud detection model, but engineering teams lack the infrastructure to support low-latency inference. Without early collaboration, the model remains stuck in Jupyter notebooks instead of being deployed into production, preventing the company from realizing any business value.\nOverlooking End-User Needs: A healthcare ML model predicts patient readmission risk, but doctors and nurses find the model’s explanations too complex and difficult to interpret in a clinical setting. If medical professionals had been involved earlier, the team could have designed a more interpretable model with clear decision-support insights instead of black-box predictions.\n\n\n\n\n\nBridging the Gaps\nEffective collaboration between data science, engineering, and business teams is essential for successfully integrating machine learning into an organization. However, misalignment often occurs when technical teams focus on model performance without considering business impact, or when business stakeholders expect ML solutions to work like traditional software. To bridge these gaps and create a seamless partnership, organizations can adopt the following strategies:\n\nCreate cross-functional teams where data scientists, engineers, and business leaders collaborate from the beginning of a project. Embedding ML engineers within business units or product teams fosters shared ownership of outcomes.\nEstablish shared objectives by aligning model performance metrics with business KPIs. Instead of focusing solely on accuracy, incorporate long-term business impact, usability, and risk considerations.\nDefine clear success criteria before development begins. Teams should document expected outputs, edge cases, and operational requirements to prevent misalignment later.\nDevelop communication protocols such as regular check-ins, joint planning sessions, and shared documentation to keep all stakeholders informed and aligned.\nEducate stakeholders on ML capabilities and limitations to set realistic expectations and ensure business teams understand how to interpret and use model outputs effectively.\n\nBy fostering better collaboration, organizations can ensure that ML initiatives are not only technically sound but also aligned with business needs and operational realities, maximizing their impact.\n\n\n\nBarriers to ML Adoption\nEven when an organization invests in machine learning, adoption is not always seamless. Many challenges—both technical and organizational—can prevent ML projects from delivering real value. Below are some of the most common barriers organizations face when integrating ML into their workflows.\n\n\n\n\n\n\nResistance to Change\n\n\n\n\n\nMachine learning often introduces new ways of working, which can be met with skepticism from employees who are used to traditional decision-making processes.\n\nFear of Job Displacement: Employees may worry that ML automation will replace their roles, leading to resistance in sharing domain expertise or adopting model-driven insights. For example, an ML-powered customer support chatbot might face pushback from human agents concerned about job security.\nLack of Technical Understanding: Decision-makers without an ML background might not trust model outputs, leading to underutilization of ML-driven recommendations. Business leaders may prefer intuitive, rule-based systems over seemingly opaque ML models.\nDisrupting Existing Workflows: ML models often challenge the status quo by surfacing insights that require new decision-making processes. If these changes are not carefully managed, employees may revert to manual methods, ignoring ML recommendations altogether.\n\n\n\n\n\n\n\n\n\n\nLack of Trust in ML-Driven Decision-Making\n\n\n\n\n\nFor machine learning to be effective, stakeholders must trust model predictions and understand when and how to act on them.\n\nBlack-Box Models: Many ML models, especially deep learning-based systems, lack transparency, making it difficult for business teams to trust their outputs. For example, an ML-powered loan approval model might reject an applicant without a clear explanation, causing frustration among loan officers and regulators.\nHistorical Bias in Data: If past decisions were biased, ML models trained on historical data can perpetuate or amplify unfairness. A hiring algorithm trained on historical resumes might unintentionally favor one demographic over another. Without careful oversight, organizations may be hesitant to adopt ML due to fairness concerns.\nInconsistent Model Performance: A model that performs well in a controlled testing environment may struggle in real-world settings due to shifting data distributions. If stakeholders experience unpredictable model behavior, they may lose confidence in ML systems altogether.\n\n\n\n\n\n\n\n\n\n\nThe Disconnect Between Technical and Business Teams\n\n\n\n\n\nMachine learning is not just a technical problem—it is a business solution. However, misalignment between data teams and business teams can derail ML adoption.\n\nMisaligned Expectations: Data scientists might optimize for accuracy, while business teams care more about interpretability or fairness. Without shared goals, ML projects may fail to gain traction.\nLack of ML Literacy in Business Units: Executives and domain experts may struggle to understand how ML models generate predictions or how to interpret model outputs, leading to low adoption rates. For example, a marketing team might hesitate to use an ML-based customer segmentation model if they don’t understand how it defines audience segments.\nDifficulty in Measuring ROI: Unlike traditional software projects, ML initiatives often have uncertain payoffs and require continuous retraining. Organizations that demand immediate and clear ROI may abandon ML projects before they have time to demonstrate value.\n\n\n\n\n\nOvercoming These Barriers\nTo increase ML adoption, organizations must focus on building trust, aligning teams, and demonstrating clear value. This requires proactive efforts to bridge the gap between technical teams and business stakeholders while ensuring transparency, usability, and continuous improvement.\n\n\n\n\n\n\nFoster a culture of ML literacy\n\n\n\n\n\nMany business leaders and decision-makers hesitate to adopt ML-driven solutions simply because they don’t fully understand how they work. Providing non-technical training on ML fundamentals, model limitations, and real-world applications helps stakeholders make informed decisions and trust the models. Hosting regular knowledge-sharing sessions and workshops can demystify ML and demonstrate its value.\n\n\n\n\n\n\n\n\n\nBuild interpretable models where possible\n\n\n\n\n\nBlack-box models can be a major roadblock to adoption, as stakeholders may be reluctant to use predictions they can’t explain. Leveraging explainability techniques like SHAP, LIME, and feature importance visualizations helps users understand how models arrive at their decisions. Ensuring that ML outputs are interpretable builds credibility and increases stakeholder buy-in.\n\n\n\n\n\n\n\n\n\nPilot ML solutions in low-risk environments\n\n\n\n\n\nOrganizations can gain confidence in ML by starting small — deploying models in controlled, low-risk settings before scaling them to critical business processes. For example, testing a demand forecasting model in a single region before rolling it out company-wide allows teams to refine performance and address any unforeseen issues without major business disruptions.\n\n\n\n\n\n\n\n\n\nCreate cross-functional teams\n\n\n\n\n\nEmbedding business stakeholders into ML development from the start ensures that models are aligned with actual business needs. Product managers, domain experts, and analysts should collaborate with data scientists and engineers to define success metrics, validate assumptions, and ensure that ML solutions address real-world problems.\n\n\n\n\n\n\n\n\n\nMonitor and iterate\n\n\n\n\n\nML adoption isn’t a one-time event—it’s an evolving process that requires continuous refinement. Setting up feedback loops, tracking model performance, and making iterative improvements based on user feedback helps build trust and ensures that models remain relevant and useful over time. Establishing clear monitoring and governance practices ensures that ML systems continue to meet business objectives.\n\n\n\nBy addressing these barriers, organizations can unlock the full potential of ML, transforming it from an experimental capability into a trusted and widely adopted tool for decision-making.\n\n\n\nScaling ML in an Organization\nSuccessfully adopting ML at scale requires more than just deploying models—it involves creating an environment where ML can continuously evolve, integrate with business processes, and deliver long-term value. This means establishing the right infrastructure, governance, and culture to ensure ML initiatives are both sustainable and impactful. Without a systematic approach, ML efforts can remain isolated, difficult to maintain, and ultimately fail to provide consistent business value.\n\nBuilding an ML Culture\nScaling ML isn’t just about technology—it requires organizational alignment and a shift in mindset to ensure that machine learning is embraced across teams. A strong ML culture helps to break down silos, align stakeholders, and ensure that ML-driven insights are trusted and used effectively. Organizations can cultivate an ML culture by:\n\n\n\n\n\n\nEducating teams on ML’s capabilities and limitations\n\n\n\n\n\nOrganizations should provide ML literacy training for non-technical teams, including business leaders, product managers, and decision-makers. By helping teams understand how ML models work, their assumptions, and their limitations, organizations can build trust in ML-based decision-making and set realistic expectations.\n\n\n\n\n\n\n\n\n\nEncouraging experimentation in a controlled environment\n\n\n\n\n\nEstablishing ML innovation labs or sandbox environments allows teams to test ML ideas in low-risk settings before full-scale deployment. Encouraging iterative experimentation—where teams can try new models, datasets, and feature engineering techniques without disrupting core business functions—fosters a culture of learning and continuous improvement.\n\n\n\n\n\n\n\n\n\nIntegrating ML into decision-making processes\n\n\n\n\n\nTo make ML an integral part of business operations, organizations should embed ML models directly into business workflows and decision-support systems. This means ensuring ML outputs are accessible through dashboards, APIs, or business intelligence tools where stakeholders can easily interact with them. It also requires ongoing evaluation to ensure that the models remain aligned with business objectives.\n\n\n\nBy proactively building an ML culture, organizations move beyond treating ML as a series of disconnected projects and instead integrate it as a core competency that drives innovation and efficiency across the enterprise.\n\n\nSetting Up an Effective MLOps Practice\nTo scale ML effectively, organizations need consistent, standardized processes that govern the entire ML lifecycle. Without standardization, teams across different business units may develop their own inconsistent, one-off solutions for data ingestion, model experimentation, deployment, and monitoring—leading to inefficiencies, redundant work, and challenges in governance.\nThroughout this book, we have covered DataOps, ModelOps, and DevOps concepts that guide best practices in managing machine learning systems. To truly scale ML, organizations must move beyond individual teams developing custom solutions and instead establish enterprise-wide MLOps frameworks that provide:\n\n\n\n\n\n\nStandardized data pipelines and feature stores\n\n\n\n\n\nA centralized feature store and well-defined data processing pipelines ensure that all ML teams work with high-quality, versioned, and accessible data rather than duplicating data wrangling efforts across multiple projects.\n\n\n\n\n\n\n\n\n\nA unified model experimentation and versioning framework\n\n\n\n\n\nBy adopting common tools for model tracking, versioning, and governance, such as MLflow or DVC, organizations eliminate fragmented experimentation workflows and create a structured model registry where teams can reuse models, compare versions, and maintain lineage across deployments.\n\n\n\n\n\n\n\n\n\nEnterprise-level CI/CD for ML models\n\n\n\n\n\nRather than deploying models manually, organizations should automate model validation, testing, and deployment pipelines to ensure smooth transitions from development to production. This reduces human error and ensures that new models are deployed efficiently, with minimal downtime.\n\n\n\n\n\n\n\n\n\nScalable monitoring and alerting for deployed models\n\n\n\n\n\nA robust model monitoring system should track data drift, concept drift, model performance degradation, and operational metrics. Standardizing monitoring practices across teams ensures consistency in detecting issues early and retraining models proactively.\n\n\n\nStandardizing these MLOps processes across the enterprise, organizations create a scalable, maintainable, and efficient ML infrastructure that allows ML teams to focus on innovation rather than constantly reinventing foundational processes.\nBy investing in both cultural and operational transformation, organizations set themselves up for long-term ML success—ensuring that machine learning is not just a research exercise, but a scalable, value-driven business capability.",
    "crumbs": [
      "Human Elements",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>The Human Side of ML Systems</span>"
    ]
  },
  {
    "objectID": "12-human-side-of-ml.html#interpretability-fairness-and-ethical-considerations-in-ml",
    "href": "12-human-side-of-ml.html#interpretability-fairness-and-ethical-considerations-in-ml",
    "title": "12  The Human Side of ML Systems",
    "section": "12.3 Interpretability, Fairness, and Ethical Considerations in ML",
    "text": "12.3 Interpretability, Fairness, and Ethical Considerations in ML\nAs machine learning systems increasingly influence real-world decisions—whether in hiring, healthcare, finance, or criminal justice—questions about their transparency, fairness, and ethical implications have become more urgent. While powerful ML models can drive business value and efficiency, they also introduce risks, such as biased decision-making, lack of interpretability, and unintended consequences.\nThis section explores the importance of interpretable and fair ML systems, the challenges organizations face in achieving these goals, and the strategies that can be used to enhance model transparency, mitigate bias, and adhere to ethical and regulatory standards. Ensuring that ML models are not only technically sound but also aligned with human values, legal requirements, and societal expectations is key to responsible ML adoption.\n\nWhy Interpretability and Fairness Matter\nMachine learning models are often deployed to assist or automate decision-making in high-stakes applications such as lending, hiring, medical diagnostics, and criminal justice. In these contexts, interpretability and fairness are not just technical considerations—they are essential for ensuring trust, accountability, and ethical responsibility.\n\n\n\n\n\n\nBuilding Stakeholder Trust\n\n\n\n\n\nFor machine learning to be widely adopted, stakeholders—whether business leaders, regulators, or end-users—must trust the outputs of these models. Black-box models that make predictions without clear explanations can lead to skepticism and resistance. Interpretability helps bridge this gap by providing insights into how a model makes decisions, allowing stakeholders to understand and verify the reasoning behind predictions.\n\n\n\n\n\n\n\n\n\nDebugging and Improving Models\n\n\n\n\n\nInterpretability is also crucial for improving model performance. If a model is underperforming or making unexpected predictions, data scientists need to diagnose issues and refine it. Understanding which features influence predictions the most can help teams detect biases, data errors, or flaws in the model design. Without interpretability, debugging an ML system becomes a trial-and-error process with little visibility into the root causes of failures.\n\n\n\n\n\n\n\n\n\nEnsuring Fairness and Preventing Bias\n\n\n\n\n\nFairness in machine learning refers to the principle that models should not systematically disadvantage certain groups or individuals. However, bias can creep into models in multiple ways—through imbalanced training data, historical discrimination, or unintended correlations between features and sensitive attributes. Without careful monitoring and explainability techniques, biased models can reinforce and amplify societal inequities.\n\n\n\n\n\n\n\n\n\nMeeting Regulatory and Ethical Standards\n\n\n\n\n\nMany industries operate under strict regulatory requirements that mandate explainability and fairness in automated decision-making. Regulations such as the General Data Protection Regulation (GDPR) and the California Consumer Privacy Act (CCPA) require organizations to provide transparency into algorithmic decisions that impact individuals. Additionally, ethical ML frameworks emphasize fairness, accountability, and transparency, making it critical for organizations to proactively assess their models for compliance.\n\n\n\nBy prioritizing interpretability and fairness, organizations can develop ML systems that are not only accurate and efficient but also responsible and aligned with societal and legal expectations. The next sections will explore methods for enhancing model explainability, mitigating bias, and implementing fairness-aware machine learning techniques.\n\n\nChallenges in ML Interpretability and Trust\nWhile interpretability and fairness are essential for building responsible machine learning systems, achieving them is not always straightforward. Many challenges arise when trying to balance model accuracy, explainability, and fairness, particularly as ML models become more complex and are deployed in real-world settings.\n\n\n\n\n\n\nThe Black-Box Nature of Complex Models\n\n\n\n\n\nSome of the most powerful machine learning models, such as deep learning neural networks and ensemble methods, are inherently difficult to interpret. These models contain millions of parameters and rely on intricate relationships between features, making it nearly impossible to explain their predictions in simple terms. While simpler models like decision trees or linear regression are more interpretable, they often lack the predictive power needed for many tasks. This creates a trade-off between accuracy and interpretability, forcing teams to decide how much transparency they are willing to sacrifice for performance.\n\n\n\n\n\n\n\n\n\nVariability in Interpretability Methods\n\n\n\n\n\nDifferent techniques exist to explain ML models, but they do not always provide consistent results. Feature importance scores, for example, can vary based on the method used (e.g., SHAP, LIME, permutation importance). This variability can make it difficult to determine which explanations are the most reliable. Additionally, different stakeholders require different levels of interpretability—what makes sense to a data scientist may not be meaningful to a business executive or a regulator.\n\n\n\n\n\n\n\n\n\nTrusting Model Explanations\n\n\n\n\n\nEven when explainability techniques are used, they do not always guarantee trust in ML decisions. For example, a model may highlight the most important features used in a prediction, but this does not mean those features are used correctly or fairly. Interpretability methods can also be manipulated to provide misleading or overly simplistic explanations, creating a false sense of transparency.\n\n\n\n\n\n\n\n\n\nDealing with Unexpected Model Behavior\n\n\n\n\n\nMachine learning models can behave unpredictably when faced with new or out-of-distribution data. A model trained on one dataset may generalize poorly when deployed in a different setting, leading to surprising and sometimes harmful decisions. This unpredictability raises concerns about whether models should be fully automated or require human oversight. In high-risk applications like healthcare or finance, errors can have serious consequences, making model monitoring and human-in-the-loop approaches essential.\n\n\n\n\n\n\n\n\n\nLack of Standardized Interpretability and Fairness Metrics\n\n\n\n\n\nUnlike accuracy, which is easy to quantify, there is no universal metric for interpretability or fairness. Various fairness metrics exist, such as disparate impact, equalized odds, and demographic parity, but different contexts require different definitions of fairness. Organizations must decide which fairness criteria are most appropriate for their use case, which can be a complex and subjective decision.\n\n\n\n\n\n\n\n\n\nBalancing Trade-Offs Between Accuracy, Fairness, and Explainability\n\n\n\n\n\nIn many cases, optimizing for one aspect of an ML system comes at the expense of another. Improving model accuracy may require using more complex models, reducing interpretability. Making a model more fair may slightly reduce its overall performance. Organizations must carefully navigate these trade-offs to ensure their ML systems are both effective and responsible.\n\n\n\n\n\n\n\n\n\nStakeholder Resistance to ML Decision-Making\n\n\n\n\n\nEven when a model is interpretable and fair, there can still be resistance from stakeholders who are uncomfortable with algorithmic decision-making. Business leaders, regulators, and customers may be hesitant to trust AI-driven processes, particularly if they replace human decision-makers. Transparent communication, clear documentation, and demonstrable improvements over existing decision-making methods are crucial for overcoming this resistance.\n\n\n\nAddressing these challenges requires a thoughtful approach that combines technical solutions with ethical considerations. In the next sections, we will explore methods to improve explainability, mitigate bias, and design ML systems that foster trust and fairness in decision-making.\n\n\nCommon Sources of Bias and Unfairness in ML Models\nMachine learning models are only as good as the data they learn from, and unfortunately, data is often shaped by historical, societal, and systemic biases. When these biases go undetected, they can lead to unfair or even harmful outcomes, disproportionately affecting certain groups.\nBias in ML can emerge at multiple stages of the model lifecycle — from data collection and feature selection to algorithmic decision-making and deployment. Addressing these biases is not just a technical challenge but also an ethical imperative, especially in high-stakes applications like hiring, lending, law enforcement, healthcare, and financial services.\n\n\n\n\n\n\nBias in machine learning refers to systematic errors in model predictions that unfairly favor or disadvantage certain groups.\nML models are often deployed in settings where their decisions can significantly impact people’s lives. A biased model can reinforce existing inequalities, create unintended discrimination, or produce inaccurate predictions that lead to poor decision-making. The challenge is that bias is not always easy to detect, and even models trained on seemingly neutral data can exhibit biased behaviors.\n\n\n\n\nBias in Data Collection and Preprocessing\nBias can be introduced into machine learning models before training even begins, during data collection and preprocessing. If the data used for training is systematically flawed, the resulting models will inherit and reinforce these biases, leading to unfair predictions and real-world harm. Below are three key types of bias that often emerge at this stage.\n\n\n\n\n\n\nMeasurement Bias\n\n\n\n\n\nMeasurement bias occurs when the way data is collected systematically disadvantages certain groups due to faulty or non-representative measurement techniques. This can arise from:\n\nDevice Calibration Issues: Many medical sensors and wearable health devices are calibrated based on data collected from a limited demographic. For example, pulse oximeters, widely used in hospitals, have been found to overestimate blood oxygen levels in patients with darker skin tones, leading to disparities in healthcare treatment.\n\n📖 Read More: Racial Bias in Pulse Oximetry Measurement (New England Journal of Medicine).\n\nSurvey and Reporting Bias: If data is collected through surveys or self-reports, different groups may respond differently due to cultural factors, social pressures, or language barriers, skewing results in ways that do not reflect reality.\n\nWhen measurement bias is present, the model is trained on flawed or systematically skewed data, which can lead to misdiagnosis in healthcare, unfair lending decisions, and other harmful outcomes.\n\n\n\n\n\n\n\n\n\nProxy Variables and Hidden Bias\n\n\n\n\n\nSometimes, seemingly neutral features in a dataset act as hidden proxies for sensitive attributes like race, gender, or socioeconomic status. These features may not be explicitly discriminatory but strongly correlate with protected characteristics, leading to biased predictions.\n\nExample: ZIP Codes as Proxies for Race: Some U.S. cities remain racially and economically segregated, so a ZIP code can unintentionally serve as a proxy for race or socioeconomic status. If a model uses ZIP code to determine loan approvals or insurance rates, it may unintentionally discriminate against minority communities.\n\n📖 Read More: The Racial Bias Built Into Mortgage Algorithms (Bloomberg).\n\nExample: Names as Proxies for Gender or Ethnicity: Models trained on resume data may learn that certain names (e.g., “Emily” vs. “Jamal”) correlate with hiring decisions, reinforcing existing hiring biases.\n\n📖 Read More: Are Emily and Greg More Employable than Lakisha and Jamal? (National Bureau of Economic Research).\n\n\nWithout careful feature selection and fairness audits, models can perpetuate hidden biases even when explicitly sensitive attributes are removed from the dataset.\n\n\n\n\n\n\n\n\n\nImbalanced Datasets\n\n\n\n\n\nAn imbalanced dataset occurs when certain groups are underrepresented, leading to models that fail to generalize well across all populations. When collected data If a machine learning model is trained on non-representative data, it may struggle to make accurate predictions for underrepresented groups.\n\nExample: Facial Recognition Bias: Studies have shown that commercial facial recognition systems perform significantly worse on women and people with darker skin tones because the training datasets primarily contained images of white males.\n\n📖 Read More: Gender Shades: Intersectional Accuracy Disparities in Commercial Gender Classification (Proceedings of Machine Learning Research).\n\nExample: Healthcare AI Gaps: Many medical AI models are trained on historical patient data that underrepresents certain demographic groups, leading to misdiagnoses and lower-quality healthcare recommendations for minorities and women.\n\n📖 Read More: Disparities in Machine Learning-Based Medical Decision Making (Nature Digital Medicine).\n\n\nAddressing dataset imbalances requires intentional data collection strategies, such as oversampling underrepresented groups, re-weighting training data, or using fairness-aware machine learning techniques.\n\n\n\n\n\nBias in Training Data\nEven when data is collected with the best intentions, bias can persist during the training phase, leading to models that reinforce existing inequalities. Training data reflects historical patterns, and without careful curation, machine learning models can encode and perpetuate these biases. Below are key types of biases that emerge during training.\n\n\n\n\n\n\nHistorical Bias\n\n\n\n\n\nHistorical bias occurs when past societal inequalities are reflected in training data, even if the data was collected correctly. This means models trained on such data will reproduce past patterns of discrimination, making fairness a challenge.\n\nExample: Gender Bias in Hiring Models: If a hiring model is trained on decades of historical hiring data, it may learn patterns that favor men over women for technical roles due to past hiring discrimination.\n\n📖 Read More: Amazon Scraps AI Recruiting Tool That Showed Bias Against Women (Reuters).\n\nExample: Credit Lending Discrimination: Historically, minority communities have been denied loans at higher rates due to redlining and systemic bias. If a loan approval model is trained on past banking decisions, it may unfairly penalize minority applicants.\n\nRelated Issue: This connects with proxy variables and hidden bias, where ZIP codes or past income levels serve as indirect signals of race or socioeconomic status, leading to discriminatory lending outcomes.\n\n\nHistorical bias is particularly difficult to mitigate because it is deeply embedded in the patterns of past decisions. Addressing it requires proactive interventions such as re-weighting training data, using fairness constraints, and auditing feature selection.\n\n\n\n\n\n\n\n\n\nSampling Bias\n\n\n\n\n\nSampling bias occurs when the training data is not representative of the population that the model will be applied to. As a result, the model generalizes poorly to underrepresented groups, leading to higher error rates for certain demographics.\n\nExample: Facial Recognition Bias: Commercial facial recognition systems have been shown to misidentify darker-skinned individuals at much higher rates than lighter-skinned individuals. This is because training datasets were disproportionately composed of white male faces.\n\n📖 Read More: Gender Shades: Intersectional Accuracy Disparities in Commercial Gender Classification (Proceedings of Machine Learning Research).\nRelated Issue: This bias is closely linked to imbalanced datasets in the data collection phase, where certain groups were under-sampled during dataset construction.\n\nExample: Healthcare AI Models: Many AI-driven diagnostic tools struggle with accuracy for women and minority patients because medical training datasets historically underrepresented these groups.\n\n📖 Read More: Disparities in Machine Learning-Based Medical Decision Making (Nature Digital Medicine).\n\n\nTo combat sampling bias, organizations must diversify their datasets, use data augmentation techniques, and apply fairness-aware sampling strategies to ensure all groups are adequately represented.\n\n\n\n\n\n\n\n\n\nLabel Bias\n\n\n\n\n\nLabel bias occurs when the labels used to train a model contain human biases or reflect subjective judgments, leading to skewed learning patterns.\n\nExample: Bias in Sentiment Analysis: AI models trained to detect “toxic speech” have been found to unfairly flag dialects associated with African American English (AAE) as more offensive than Standard American English. This happens because human annotators may unconsciously associate informal speech patterns with negativity.\n\n📖 Read More: Racial Disparities in Automated Speech Moderation (ArXiv Preprint).\nRelated Issue: Measurement bias during data collection may have led to skewed annotations, where annotators’ subjective opinions influenced the labels.\n\nExample: Political Bias in News Classification: News classification models trained on biased datasets may label articles from one political ideology as more “factual” than others, depending on the dataset composition and labeling process.\n\nSince labels define the learning objective of a model, biased labels result in systematic discrimination. Strategies to mitigate label bias include blind annotations, diverse annotator pools, and fairness audits of labeled data.\n\n\n\n\n\nAlgorithmic and Model-Induced Bias\nEven when data collection and training processes are carefully managed, bias can still emerge from the model itself. Machine learning algorithms are not inherently fair; they optimize for accuracy based on available data, and without explicit fairness constraints, they may amplify biases. Below are three major ways in which algorithmic and model-induced bias can manifest.\n\n\n\n\n\n\nFeature Selection Bias\n\n\n\n\n\nFeature selection bias occurs when certain input variables disproportionately influence predictions, often because they correlate with sensitive attributes like race, gender, or socioeconomic status. Even when protected attributes are explicitly removed, other variables can serve as proxies, leading to biased outcomes.\n\nExample: ZIP Codes and Racial Bias in Lending: Many financial institutions prohibit the use of race in loan approval models, but ZIP code can act as an indirect proxy for race due to historical housing segregation. If a model assigns lower creditworthiness to individuals based on ZIP code, it may systematically disadvantage minority communities, reinforcing discriminatory lending practices.\n\n📖 Read More: The Racial Bias Built Into Mortgage Algorithms (Bloomberg).\nRelated Issue: This ties back to proxy variables and hidden bias discussed in the Bias in Data Collection and Preprocessing section.\n\nExample: Gender Bias in Hiring Models: Some hiring algorithms use word embeddings trained on historical job postings. Since past hiring practices favored men for technical roles, models trained on resume screening data may assign higher scores to male candidates, even if gender is excluded as a direct feature.\n\n📖 Read More: Bias in Word Embeddings (ArXiv Preprint).\n\n\nTo mitigate feature selection bias, organizations should:\n\nConduct fairness audits to detect unintended correlations between features and sensitive attributes.\nUse fairness-aware feature selection techniques, such as removing or re-weighting biased features.\nApply explainability tools like SHAP or LIME to ensure no single feature disproportionately drives predictions.\n\n\n\n\n\n\n\n\n\n\nOverfitting to Majority Groups\n\n\n\n\n\nWhen models are trained on imbalanced datasets, they tend to optimize for the majority group, leading to poor generalization for underrepresented populations. This is often a result of sampling bias during data collection, where certain groups are underrepresented in the training data.\n\nExample: Facial Recognition Accuracy Disparities: A 2018 study found that facial recognition systems had error rates of less than 1% for white males but over 30% for Black women. The models were trained primarily on lighter-skinned individuals, causing them to overfit to the majority demographic and fail on darker-skinned individuals.\n\n📖 Read More: Gender Shades: Intersectional Accuracy Disparities in Commercial Gender Classification (Proceedings of Machine Learning Research).\nRelated Issue: This connects to sampling bias in the Bias in Training Data section, where training datasets fail to capture real-world diversity.\n\nExample: Healthcare AI Models Misdiagnosing Minorities: Many medical AI systems are trained on historical hospital data, which often contains fewer examples from minority populations. As a result, risk prediction models for diseases like skin cancer and heart disease underperform for non-white patients, leading to lower-quality care.\n\n📖 Read More: Algorithmic Bias in Health Care (Science).\n\n\nTo address overfitting to majority groups, organizations can:\n\nBalance datasets using oversampling, re-weighting, or data augmentation for underrepresented groups.\nUse group fairness metrics (e.g., disparate impact, equalized odds) to assess performance across subpopulations.\nApply debiasing techniques such as adversarial reweighting or fairness-aware loss functions.\n\n\n\n\n\n\n\n\n\n\nAlgorithmic Reinforcement of Bias\n\n\n\n\n\nBias in machine learning models doesn’t just persist—it can compound over time through feedback loops, where model predictions influence future data collection and decision-making. When models make biased predictions, those predictions shape new training data, reinforcing existing disparities.\n\nExample: Predictive Policing and Racial Profiling: Predictive policing models use historical crime data to forecast where crimes are likely to occur. However, if past policing practices disproportionately targeted minority neighborhoods, the model learns these patterns and directs more police resources to those areas, reinforcing systemic biases.\n\n📖 Read More: The Dirty Secret of Predictive Policing (The Verge).\n\nExample: Bias in Automated Hiring Systems: Resume screening algorithms often prioritize candidates based on previous hiring data. If companies historically hired more men than women, the algorithm learns to prefer male candidates, further reducing the number of women in the hiring pool. Over time, this creates a self-reinforcing cycle where women receive fewer job opportunities.\n\n📖 Read More: Amazon’s Biased Hiring Algorithm (Reuters).\n\n\nTo break algorithmic reinforcement of bias, organizations should:\n\nContinuously monitor model performance over time using fairness-aware evaluation metrics.\nIntroduce human-in-the-loop interventions, where decision-makers override biased predictions when necessary.\nPeriodically retrain models using debiased datasets to reduce bias drift.\n\n\n\n\n\n\nBias in Model Evaluation and Deployment\nEven when models are trained on seemingly fair and representative data, bias can still emerge during evaluation and deployment. If not addressed, these biases can result in unfair or harmful real-world consequences. Below are four key ways bias can appear during this stage, along with real-world examples illustrating their impact.\n\n\n\n\n\n\nUnequal Performance Across Groups\n\n\n\n\n\nMachine learning models often perform better for some demographic groups than others, leading to disparities in accuracy, precision, recall, or F1-score. When models are optimized for overall accuracy, they may fail to detect performance gaps across subpopulations, disproportionately harming underrepresented groups.\n\nExample: Facial Recognition Disparities: A study on commercial facial recognition systems found that error rates were significantly higher for darker-skinned individuals compared to lighter-skinned individuals. While white male faces were misclassified at a rate of only 0.8%, the error rate for Black women was as high as 34.7%. This unequal performance can have serious consequences, such as wrongful arrests due to misidentification.\n\n📖 Read More: Gender Shades: Intersectional Accuracy Disparities in Commercial Gender Classification.\n\nExample: Healthcare Risk Scores: A widely used healthcare risk prediction model systematically underestimated the needs of Black patients. The model used healthcare spending as a proxy for a patient’s medical risk, but because Black patients historically had less access to healthcare, they appeared “healthier” than they actually were. This led to fewer Black patients being flagged for extra medical care, exacerbating healthcare inequalities.\n\n📖 Read More: Racial Bias in a Healthcare Algorithm.\n\n\nTo address unequal performance across groups, organizations should:\n\nMeasure model performance across subgroups using fairness-aware metrics (e.g., equalized odds, disparate impact).\nAdjust decision thresholds or model architectures to improve fairness for underperforming groups.\nConsider alternative fairness-aware objectives when training models.\n\n\n\n\n\n\n\n\n\n\nDecision Threshold Bias\n\n\n\n\n\nML models often apply a single decision threshold across all groups, but different subpopulations may require different thresholds for optimal fairness. If a uniform threshold is used, it can unintentionally favor or disadvantage certain groups.\n\nExample: Credit Scoring and Loan Approvals: Credit scoring models assess loan applicants based on a risk threshold. However, studies have shown that Black and Hispanic borrowers are often denied loans at higher rates than white borrowers, despite similar financial profiles. A one-size-fits-all threshold fails to account for historical disparities in credit access.\n\n📖 Read More: Algorithmic Bias in Lending.\n\nExample: Predicting College Success: Some universities use ML models to predict student dropout risk. However, first-generation college students may require a different prediction threshold than students from families with a history of higher education. Without adjustments, these models can disproportionately flag first-generation students as “high-risk,” leading to unfair interventions.\n\n📖 Read More: Algorithmic Decision-Making in Higher Education (Data & Society).\n\n\nTo mitigate decision threshold bias, organizations can:\n\nCalibrate separate thresholds for different groups to ensure fair treatment.\nUse fairness-aware decision-making frameworks, such as equalized odds or demographic parity.\nImplement post-processing adjustments to mitigate disparities without retraining models.\n\n\n\n\n\n\n\n\n\n\nContextual Bias\n\n\n\n\n\nModels trained in one environment may fail to generalize fairly when applied to a different context. Differences in culture, policies, economic conditions, or demographics can cause models to make incorrect or biased predictions in new settings.\n\nExample: Credit Scoring Across Countries: A credit risk model trained on U.S. financial data performed poorly when applied to loan applicants in South Africa. The model did not account for different credit behaviors, financial regulations, and economic conditions, leading to higher rejection rates for qualified South African applicants.\n\n📖 Read More: Machine Learning and Credit Risk in Emerging Markets.\n\n\nTo address contextual bias, organizations should:\n\nConduct fairness audits before deploying models in new environments.\nUse domain-specific knowledge to adapt models to regional or cultural contexts.\nRegularly retrain models using locally relevant data.\n\n\n\n\n\n\n\n\n\n\nFeedback Loops in Production\n\n\n\n\n\nML models influence the data they later receive, creating reinforcing feedback loops that amplify biases over time. If not monitored, these loops can compound existing inequalities in ways that may be difficult to reverse.\n\nExample: Social Media Recommendation Algorithms: Social media platforms use recommendation algorithms to maximize engagement, but this often leads to users being fed increasingly extreme or biased content. Studies have shown that YouTube’s recommendation system can push users toward more radical political videos over time by continually reinforcing their existing preferences. This feedback loop amplifies misinformation and ideological echo chambers.\n\n📖 Read More: Algorithmic Radicalization on YouTube (MIT Technology Review).\n\nExample: AI in Hiring and Performance Reviews: Some companies use AI-powered performance review systems that predict employee success based on past evaluations. If historical biases favored certain groups, the AI may continue rewarding the same groups, reinforcing existing workplace inequalities.\n\n📖 Read More: The Dangers of AI in Hiring and Employee Evaluation (Harvard Business Review).\n\n\nTo prevent harmful feedback loops, organizations can:\n\nMonitor and audit deployed models for unintended consequences over time.\nIntroduce human-in-the-loop interventions, where decision-makers override biased predictions when necessary.\nPeriodically retrain models using new, unbiased data to prevent bias from accumulating.\n\n\n\n\n\n\n\nEthical Considerations and Regulatory Compliance\nAs ML systems become integral to decision-making in healthcare, finance, hiring, and public services, ensuring they operate ethically and legally is a pressing concern. Regulatory frameworks, transparency requirements, and fairness audits are designed to help prevent harmful consequences of ML, such as discriminatory loan approvals, biased hiring models, or privacy violations.\nFor ML practitioners, understanding and adhering to regulations is not just a legal requirement, it’s an ethical responsibility. Failure to comply can lead to legal repercussions, reputational damage, and financial penalties, but more importantly, it can erode public trust in ML.\n\n\n\n\n\n\nRegulations are designed to ensure fairness, privacy, and accountability in ML-driven decision-making. Without oversight, ML systems can perpetuate discrimination, exploit personal data, and make unchallengeable, opaque decisions.\nFor example:\n\nA hiring algorithm trained on biased historical data may systematically reject qualified candidates from certain demographic groups.\nA predictive policing model could reinforce systemic biases, disproportionately targeting minority communities.\nAn ML-powered lending system might unfairly deny loans based on ZIP code, unintentionally acting as a proxy for race or socioeconomic status.\n\nRegulations help mitigate these risks by setting standards for data protection, fairness, and transparency. As ML governance continues to evolve, ML teams must stay informed to ensure compliance and responsible development.\n\n\n\n\nMajor ML Regulations: GDPR, CCPA, and Beyond\nSeveral key regulations shape how machine learning models handle data privacy, fairness, and transparency. These regulations ensure that ML systems are designed to protect user rights, prevent discrimination, and operate transparently. Different regions have introduced their own legal frameworks, but they all share common goals — giving users control over their data, ensuring models make fair and explainable decisions, and preventing harmful biases.\n\n\n\n\n\n\nGeneral Data Protection Regulation (GDPR) (European Union)\n\n\n\n\n\nGDPR enforces strict privacy rights and transparency in data processing. It is particularly relevant for ML practitioners because it requires:\n\nRight to explanation: Users can request an explanation of algorithmic decisions affecting them.\nData protection and consent: ML models that process personal data must have explicit user consent.\nFairness and non-discrimination: Discriminatory models based on race, gender, or other protected attributes can violate GDPR.\n\n📖 Read More: GDPR Guidelines on Automated Decision-Making.\n\n\n\n\n\n\n\n\n\nCalifornia Consumer Privacy Act (CCPA) (United States)\n\n\n\n\n\nCCPA provides similar privacy protections but focuses on consumer rights and transparency. It is relevant to ML teams working with customer data because:\n\nUsers can opt out of data collection or automated decision-making.\nBusinesses must disclose how ML models use consumer data.\nDiscriminatory practices based on data access are prohibited.\n\n📖 Read More: California Consumer Privacy Act Summary.\n\n\n\n\n\n\n\n\n\nOther emerging ML governance frameworks include:\n\n\n\n\n\n\nThe EU AI Act: Proposes risk-based ML regulation, banning high-risk models (e.g., social scoring).\nThe U.S. AI Bill of Rights: Establishes ML fairness, privacy, and transparency principles.\n\n\n\n\nFor ML practitioners, staying informed on evolving regulations is crucial because:\n\nRegulations shape model design: ML systems must be designed with compliance in mind, not as an afterthought.\nFailure to comply leads to legal and financial risks: Fines for GDPR violations can reach 4% of a company’s annual revenue.\nCompliance drives user trust: Organizations that prioritize fairness and transparency build stronger relationships with consumers and stakeholders.\n\n\n\nThe Role of Audits, Documentation, and Transparency\nBeyond legal requirements, transparent ML development fosters trust and ethical responsibility. Organizations should implement fairness audits, model documentation, and explainability practices to ensure that their models operate fairly and can be understood by both technical and non-technical stakeholders.\n\n\n\n\n\n\nAudits for Fairness and Bias\n\n\n\n\n\n\nRegular bias audits help prevent unintended discrimination. Bias can emerge at any stage of an ML pipeline. Routine audits assess model predictions across demographic groups, using fairness metrics to detect disparities before they cause harm.\nFairness evaluations throughout the ML lifecycle improve accountability. Evaluating fairness at multiple stages—data preprocessing, model training, and post-deployment—helps mitigate bias. This includes checking for imbalanced datasets, assessing disparate impact, and monitoring for bias drift over time.\nExample: A financial institution auditing its loan approval model for fairness. To comply with regulations like the Equal Credit Opportunity Act (ECOA) and GDPR, banks conduct fairness audits to ensure loan approvals don’t systematically disadvantage certain groups. These audits help detect biases in credit scoring and refine decision thresholds when needed.\n\n\n\n\n\n\n\n\n\n\nModel Documentation and Explainability\n\n\n\n\n\n\nDatasheets for datasets provide transparency in data collection. These standardized documents outline how data was collected, potential biases, preprocessing steps, and intended use cases, helping ML teams assess risks before training models.\nModel cards summarize key model details for responsible deployment. They include information on a model’s purpose, performance across different groups, limitations, and fairness considerations, ensuring stakeholders understand its capabilities and risks.\nExample: Google’s model cards improve accountability in ML models. Google introduced model cards to document important details such as evaluation metrics, fairness concerns, and recommended usage, making it easier for regulators and stakeholders to assess model impact.\n\n📖 Read More: Google’s Model Cards.\n\n\n\n\n\n\n\n\n\nTransparency and User Rights\n\n\n\n\n\n\nUsers should understand how ML-driven decisions impact them. Organizations must provide clear explanations of automated decisions, especially when they affect critical areas like hiring, lending, or healthcare.\nExample: Transparent hiring decisions promote fairness. If an ML-based hiring system rejects an applicant, it should explain why—such as missing qualifications—rather than making opaque, unaccountable decisions.\n\n\n\n\n\n\nEnsuring Responsible Deployment of ML Models\nEven with strong compliance measures, responsible ML development goes beyond regulatory checklists. Organizations must proactively build processes that ensure ML models remain fair, interpretable, and aligned with ethical considerations throughout their lifecycle.\n\n\n\n\n\n\nHuman Oversight and Intervention\n\n\n\n\n\n\nIn high-stakes applications like healthcare and hiring, human oversight ensures that ML models do not make critical decisions in isolation. While models can assist in decision-making, final judgments should often be left to domain experts.\nHuman intervention helps mitigate risks by catching incorrect predictions, addressing ethical concerns, and ensuring accountability for automated decisions.\nExample: AI-assisted cancer detection models analyze medical scans to identify potential malignancies. However, to prevent misdiagnoses, a human doctor must review the model’s assessment and make the final diagnosis before any treatment decisions are made.\n\n\n\n\n\n\n\n\n\n\nRobust Model Monitoring and Drift Detection\n\n\n\n\n\n\nML models are not static; their performance can degrade over time due to changes in data distributions, known as data drift or concept drift. Without continuous monitoring, a once-reliable model may become biased or inaccurate.\nBias drift can gradually erode fairness in a model. If a model starts favoring one group over time, it can reinforce systemic inequalities.\nExample: A credit scoring model might initially treat applicants fairly but, as financial behaviors evolve, it may start favoring certain demographics due to new patterns in the data. Without monitoring and drift detection, such biases could go unnoticed and cause discriminatory lending practices.\n\n\n\n\n\n\n\n\n\n\nEmbedding Ethical ML Design Principles\n\n\n\n\n\n\nEthical ML requires an intentional, proactive approach rather than treating fairness and accountability as afterthoughts. Organizations must integrate ethical considerations into every stage of model development and deployment.\nBest practices include:\n\nDiverse ML teams: Having teams with varied backgrounds helps prevent blind spots and ensures models are designed with fairness in mind.\nPre-deployment risk assessments: Evaluating models for potential harm before launch can prevent ethical pitfalls and unintended consequences.\nThird-party audits: Independent fairness and accountability audits help ensure that models meet ethical and regulatory standards.\n\nEmbedding these principles early reduces the risk of biased outcomes and fosters public trust in ML-driven decisions.\n\n\n\n\nBy prioritizing ethical considerations and regulatory compliance, organizations can build trustworthy ML systems that benefit both businesses and society.\n\n\n\nTechniques for Improving Explainability and Mitigating Bias\nEnsuring that machine learning models are both interpretable and fair requires an intentional and structured approach throughout the model lifecycle. Various techniques exist to improve transparency, detect and mitigate bias, and ensure fairness in ML systems. These techniques apply to different stages of development, from data preprocessing to model selection, evaluation, and deployment.\nRather than treating explainability and fairness as isolated concerns, ML practitioners should integrate them into their workflow as ongoing priorities. The landscape of interpretability and fairness-aware ML is evolving, and staying informed about emerging techniques is crucial for responsible ML development.\nBelow are some of the most widely used methods for improving model transparency and mitigating bias.\n\n\n\n\n\n\nFeature Importance and Explainability Techniques\n\n\n\n\n\nTo improve model interpretability, data scientists can use post-hoc explainability methods that analyze how a model makes decisions.\n\nSHAP (Shapley Additive Explanations): Quantifies the contribution of each feature to a model’s prediction, offering a game-theoretic approach to understanding feature importance.\nLIME (Local Interpretable Model-agnostic Explanations): Generates simplified surrogate models to approximate black-box model behavior for individual predictions.\nFeature importance scores: Many ML models (e.g., decision trees, gradient boosting) provide built-in feature importance metrics that indicate which inputs most influence predictions.\n\n📖 Read More: SHAP vs. LIME: Understanding Explainability Methods\n\n\n\n\n\n\n\n\n\nFairness-Aware Preprocessing and Model Training\n\n\n\n\n\nBias can be introduced through historical inequalities in data. Fairness-aware techniques adjust data or model training to mitigate bias before it affects predictions.\n\nRe-weighting and re-sampling: Adjusts dataset composition to balance representation across demographic groups.\nAdversarial debiasing: Introduces fairness constraints in model training to reduce disparities in predictions.\nFairness-aware loss functions: Modifies optimization criteria to penalize biased predictions, improving equity across subpopulations.\n\n📖 Read More: Fairness in ML: Methods for Bias Mitigation\n\n\n\n\n\n\n\n\n\nFairness Metrics and Evaluation\n\n\n\n\n\nTo detect bias in ML models, practitioners should analyze performance disparities across different groups.\n\nDemographic parity: Ensures that model predictions are proportionally distributed across demographic groups.\nEqualized odds: Requires models to have similar false positive and false negative rates across groups.\nDisparate impact analysis: Measures whether one group receives favorable or unfavorable outcomes at a significantly different rate than others.\n\n📖 Read More: Measuring Fairness in Machine Learning\n\n\n\n\n\n\n\n\n\nMonitoring and Mitigating Bias in Deployed Models\n\n\n\n\n\nBias can evolve over time as new data is introduced. Continuous model monitoring and bias detection help ensure fairness remains intact post-deployment.\n\nData drift detection: Identifies when input distributions change, potentially leading to biased outcomes.\nModel performance tracking: Ensures evaluation metrics remain fair across demographic subgroups.\nHuman-in-the-loop systems: Introduces human review processes for high-risk decisions, preventing unchecked automation biases.\n\n📖 Read More: How to Detect Bias in ML with Evidently AI\n\n\n\nThere is no one-size-fits-all solution to explainability and fairness, and different models and use cases require different approaches. The key takeaway is that ML practitioners should treat interpretability and fairness as continuous, evolving challenges, not just compliance checkboxes.\nBy integrating these methods into their workflows, data scientists and ML engineers can build ML systems that are not only technically sound but also responsible, transparent, and fair — ensuring ML-driven decisions benefit all users equitably.",
    "crumbs": [
      "Human Elements",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>The Human Side of ML Systems</span>"
    ]
  },
  {
    "objectID": "12-human-side-of-ml.html#model-failures-and-accountability",
    "href": "12-human-side-of-ml.html#model-failures-and-accountability",
    "title": "12  The Human Side of ML Systems",
    "section": "12.4 Model Failures and Accountability",
    "text": "12.4 Model Failures and Accountability\nMachine learning models have the potential to transform industries, but when they fail, the consequences can be significant—ranging from biased hiring decisions and unfair credit scoring to medical misdiagnoses and flawed criminal justice assessments. Unlike traditional software bugs, ML failures are often more complex and harder to detect because they stem from issues in data, model design, deployment, or human oversight.\nThis section explores real-world ML failures, why they happen, and the critical question: who is accountable when models go wrong? Understanding these challenges will help organizations build more resilient, fair, and accountable ML systems.\n\nReal-World Failures of ML\nMachine learning failures can lead to financial, reputational, and legal consequences, particularly in high-stakes applications. Below are a few real-world examples that highlight how bias, poor generalization, or lack of oversight can result in harmful outcomes.\n\n\n\n\n\n\nBiased Hiring Models: Amazon’s Failed AI Recruiter\n\n\n\n\n\nAmazon developed an ML-driven hiring tool to automate resume screening, but it systematically downgraded applications from women because it learned from historical hiring data, which favored male candidates in technical roles. Despite efforts to mitigate bias, the model continued reinforcing gender discrimination, leading Amazon to shut it down.\n📖 Read More: Amazon Scraps AI Recruiting Tool That Showed Bias Against Women\n\n\n\n\n\n\n\n\n\nHealthcare Disparities: Racial Bias in Medical Risk Prediction\n\n\n\n\n\nA widely used healthcare algorithm designed to predict which patients needed additional care was found to systematically underestimate the medical needs of Black patients. The algorithm used past healthcare spending as a proxy for medical risk, but because Black patients historically received less medical attention, the model falsely concluded that they were healthier than they actually were.\n📖 Read More: Racial Bias in a Healthcare Algorithm\n\n\n\n\n\n\n\n\n\nCriminal Justice Bias: COMPAS Risk Assessment\n\n\n\n\n\nThe COMPAS algorithm, used in the U.S. criminal justice system to predict recidivism risk, was found to be twice as likely to wrongly classify Black defendants as high-risk compared to white defendants. The model’s predictions influenced sentencing and parole decisions, raising concerns about systemic racial bias in automated risk assessments.\n📖 Read More: Machine Bias – ProPublica Investigation\n\n\n\n\n\nWhy Do ML Models Fail?\nFailures in machine learning typically arise from one or more of the following factors:\n\nBias in Training Data → When models learn from biased historical patterns, they can reinforce discrimination.\nPoor Generalization → Models trained on limited or non-representative data may fail in real-world settings.\nLack of Interpretability → Black-box models make it difficult to understand why a model made a specific decision, leading to low stakeholder trust.\nFailure to Monitor Deployed Models → Without ongoing monitoring, models can drift over time, leading to worsening accuracy and fairness.\nUnintended Feedback Loops → ML models can influence the data they later receive, reinforcing biases and errors (e.g., predictive policing).\n\nUnderstanding these failure modes is critical for improving accountability in ML development.\n\n\nWho is Accountable for Model Failures?\nWhen a machine learning model causes harm, the responsibility often becomes unclear. Unlike traditional software, where failures are typically attributed to bugs in code, ML failures can stem from data biases, flawed assumptions, poor governance, or a lack of human oversight.\nTo ensure accountability, organizations should have clear roles and responsibilities for different stakeholders involved in ML projects. And each stakeholder in an ML project plays a role in ensuring fairness, reliability, and transparency:\n\n\n\n\n\n\nData Scientists & ML Engineers\n\n\n\n\n\n\nResponsible for model design, training, and validation.\nMust document assumptions, feature selection, and biases during development.\nShould implement fairness-aware modeling and explainability techniques.\n\n\n\n\n\n\n\n\n\n\nSoftware & Infrastructure Engineers\n\n\n\n\n\n\nEnsure models are properly integrated into production systems.\nMust set up monitoring pipelines to track model drift, fairness, and performance.\nShould automate bias detection and alerting mechanisms.\n\n\n\n\n\n\n\n\n\n\nProduct Managers & Business Leaders\n\n\n\n\n\n\nDefine model objectives and align them with business values.\nShould ensure models are interpretable and actionable for end-users.\nMust set up governance processes for ethical decision-making.\n\n\n\n\n\n\n\n\n\n\nLegal & Compliance Teams\n\n\n\n\n\n\nEnsure models adhere to regulatory frameworks (e.g., GDPR, CCPA, Equal Credit Opportunity Act).\nEstablish processes for auditing and risk assessment.\nEnsure ML-driven decisions are explainable and legally defensible.\n\n\n\n\n\n\n\n\n\n\nExecutives & Organizational Leaders\n\n\n\n\n\n\nMust prioritize responsible ML practices and build a culture of accountability.\nShould provide resources for fairness audits and governance.\nNeed to establish ethical AI policies at an enterprise level.\n\n\n\n\nWithout clear accountability structures, ML failures can go unnoticed until harm has already occurred. And although each member has clear accountability, the more aware of sources of bias in ML systems everyone is, then the easier it is for everyone to work together to create a fair and equitable ML system.\n\n\nBuilding Processes for Accountability in ML Projects\nIn addition to clear lines of accountability, organizations must also implement strong accountability mechanisms. By embedding these accountability mechanisms at every stage of the ML lifecycle, organizations can prevent costly failures and build more trustworthy AI systems.\n\n\n\n\n\n\nImplement Model Audits & Risk Assessments\n\n\n\n\n\n\nConduct regular fairness audits to detect bias before deployment.\nUse tools like Fairness Indicators, AI Fairness 360, and SHAP for explainability.\nPerform stress testing to see how models behave under different conditions.\n\n📖 Read More: AI Fairness 360 – Open-Source Toolkit\n\n\n\n\n\n\n\n\n\nEstablish Model Documentation & Governance\n\n\n\n\n\n\nMaintain model cards that document purpose, limitations, and fairness considerations.\nUse datasheets for datasets to ensure transparency in data sources and biases.\nCreate internal review boards for high-risk ML models.\n\n📖 Read More: Google’s Model Cards for AI Transparency\n\n\n\n\n\n\n\n\n\nMonitor Models Post-Deployment\n\n\n\n\n\n\nSet up real-time monitoring for bias, accuracy drift, and unexpected outcomes.\nUse human-in-the-loop systems for high-stakes decisions.\nCreate incident response plans for when models cause harm.\n\n📖 Read More: How to Detect Bias in ML Models with Evidently AI\n\n\n\nML systems are only as reliable as the processes and teams behind them. Without proper oversight, governance, and accountability, ML models can fail in ways that negatively impact individuals, businesses, and society.\nTo build fair and responsible ML, organizations must:\n\nProactively identify and mitigate bias in models.\nAssign clear accountability to teams responsible for ML deployment.\nMonitor deployed models continuously to detect and prevent harm.\nFollow ethical AI principles to ensure transparency, fairness, and compliance.\n\nAs ML adoption grows, accountability will be a key differentiator between organizations that build trustworthy AI systems and those that face legal, ethical, and reputational risks.\nBy fostering responsible ML development, ML practitioners can help ensure that models not only drive business value but also align with human values and societal expectations.",
    "crumbs": [
      "Human Elements",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>The Human Side of ML Systems</span>"
    ]
  },
  {
    "objectID": "12-human-side-of-ml.html#summary",
    "href": "12-human-side-of-ml.html#summary",
    "title": "12  The Human Side of ML Systems",
    "section": "12.5 Summary",
    "text": "12.5 Summary\nMachine learning systems are more than just algorithms and data pipelines—they are shaped by human decisions at every stage, from problem definition to deployment. This chapter explored the human-centric challenges in ML, including collaboration across teams, bias and fairness concerns, accountability for model failures, and the evolving landscape of responsible AI development.\n\nKey Human-Centric Challenges in ML\n\nThe Role of Humans in ML Systems: ML systems are socio-technical in nature, requiring strong collaboration between data scientists, engineers, domain experts, and business leaders. Misalignment between these groups can lead to ineffective or ethically problematic models.\nBias, Fairness, and Ethical Considerations: Bias can be introduced at multiple stages of the ML pipeline, from data collection to model evaluation. Without proactive bias detection and fairness-aware modeling, ML systems risk reinforcing societal inequalities.\nAccountability and Model Failures: When ML models fail—whether due to bias, unexpected behavior, or poor generalization—the question of who is responsible becomes critical. Building robust accountability mechanisms ensures that organizations take ownership of model outcomes.\n\n\n\nCall to Action: Responsible and Collaborative ML Development\nTo build trustworthy, fair, and effective ML systems, organizations and practitioners must:\n\nFoster cross-functional collaboration between technical and non-technical teams.\nImplement bias audits, interpretability techniques, and fairness-aware modeling.\nEstablish accountability structures to track and address ML failures.\nStay informed on emerging regulations and ensure compliance with ethical AI standards.\nPrioritize human oversight in high-stakes ML applications to prevent automation failures.\n\nML is not just about building better models—it’s about creating responsible and human-centered ML systems that serve society fairly and effectively.\n\n\nFurther Reading & Resources\nFor those looking to dive deeper into responsible AI, fairness, and interpretability, consider the following resources:\n\n\n\n\n\n\nBooks\n\n\n\n\n\n\nWeapons of Math Destruction – Cathy O’Neil (on the societal impact of biased algorithms)\nThe Alignment Problem – Brian Christian (on ethical AI and human oversight)\nInterpretable Machine Learning – Christoph Molnar (on explainability techniques)\n\n\n\n\n\n\n\n\n\n\nAcademic Papers & Reports\n\n\n\n\n\n\nGender Shades: Evaluating Bias in Commercial Facial Analysis\nFairness and Machine Learning: Limitations and Opportunities\nAI and Ethics Guidelines – OECD Principles on AI\n\n\n\n\n\n\n\n\n\n\nCourses & Toolkits\n\n\n\n\n\n\nFairness Indicators – Google\nAI Fairness 360 – IBM Open-Source Toolkit\nResponsible AI Course – Microsoft\n\n\n\n\nBy continuously learning and applying responsible ML practices, practitioners can build trustworthy, interpretable, and equitable ML systems that drive positive real-world impact.",
    "crumbs": [
      "Human Elements",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>The Human Side of ML Systems</span>"
    ]
  },
  {
    "objectID": "12-human-side-of-ml.html#exercise",
    "href": "12-human-side-of-ml.html#exercise",
    "title": "12  The Human Side of ML Systems",
    "section": "12.6 Exercise",
    "text": "12.6 Exercise\nThis exercise will help you analyze real-world failures of machine learning systems, focusing on bias, interpretability, accountability, and ethical considerations. By examining actual case studies, you will evaluate the risks, identify accountability gaps, and propose strategies to improve responsible ML development.\n\nStep 1: Choose a Case Study\nSelect one of the following real-world ML failures to analyze:\n\n\n\n\n\n\nAmazon’s AI Hiring Model\n\n\n\n\n\n\nAmazon developed an AI-powered hiring system to automate resume screening.\nThe system downgraded resumes from women because it learned from historical hiring data that favored male candidates.\n📖 Read More: Amazon Scraps AI Recruiting Tool That Showed Bias Against Women\n\n\n\n\n\n\n\n\n\n\nHealthcare Algorithm with Racial Bias\n\n\n\n\n\n\nA widely used healthcare risk prediction model systematically underestimated the risk levels of Black patients, leading to disparities in who received extra medical care.\n📖 Read More: Racial Bias in a Healthcare Algorithm\n\n\n\n\n\n\n\n\n\n\nFacial Recognition and Misidentification\n\n\n\n\n\n\nLaw enforcement agencies used facial recognition software to identify suspects, but the system had higher misidentification rates for people with darker skin tones.\nThis led to wrongful arrests and public concerns over racial bias in policing.\n📖 Read More: Facial Recognition Wrongfully Identifies Black Man\n\n\n\n\n\n\n\n\n\n\nApple Card Gender Bias in Credit Limits\n\n\n\n\n\n\nApple’s credit card algorithm offered lower credit limits to women compared to men, even when they had similar financial profiles.\n📖 Read More: Apple Card Faces Accusations of Gender Bias\n\n\n\n\n\n\n\n\n\n\nCOMPAS Criminal Justice Risk Assessment\n\n\n\n\n\n\nThe COMPAS algorithm was used in criminal sentencing to predict the likelihood of repeat offenses.\nAn investigation found it was more likely to incorrectly classify Black defendants as high-risk compared to white defendants.\n📖 Read More: Machine Bias - ProPublica\n\n\n\n\n\n\nStep 2: Analyze the ML Failure\nFor your chosen case study, answer the following questions:\n\nIdentifying Bias and Interpretability Issues\n\nWhat types of bias (e.g., historical bias, sampling bias, proxy bias) were present in the system?\nHow did the lack of model interpretability contribute to stakeholder distrust or failure to detect these issues?\n\nAccountability Gaps\n\nWhich stakeholders (e.g., data scientists, engineers, product managers, legal teams) should have been responsible for detecting and mitigating these issues?\nAt what stage in the ML lifecycle (data collection, model training, deployment) should these risks have been identified?\nWere there any regulatory or ethical standards that were overlooked?\n\nProposing Solutions for Responsible ML Development\n\nWhat mitigation strategies (e.g., fairness-aware algorithms, better data collection practices, human-in-the-loop systems) could have prevented this failure?\nWhat monitoring or audit mechanisms should have been in place to detect these biases before deployment?\nIf this system were being developed today, what steps would you take to ensure it meets fairness and ethical standards?",
    "crumbs": [
      "Human Elements",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>The Human Side of ML Systems</span>"
    ]
  },
  {
    "objectID": "13-continued-learning.html",
    "href": "13-continued-learning.html",
    "title": "13  Continuing Your Growth as an ML Practitioner",
    "section": "",
    "text": "13.1 Staying Up to Date with ML Trends\nThis chapter will serve as a guide for lifelong learning in machine learning and MLOps. ML is a rapidly evolving field, and staying relevant requires continuous learning, hands-on practice, and engagement with the community. This chapter will quickly cover:",
    "crumbs": [
      "Human Elements",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Continuing Your Growth as an ML Practitioner</span>"
    ]
  },
  {
    "objectID": "13-continued-learning.html#staying-up-to-date-with-ml-trends",
    "href": "13-continued-learning.html#staying-up-to-date-with-ml-trends",
    "title": "13  Continuing Your Growth as an ML Practitioner",
    "section": "",
    "text": "Why Continuous Learning Matters:\n\nRapid advancements in ML, deep learning, and MLOps.\nThe growing importance of specialized subfields (e.g., Responsible AI, Generative AI).\n\nWhere to Follow ML Trends:\n\nResearch conferences (NeurIPS, ICML, CVPR, etc.).\nIndustry blogs (Google AI, OpenAI, Hugging Face).\nNewsletters and podcasts (The Batch, Towards Data Science, DataTalks).",
    "crumbs": [
      "Human Elements",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Continuing Your Growth as an ML Practitioner</span>"
    ]
  },
  {
    "objectID": "13-continued-learning.html#hands-on-learning-building-and-experimenting",
    "href": "13-continued-learning.html#hands-on-learning-building-and-experimenting",
    "title": "13  Continuing Your Growth as an ML Practitioner",
    "section": "13.2 Hands-on Learning: Building and Experimenting",
    "text": "13.2 Hands-on Learning: Building and Experimenting\n\nThe Power of Projects:\n\nLearning is best done through hands-on practice.\nBuild ML models, deploy pipelines, and optimize real-world datasets.\n\nIdeas for Personal ML Projects:\n\nEnd-to-end ML pipelines (data ingestion → training → deployment).\nExperiment tracking and model versioning with new datasets.\nModel monitoring with real-world data drift scenarios.\n\nOpen-Source Contributions:\n\nContributing to ML frameworks (e.g., TensorFlow, PyTorch, Scikit-learn).\nCollaborating on GitHub projects.\nWriting and sharing code through blog posts or tutorials.",
    "crumbs": [
      "Human Elements",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Continuing Your Growth as an ML Practitioner</span>"
    ]
  },
  {
    "objectID": "13-continued-learning.html#learning-from-the-community",
    "href": "13-continued-learning.html#learning-from-the-community",
    "title": "13  Continuing Your Growth as an ML Practitioner",
    "section": "13.3 Learning from the Community",
    "text": "13.3 Learning from the Community\n\nJoining ML Communities:\n\nOnline forums (Reddit r/MachineLearning, Kaggle, Stack Overflow).\nOpen-source Slack communities (MLflow, Weights & Biases, Hugging Face).\nAttending ML and MLOps meetups.\n\nFollowing ML Practitioners:\n\nEngaging with experts on LinkedIn, Twitter, and YouTube.\nLearning from experienced professionals in industry and academia.\n\nParticipating in Competitions:\n\nKaggle challenges for hands-on learning.\nHackathons and industry-led competitions.",
    "crumbs": [
      "Human Elements",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Continuing Your Growth as an ML Practitioner</span>"
    ]
  },
  {
    "objectID": "13-continued-learning.html#mastering-mlops-and-advanced-ml-topics",
    "href": "13-continued-learning.html#mastering-mlops-and-advanced-ml-topics",
    "title": "13  Continuing Your Growth as an ML Practitioner",
    "section": "13.4 Mastering MLOps and Advanced ML Topics",
    "text": "13.4 Mastering MLOps and Advanced ML Topics\n\nDeepening MLOps Knowledge:\n\nReading advanced books on ML engineering and productionization.\nExperimenting with MLOps tools (Kubeflow, Apache Airflow, Feature Stores).\nUnderstanding cloud ML workflows (AWS SageMaker, Google Vertex AI).\n\nExpanding into Specializations:\n\nNLP, Computer Vision, Generative AI.\nResponsible AI, Fairness, and Model Interpretability.\nEdge ML and Embedded AI.\n\nTaking Online Courses and Certifications:\n\nML Engineering & MLOps courses (Coursera, Udacity, DataTalks).\nCertifications (AWS ML Specialty, TensorFlow Developer).",
    "crumbs": [
      "Human Elements",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Continuing Your Growth as an ML Practitioner</span>"
    ]
  },
  {
    "objectID": "13-continued-learning.html#soft-skills-for-career-growth",
    "href": "13-continued-learning.html#soft-skills-for-career-growth",
    "title": "13  Continuing Your Growth as an ML Practitioner",
    "section": "13.5 Soft Skills for Career Growth",
    "text": "13.5 Soft Skills for Career Growth\n\nCommunicating ML Effectively:\n\nExplaining complex concepts to non-technical stakeholders.\nWriting clear documentation and reports.\n\nProblem-Solving and Business Impact:\n\nLearning to frame ML problems in a business context.\nPrioritizing impact over complexity in ML projects.\n\nMentorship and Leadership:\n\nTeaching others through mentoring or blogging.\nLeading ML projects and improving team workflows.",
    "crumbs": [
      "Human Elements",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Continuing Your Growth as an ML Practitioner</span>"
    ]
  },
  {
    "objectID": "13-continued-learning.html#final-thoughts-the-journey-never-ends",
    "href": "13-continued-learning.html#final-thoughts-the-journey-never-ends",
    "title": "13  Continuing Your Growth as an ML Practitioner",
    "section": "13.6 Final Thoughts: The Journey Never Ends",
    "text": "13.6 Final Thoughts: The Journey Never Ends\n\nRecap of the key takeaways from the book.\nThe best ML practitioners never stop learning—keep experimenting, keep questioning.\nEncourage the reader to stay curious, contribute, and keep building.",
    "crumbs": [
      "Human Elements",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Continuing Your Growth as an ML Practitioner</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Amershi, Saleema, Andrew Begel, Christian Bird, Robert DeLine, Harald\nGall, Ece Kamar, Nachiappan Nagappan, Besmira Nushi, and Thomas\nZimmermann. 2019. “Software Engineering for Machine Learning: A\nCase Study.” In 2019 IEEE/ACM 41st International Conference\non Software Engineering: Software Engineering in Practice\n(ICSE-SEIP), 291–300. IEEE.\n\n\nGama, João, Indrė Žliobaitė, Albert Bifet, Mykola Pechenizkiy, and\nAbdelhamid Bouchachia. 2014. “A Survey on Concept Drift\nAdaptation.” ACM Computing Surveys (CSUR) 46 (4): 1–37.\n\n\nGéron, Aurélien. 2022. Hands-on Machine Learning with Scikit-Learn,\nKeras, and TensorFlow. \" O’Reilly Media, Inc.\".\n\n\nHeckman, James. 2013. “Sample Selection Bias as a Specification\nError.” Applied Econometrics 31 (3): 129–37.\n\n\nHuyen, Chip. 2022. Designing Machine Learning Systems. \"\nO’Reilly Media, Inc.\".\n\n\nKreuzberger, Dominik, Niklas Kühl, and Sebastian Hirschl. 2023.\n“Machine Learning Operations (Mlops): Overview, Definition, and\nArchitecture.” IEEE Access 11: 31866–79.\n\n\nKuhn, Max, and Kjell Johnson. 2019. Feature Engineering and\nSelection: A Practical Approach for Predictive Models. Chapman;\nHall/CRC.\n\n\nLerman, Rachel. February 3, 2016. “Google Is Testing Its\nSelf-Driving Car in Kirkland,” February 3, 2016.\n\n\nLevine, Sergey, Aviral Kumar, George Tucker, and Justin Fu. 2020.\n“Offline Reinforcement Learning: Tutorial, Review, and\nPerspectives on Open Problems.” arXiv Preprint\narXiv:2005.01643.\n\n\nMattson, Peter, Christine Cheng, Gregory Diamos, Cody Coleman, Paulius\nMicikevicius, David Patterson, Hanlin Tang, et al. 2020. “Mlperf\nTraining Benchmark.” Proceedings of Machine Learning and\nSystems 2: 336–49.\n\n\nPapernot, Nicolas, Patrick McDaniel, Ian Goodfellow, Somesh Jha, Z\nBerkay Celik, and Ananthram Swami. 2017. “Practical Black-Box\nAttacks Against Machine Learning.” In Proceedings of the 2017\nACM on Asia Conference on Computer and Communications Security,\n506–19.\n\n\nPolyzotis, Neoklis, Martin Zinkevich, Sudip Roy, Eric Breck, and Steven\nWhang. 2019. “Data Validation for Machine Learning.”\nProceedings of Machine Learning and Systems 1: 334–47.\n\n\nSculley, David, Gary Holt, Daniel Golovin, Eugene Davydov, Todd\nPhillips, Dietmar Ebner, Vinay Chaudhary, Michael Young, Jean-Francois\nCrespo, and Dan Dennison. 2015. “Hidden Technical Debt in Machine\nLearning Systems.” Advances in Neural Information Processing\nSystems 28.\n\n\nTolomei, Gabriele, Fabrizio Silvestri, Andrew Haines, and Mounia Lalmas.\n2017. “Interpretable Predictions of Tree-Based Ensembles via\nActionable Feature Tweaking.” In Proceedings of the 23rd ACM\nSIGKDD International Conference on Knowledge Discovery and Data\nMining, 465–74.\n\n\nVemulapalli, Gopichand. 2023. “Operationalizing Machine Learning\nBest Practices for Scalable Production Deployments.”\nInternational Machine Learning Journal and Computer Engineering\n6 (6): 1–21.\n\n\nZheng, Alice, and Amanda Casari. 2018. Feature Engineering for\nMachine Learning: Principles and Techniques for Data Scientists. \"\nO’Reilly Media, Inc.\".",
    "crumbs": [
      "References"
    ]
  }
]